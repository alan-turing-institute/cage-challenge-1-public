episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,timesteps_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,hist_stats/episode_reward,hist_stats/episode_lengths,timers/sample_time_ms,timers/sample_throughput,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_agent_steps_sampled,info/num_steps_trained,info/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
nan,nan,nan,nan,0,4,4000,0,4000,True,0,1,005f5_00000,1d54a89b587c43b4b31f77f54ef04f30,2022-01-19_13-24-06,1642598646,8.214321851730347,8.214321851730347,43963,MAC-ATI0602,127.0.0.1,8.214321851730347,0,1,[],[],6201.415,645.014,0.317,12623939.804,2007.504,1992.524,1.932,4000,4000,4000,4000,50.84166666666666,61.70000000000002,0.20000000298023224,9.999999747378752e-05,18171.703,-0.010948863,18171.707,-0.0029273776,0.02339017,3.6907651,0.0
