{"episode_reward_max": -18.7, "episode_reward_min": -88.7, "episode_reward_mean": -63.71201923076923, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.6, -27.700000000000006, -83.69999999999999, -33.7, -82.69999999999999, -34.199999999999996, -24.700000000000003, -86.69999999999999, -75.7, -86.3, -83.0, -42.7, -18.7, -84.7, -30.700000000000006, -86.69999999999999, -85.69999999999999, -83.69999999999999, -81.69999999999999, -52.7, -59.7, -72.69999999999999, -85.69999999999999, -82.69999999999999, -34.7, -49.7, -75.7, -85.69999999999999, -82.69999999999999, -77.7, -19.7, -88.69999999999999, -80.3, -82.6, -77.5, -30.700000000000003, -84.7, -87.69999999999999, -78.69999999999999, -86.2, -25.700000000000006, -44.8, -40.7, -83.69999999999999, -33.7, -34.7, -87.69999999999999, -33.7, -83.69999999999999, -35.400000000000006, -76.8, -86.69999999999999, -33.7, -24.9, -32.7, -79.69999999999999, -35.5, -82.69999999999999, -85.69999999999999, -36.7, -83.69999999999999, -80.69999999999999, -86.69999999999999, -79.1, -60.7, -22.600000000000005, -78.69999999999999, -31.700000000000006, -82.69999999999999, -79.69999999999999, -25.700000000000003, -84.0, -84.4, -73.7, -79.69999999999999, -30.5, -83.0, -82.7, -82.9, -36.7, -88.7, -84.69999999999999, -38.4, -83.6, -84.69999999999999, -83.69999999999999, -83.5, -86.7, -63.7, -35.70000000000001, -72.7, -85.6, -80.69999999999999, -83.69999999999999, -83.69999999999999, -38.099999999999994, -37.7, -85.69999999999999, -81.69999999999999, -59.6, -27.299999999999997, -32.70000000000001, -36.7, -31.700000000000003, -83.69999999999999, -81.69999999999999, -75.7, -58.7, -76.69999999999999, -32.400000000000006, -33.70000000000001, -80.69999999999999, -83.3, -37.6, -87.69999999999999, -84.69999999999999, -33.7, -86.8, -87.6, -82.69999999999999, -45.7, -78.4, -81.69999999999999, -85.69999999999999, -85.69999999999999, -37.7, -84.0, -84.69999999999999, -85.2, -20.600000000000005, -22.700000000000003, -85.7, -27.700000000000006, -81.9, -83.69999999999999, -82.3, -31.700000000000006, -74.6, -37.7, -81.69999999999999, -83.69999999999999, -85.69999999999999, -85.69999999999999, -33.7, -60.400000000000006, -78.69999999999999, -85.6, -23.700000000000003, -86.69999999999999, -35.7, -82.69999999999999, -84.69999999999999, -35.7, -32.7, -31.700000000000003, -34.7, -86.69999999999999, -83.6, -77.4, -78.69999999999999, -78.2, -84.4, -79.69999999999999, -81.7, -30.700000000000006, -63.7, -80.2, -56.6, -25.700000000000003, -32.7, -86.69999999999999, -83.69999999999999, -23.700000000000003, -87.7, -31.700000000000003, -32.7, -35.7, -20.700000000000003, -32.6, -86.69999999999999, -38.70000000000001, -84.5, -58.7, -75.9, -83.69999999999999, -82.69999999999999, -81.69999999999999, -85.7, -83.5, -36.5, -61.60000000000001, -82.69999999999999, -36.7, -86.69999999999999, -81.69999999999999, -70.7, -28.700000000000006, -75.7, -84.2, -28.700000000000006, -28.700000000000006, -60.7, -31.700000000000006, -36.7, -61.2, -28.2, -78.69999999999999, -84.4], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.373731160140061, "mean_inference_ms": 1.3188507173444841, "mean_action_processing_ms": 0.09449956181285145, "mean_env_wait_ms": 4.2797524135905896, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4000, "timesteps_this_iter": 0, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 8285.688, "sample_throughput": 482.76, "load_time_ms": 0.322, "load_throughput": 12427567.407, "learn_time_ms": 2310.751, "learn_throughput": 1731.039, "update_time_ms": 2.002}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2031.1334228515625, "policy_loss": -0.02241145633161068, "vf_loss": 2031.1512451171875, "vf_explained_var": -0.012262850999832153, "kl": 0.023422086611390114, "entropy": 3.690504789352417, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 4000, "num_steps_trained": 4000, "num_agent_steps_trained": 4000}, "done": false, "episodes_total": 208, "training_iteration": 1, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-05-12", "timestamp": 1642601112, "time_this_iter_s": 10.605682849884033, "time_total_s": 10.605682849884033, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.605682849884033, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 46.725, "ram_util_percent": 61.76875}}
{"episode_reward_max": -15.699999999999996, "episode_reward_min": -87.9, "episode_reward_mean": -55.9622641509434, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.7, -81.69999999999999, -81.69999999999999, -24.700000000000003, -35.9, -82.69999999999999, -23.7, -81.69999999999999, -60.7, -32.7, -34.7, -79.69999999999999, -79.69999999999999, -82.69999999999999, -15.699999999999996, -33.7, -87.7, -75.69999999999999, -25.6, -73.7, -81.69999999999999, -32.7, -82.69999999999999, -28.700000000000006, -71.4, -40.7, -33.7, -73.4, -87.69999999999999, -86.69999999999999, -48.7, -83.69999999999999, -84.69999999999999, -33.7, -33.7, -42.70000000000001, -76.69999999999999, -84.69999999999999, -84.69999999999999, -16.7, -38.7, -30.700000000000003, -34.7, -29.6, -85.4, -86.69999999999999, -84.69999999999999, -30.700000000000006, -72.7, -54.2, -25.700000000000006, -32.7, -78.69999999999999, -19.7, -34.7, -54.7, -72.7, -22.2, -32.7, -28.700000000000006, -85.69999999999999, -19.7, -58.7, -34.6, -82.69999999999999, -85.7, -83.4, -37.7, -83.5, -85.69999999999999, -32.5, -30.700000000000003, -22.700000000000003, -51.7, -82.69999999999999, -79.69999999999999, -32.7, -46.7, -49.7, -33.4, -84.69999999999999, -80.69999999999999, -82.69999999999999, -80.69999999999999, -35.7, -86.9, -24.700000000000003, -32.7, -50.8, -32.7, -36.7, -80.4, -82.69999999999999, -83.3, -49.7, -31.700000000000006, -24.700000000000003, -84.8, -31.700000000000006, -34.7, -27.2, -30.700000000000006, -30.700000000000006, -25.600000000000005, -72.7, -35.3, -84.69999999999999, -31.700000000000006, -29.700000000000006, -31.700000000000003, -28.700000000000003, -82.69999999999999, -79.69999999999999, -81.69999999999999, -26.600000000000005, -83.69999999999999, -24.700000000000006, -80.69999999999999, -30.6, -81.69999999999999, -31.700000000000006, -33.1, -31.700000000000003, -76.1, -35.7, -81.4, -71.6, -85.69999999999999, -82.69999999999999, -87.69999999999999, -24.700000000000003, -29.6, -85.69999999999999, -31.700000000000003, -85.5, -87.9, -26.700000000000006, -60.7, -86.69999999999999, -85.6, -83.4, -24.5, -84.69999999999999, -83.69999999999999, -81.69999999999999, -81.69999999999999, -26.700000000000006, -35.70000000000001, -31.700000000000006, -82.69999999999999, -34.7, -82.69999999999999, -23.700000000000003, -81.4, -35.7, -71.69999999999999, -31.700000000000006, -79.69999999999999, -80.69999999999999, -83.69999999999999, -75.7, -24.700000000000006, -19.6, -44.7, -71.69999999999999, -50.7, -32.7, -24.700000000000003, -78.69999999999999, -82.69999999999999, -83.69999999999999, -81.69999999999999, -36.7, -86.0, -23.700000000000003, -81.69999999999999, -38.7, -82.69999999999999, -62.6, -35.70000000000001, -35.7, -83.69999999999999, -32.9, -32.2, -81.8, -34.5, -31.700000000000003, -29.700000000000006, -83.69999999999999, -60.3, -23.700000000000003, -75.7, -33.7, -29.700000000000006, -33.4, -26.700000000000006, -83.69999999999999, -74.3, -31.700000000000003, -33.7, -83.0, -80.69999999999999, -81.69999999999999, -84.6, -74.5, -26.3, -80.0, -72.69999999999999, -35.9, -73.7, -27.70000000000001, -83.69999999999999], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.569345073185224, "mean_inference_ms": 1.3858563062371403, "mean_action_processing_ms": 0.09933231712162105, "mean_env_wait_ms": 4.577662752962662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 8000, "timesteps_this_iter": 0, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 10007.923, "sample_throughput": 399.683, "load_time_ms": 0.317, "load_throughput": 12604970.699, "learn_time_ms": 2235.738, "learn_throughput": 1789.118, "update_time_ms": 1.875}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 961.6114501953125, "policy_loss": -0.024078333750367165, "vf_loss": 961.6298217773438, "vf_explained_var": -0.0044841705821454525, "kl": 0.018897822126746178, "entropy": 3.65165638923645, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 8000, "num_steps_trained": 8000, "num_agent_steps_trained": 8000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 420, "training_iteration": 2, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-05-24", "timestamp": 1642601124, "time_this_iter_s": 11.542339086532593, "time_total_s": 22.148021936416626, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22.148021936416626, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 55.46875, "ram_util_percent": 62.099999999999994}}
{"episode_reward_max": -16.699999999999996, "episode_reward_min": -87.69999999999999, "episode_reward_mean": -47.53221153846153, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.9, -87.0, -23.700000000000003, -25.700000000000003, -33.7, -68.69999999999999, -48.5, -29.700000000000006, -80.69999999999999, -73.7, -79.69999999999999, -60.7, -83.69999999999999, -32.7, -32.0, -27.700000000000006, -21.700000000000003, -73.7, -81.69999999999999, -24.6, -32.7, -26.700000000000006, -82.69999999999999, -35.7, -83.69999999999999, -28.700000000000006, -23.700000000000003, -34.60000000000001, -83.69999999999999, -78.69999999999999, -35.7, -18.7, -33.7, -30.700000000000006, -84.2, -81.69999999999999, -78.5, -26.5, -73.9, -29.3, -33.7, -19.700000000000003, -28.700000000000006, -34.4, -87.69999999999999, -74.6, -30.700000000000006, -73.7, -41.7, -87.69999999999999, -35.0, -32.7, -83.69999999999999, -35.3, -34.7, -82.69999999999999, -85.69999999999999, -32.7, -31.700000000000006, -33.7, -31.700000000000006, -79.69999999999999, -33.7, -81.69999999999999, -26.700000000000003, -48.7, -34.5, -16.699999999999996, -20.700000000000003, -36.7, -29.700000000000006, -27.700000000000003, -33.7, -76.7, -56.7, -76.8, -31.70000000000001, -78.69999999999999, -71.7, -27.700000000000006, -29.700000000000003, -81.69999999999999, -33.7, -39.7, -83.7, -25.700000000000003, -60.7, -83.4, -29.700000000000006, -33.7, -34.7, -83.69999999999999, -55.8, -52.7, -36.7, -20.700000000000003, -49.0, -23.9, -32.7, -35.70000000000001, -78.69999999999999, -34.3, -32.60000000000001, -72.7, -22.700000000000003, -19.5, -34.7, -24.600000000000005, -81.69999999999999, -35.3, -22.599999999999998, -33.7, -34.7, -33.6, -57.7, -33.7, -33.5, -80.2, -35.7, -26.700000000000003, -28.700000000000006, -52.7, -84.69999999999999, -33.5, -64.7, -82.69999999999999, -34.7, -27.5, -31.700000000000006, -18.7, -34.7, -28.700000000000003, -25.600000000000005, -73.7, -25.700000000000003, -32.0, -76.7, -33.7, -33.7, -70.7, -81.7, -30.6, -32.5, -83.69999999999999, -80.69999999999999, -41.7, -27.700000000000006, -81.69999999999999, -41.7, -35.70000000000001, -82.1, -24.700000000000003, -75.7, -64.7, -84.69999999999999, -83.4, -48.6, -28.600000000000005, -18.700000000000003, -69.7, -26.700000000000006, -79.69999999999999, -24.9, -30.700000000000006, -35.70000000000001, -80.69999999999999, -30.700000000000003, -81.69999999999999, -22.3, -79.69999999999999, -82.2, -32.6, -81.69999999999999, -30.700000000000003, -86.69999999999999, -34.70000000000001, -32.4, -31.700000000000006, -52.7, -32.3, -20.700000000000003, -81.69999999999999, -35.4, -79.69999999999999, -77.69999999999999, -49.7, -30.700000000000006, -32.60000000000001, -29.700000000000006, -72.7, -32.7, -32.7, -30.700000000000006, -35.7, -26.4, -28.9, -36.7, -28.700000000000006, -74.3, -64.3, -34.60000000000001, -34.6, -34.5, -25.700000000000006, -26.700000000000003, -26.700000000000003, -74.7, -33.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.511869844139835, "mean_inference_ms": 1.3550305636633797, "mean_action_processing_ms": 0.09712619568577849, "mean_env_wait_ms": 4.497286996139125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 12000, "timesteps_this_iter": 0, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 10191.275, "sample_throughput": 392.493, "load_time_ms": 0.307, "load_throughput": 13032534.438, "learn_time_ms": 2123.997, "learn_throughput": 1883.242, "update_time_ms": 1.943}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 522.8798828125, "policy_loss": -0.03152108192443848, "vf_loss": 522.9032592773438, "vf_explained_var": -0.00444033881649375, "kl": 0.027124056592583656, "entropy": 3.614048957824707, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 12000, "num_steps_trained": 12000, "num_agent_steps_trained": 12000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 628, "training_iteration": 3, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-05-34", "timestamp": 1642601134, "time_this_iter_s": 10.269296169281006, "time_total_s": 32.41731810569763, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.41731810569763, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 48.626666666666665, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -14.699999999999998, "episode_reward_min": -86.69999999999999, "episode_reward_mean": -43.402830188679246, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-81.69999999999999, -83.69999999999999, -78.1, -19.7, -33.7, -37.7, -31.700000000000003, -34.7, -27.700000000000003, -31.700000000000006, -79.69999999999999, -60.6, -29.700000000000003, -29.700000000000003, -33.099999999999994, -38.8, -22.700000000000003, -31.9, -76.69999999999999, -31.700000000000003, -33.6, -77.69999999999999, -29.2, -34.7, -47.4, -29.2, -81.69999999999999, -81.69999999999999, -47.7, -61.6, -37.70000000000001, -24.700000000000003, -84.0, -82.69999999999999, -58.7, -56.7, -71.7, -33.6, -27.700000000000003, -23.700000000000006, -72.7, -71.0, -34.7, -27.700000000000006, -86.1, -55.7, -35.400000000000006, -76.69999999999999, -33.3, -79.69999999999999, -72.7, -22.6, -16.7, -28.700000000000006, -26.5, -27.4, -24.700000000000003, -82.3, -36.70000000000001, -23.0, -36.2, -34.7, -84.7, -32.7, -26.7, -37.7, -73.69999999999999, -31.700000000000006, -65.7, -57.7, -54.7, -80.3, -30.700000000000006, -30.700000000000006, -33.7, -80.69999999999999, -83.3, -33.60000000000001, -21.700000000000003, -27.700000000000003, -34.7, -22.700000000000003, -50.5, -25.4, -71.7, -63.7, -27.799999999999997, -26.600000000000005, -29.600000000000005, -26.700000000000003, -77.0, -35.8, -29.700000000000006, -34.7, -38.70000000000001, -28.700000000000006, -34.4, -27.600000000000005, -24.700000000000003, -32.7, -30.700000000000006, -82.69999999999999, -74.7, -31.700000000000006, -20.700000000000003, -20.700000000000003, -32.7, -52.70000000000001, -26.700000000000006, -58.6, -23.099999999999998, -27.700000000000006, -32.70000000000001, -33.60000000000001, -20.6, -33.7, -31.700000000000006, -82.69999999999999, -32.3, -29.8, -78.4, -34.7, -35.3, -40.3, -30.700000000000006, -41.7, -31.700000000000006, -27.3, -25.700000000000006, -25.8, -29.3, -26.0, -29.3, -27.700000000000006, -31.700000000000006, -28.700000000000006, -40.7, -21.700000000000003, -18.700000000000003, -71.2, -74.4, -25.2, -30.700000000000006, -26.700000000000006, -28.4, -78.7, -26.700000000000006, -73.9, -24.700000000000006, -34.9, -80.69999999999999, -54.6, -14.699999999999998, -49.7, -32.7, -22.8, -62.9, -41.7, -67.69999999999999, -37.6, -23.799999999999997, -34.50000000000001, -21.6, -51.7, -35.7, -32.7, -34.3, -32.7, -78.69999999999999, -54.6, -31.700000000000006, -35.6, -34.8, -81.69999999999999, -85.1, -31.600000000000005, -39.3, -31.700000000000006, -66.69999999999999, -34.7, -28.7, -32.7, -83.69999999999999, -24.700000000000003, -27.700000000000006, -61.6, -30.700000000000006, -35.70000000000001, -33.7, -28.2, -33.70000000000001, -35.7, -34.70000000000001, -84.69999999999999, -32.5, -53.6, -26.700000000000006, -59.6, -32.7, -25.700000000000006, -24.700000000000003, -83.3, -78.69999999999999, -34.7, -30.700000000000003, -28.700000000000006, -29.700000000000006, -36.7, -60.1, -75.7, -28.700000000000006, -86.69999999999999], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4977611828017188, "mean_inference_ms": 1.3484227690092476, "mean_action_processing_ms": 0.096626354437773, "mean_env_wait_ms": 4.483479584672695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 16000, "timesteps_this_iter": 0, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 10243.629, "sample_throughput": 390.487, "load_time_ms": 0.318, "load_throughput": 12569556.846, "learn_time_ms": 2135.943, "learn_throughput": 1872.709, "update_time_ms": 2.179}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 405.1348876953125, "policy_loss": -0.034412603825330734, "vf_loss": 405.16021728515625, "vf_explained_var": -0.002419162541627884, "kl": 0.020218441262841225, "entropy": 3.5494766235351562, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 16000, "num_agent_steps_sampled": 16000, "num_steps_trained": 16000, "num_agent_steps_trained": 16000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 840, "training_iteration": 4, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-05-45", "timestamp": 1642601145, "time_this_iter_s": 10.646285057067871, "time_total_s": 43.0636031627655, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 43.0636031627655, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 46.18666666666666, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -12.6, "episode_reward_min": -85.69999999999999, "episode_reward_mean": -39.223113207547165, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.0, -27.700000000000006, -31.700000000000006, -84.5, -61.7, -28.699999999999996, -23.700000000000006, -31.700000000000003, -20.4, -33.0, -28.799999999999997, -27.700000000000006, -35.400000000000006, -29.2, -77.69999999999999, -78.3, -34.7, -27.700000000000006, -58.7, -52.2, -36.7, -31.700000000000006, -82.69999999999999, -20.7, -33.400000000000006, -76.3, -26.2, -20.700000000000003, -26.700000000000006, -23.700000000000003, -32.7, -24.700000000000003, -32.7, -30.700000000000006, -82.69999999999999, -78.7, -81.4, -35.7, -29.8, -82.6, -34.7, -81.69999999999999, -32.5, -15.699999999999998, -34.5, -33.0, -81.5, -34.7, -51.3, -37.2, -33.60000000000001, -34.7, -20.700000000000003, -27.700000000000006, -32.7, -18.3, -29.700000000000006, -22.700000000000003, -84.3, -35.70000000000001, -70.7, -28.700000000000006, -32.7, -26.4, -26.700000000000003, -26.700000000000003, -85.3, -63.8, -31.4, -33.5, -24.700000000000003, -35.70000000000001, -30.700000000000006, -41.2, -29.700000000000006, -74.7, -33.9, -35.7, -24.2, -28.700000000000006, -24.700000000000003, -27.700000000000003, -31.700000000000003, -46.7, -71.69999999999999, -25.700000000000006, -60.7, -59.7, -33.7, -22.5, -77.5, -23.700000000000003, -32.7, -35.6, -25.700000000000003, -34.9, -59.7, -29.700000000000006, -24.5, -33.7, -76.7, -23.8, -27.700000000000006, -24.700000000000003, -23.700000000000006, -83.69999999999999, -37.0, -33.60000000000001, -26.700000000000006, -31.5, -16.7, -81.69999999999999, -31.70000000000001, -24.700000000000003, -26.3, -35.60000000000001, -32.7, -61.7, -68.7, -28.2, -83.3, -24.700000000000003, -28.5, -31.700000000000006, -33.7, -25.700000000000006, -36.5, -40.7, -29.8, -22.700000000000003, -28.700000000000006, -34.1, -19.700000000000003, -79.69999999999999, -29.700000000000006, -79.69999999999999, -20.7, -26.700000000000006, -25.700000000000006, -34.0, -32.7, -30.700000000000006, -15.699999999999998, -23.299999999999997, -81.69999999999999, -24.099999999999998, -82.1, -31.700000000000003, -28.700000000000006, -28.299999999999997, -23.2, -25.7, -55.7, -28.700000000000006, -20.7, -85.69999999999999, -32.2, -21.700000000000003, -25.600000000000005, -32.7, -22.700000000000003, -26.700000000000006, -19.4, -28.700000000000006, -84.8, -27.700000000000006, -30.700000000000006, -23.799999999999997, -63.7, -25.700000000000006, -31.700000000000003, -30.400000000000002, -26.700000000000006, -32.60000000000001, -36.3, -78.69999999999999, -56.7, -25.700000000000006, -33.7, -32.4, -35.7, -19.599999999999998, -29.700000000000006, -83.69999999999999, -43.4, -19.8, -56.2, -33.9, -21.7, -58.6, -19.700000000000003, -83.69999999999999, -21.700000000000003, -62.0, -28.700000000000003, -22.700000000000003, -58.3, -33.7, -29.600000000000005, -73.8, -35.099999999999994, -30.700000000000006, -16.4, -17.7, -18.9, -34.70000000000001, -30.6, -27.700000000000006, -75.69999999999999, -31.5, -12.6, -74.19999999999999], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5052490460350616, "mean_inference_ms": 1.3493360149648232, "mean_action_processing_ms": 0.09671247522727511, "mean_env_wait_ms": 4.489018282540392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 20000, "timesteps_this_iter": 0, "agent_timesteps_total": 20000, "timers": {"sample_time_ms": 10381.448, "sample_throughput": 385.303, "load_time_ms": 0.322, "load_throughput": 12431250.741, "learn_time_ms": 2143.841, "learn_throughput": 1865.81, "update_time_ms": 2.188}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 378.2868957519531, "policy_loss": -0.028377460315823555, "vf_loss": 378.30548095703125, "vf_explained_var": -0.0011302756611257792, "kl": 0.01444487739354372, "entropy": 3.477672576904297, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 20000, "num_steps_trained": 20000, "num_agent_steps_trained": 20000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1052, "training_iteration": 5, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-05-56", "timestamp": 1642601156, "time_this_iter_s": 10.886619091033936, "time_total_s": 53.95022225379944, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 53.95022225379944, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 47.50625, "ram_util_percent": 62.2625}}
{"episode_reward_max": -14.699999999999998, "episode_reward_min": -83.69999999999999, "episode_reward_mean": -31.942307692307693, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.700000000000003, -29.6, -29.3, -24.700000000000006, -21.700000000000003, -30.700000000000006, -26.2, -30.700000000000006, -22.700000000000003, -27.4, -26.5, -33.2, -28.700000000000006, -19.7, -35.4, -23.700000000000006, -33.7, -35.5, -35.6, -22.700000000000003, -29.700000000000006, -48.7, -32.7, -34.7, -30.2, -29.700000000000003, -32.7, -25.700000000000006, -33.7, -28.700000000000006, -23.700000000000003, -20.700000000000003, -73.7, -17.7, -23.5, -33.7, -31.700000000000006, -27.700000000000006, -31.700000000000006, -28.700000000000003, -35.099999999999994, -80.69999999999999, -34.7, -34.7, -27.700000000000006, -23.700000000000003, -29.500000000000004, -20.700000000000003, -34.70000000000001, -19.700000000000003, -21.700000000000003, -22.3, -32.7, -30.700000000000003, -26.600000000000005, -25.700000000000006, -30.700000000000003, -29.700000000000003, -33.7, -34.7, -32.0, -34.7, -35.7, -25.099999999999998, -37.6, -29.700000000000006, -35.1, -23.700000000000003, -32.7, -25.700000000000006, -22.7, -40.7, -41.7, -23.700000000000006, -27.700000000000006, -22.7, -26.700000000000006, -23.4, -27.700000000000006, -37.5, -35.7, -58.7, -29.700000000000006, -44.7, -30.700000000000006, -30.2, -31.700000000000006, -33.7, -34.3, -57.7, -32.7, -23.700000000000003, -32.7, -33.3, -32.2, -26.700000000000003, -28.700000000000006, -39.5, -34.70000000000001, -28.700000000000006, -19.5, -25.700000000000003, -27.700000000000006, -19.499999999999996, -27.7, -32.8, -27.6, -17.7, -28.700000000000006, -36.3, -35.70000000000001, -34.7, -31.700000000000003, -33.7, -26.3, -35.7, -28.700000000000006, -26.700000000000006, -31.799999999999997, -28.600000000000005, -14.8, -27.4, -76.69999999999999, -22.700000000000003, -27.700000000000006, -27.700000000000006, -63.7, -24.700000000000003, -20.9, -27.9, -26.700000000000006, -30.7, -24.700000000000006, -34.60000000000001, -30.3, -23.700000000000006, -26.0, -16.6, -33.7, -22.700000000000003, -29.600000000000005, -27.700000000000006, -28.700000000000006, -19.700000000000006, -35.7, -30.0, -76.69999999999999, -31.700000000000006, -25.700000000000006, -29.700000000000006, -28.700000000000006, -32.3, -31.9, -53.5, -32.7, -35.3, -22.8, -28.700000000000006, -76.1, -26.700000000000006, -25.700000000000006, -28.600000000000005, -24.6, -30.700000000000006, -66.7, -33.7, -31.700000000000006, -34.8, -32.7, -28.7, -51.7, -23.700000000000003, -14.699999999999998, -35.7, -24.700000000000003, -27.700000000000003, -30.700000000000006, -80.69999999999999, -33.099999999999994, -31.700000000000003, -29.700000000000003, -30.700000000000006, -32.7, -33.70000000000001, -29.500000000000004, -28.700000000000006, -25.700000000000003, -26.4, -30.700000000000003, -30.700000000000006, -35.7, -83.69999999999999, -39.8, -31.700000000000006, -26.4, -25.700000000000006, -32.1, -23.700000000000003, -21.099999999999998, -33.7, -24.700000000000003, -30.700000000000006, -33.7, -28.700000000000006, -23.700000000000003, -82.4, -19.5, -33.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.477700224401076, "mean_inference_ms": 1.3403999588922986, "mean_action_processing_ms": 0.09602298340863379, "mean_env_wait_ms": 4.465782827108111, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 24000, "timesteps_this_iter": 0, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 10389.902, "sample_throughput": 384.989, "load_time_ms": 0.322, "load_throughput": 12418368.616, "learn_time_ms": 2120.914, "learn_throughput": 1885.979, "update_time_ms": 2.18}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 157.89776611328125, "policy_loss": -0.019333185628056526, "vf_loss": 157.9078826904297, "vf_explained_var": 0.15307585895061493, "kl": 0.013674341142177582, "entropy": 3.423088788986206, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 24000, "num_agent_steps_sampled": 24000, "num_steps_trained": 24000, "num_agent_steps_trained": 24000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1260, "training_iteration": 6, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-06-06", "timestamp": 1642601166, "time_this_iter_s": 10.23497486114502, "time_total_s": 64.18519711494446, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 64.18519711494446, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 46.56428571428571, "ram_util_percent": 62.20714285714288}}
{"episode_reward_max": -14.699999999999996, "episode_reward_min": -86.69999999999999, "episode_reward_mean": -32.805660377358485, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.700000000000006, -16.6, -59.8, -23.6, -29.9, -23.700000000000003, -27.600000000000005, -32.3, -70.2, -27.700000000000006, -36.7, -30.700000000000006, -29.700000000000006, -33.7, -27.700000000000006, -24.9, -33.7, -30.700000000000003, -25.0, -44.7, -31.700000000000003, -24.700000000000003, -30.700000000000006, -27.700000000000006, -23.700000000000003, -36.3, -24.700000000000006, -28.400000000000002, -29.4, -36.7, -30.70000000000001, -32.0, -50.7, -29.700000000000006, -41.6, -43.7, -86.69999999999999, -28.700000000000006, -26.700000000000006, -34.7, -71.2, -34.7, -30.700000000000006, -34.2, -33.60000000000001, -31.700000000000006, -24.700000000000006, -14.699999999999996, -31.700000000000006, -31.700000000000003, -27.199999999999996, -21.700000000000003, -25.700000000000006, -33.5, -32.7, -32.7, -29.700000000000006, -23.299999999999997, -30.2, -22.700000000000003, -35.70000000000001, -24.700000000000006, -26.700000000000006, -32.70000000000001, -24.600000000000005, -27.700000000000006, -33.7, -23.700000000000003, -19.7, -24.700000000000006, -49.7, -60.7, -29.70000000000001, -24.700000000000003, -32.7, -24.700000000000003, -56.0, -29.700000000000003, -33.7, -22.7, -30.700000000000006, -33.7, -34.7, -27.4, -31.700000000000006, -21.700000000000003, -28.3, -28.6, -75.7, -32.7, -28.700000000000006, -75.7, -30.2, -43.4, -22.700000000000003, -25.70000000000001, -36.7, -26.700000000000006, -29.700000000000006, -37.8, -40.7, -34.7, -21.6, -21.700000000000003, -25.700000000000003, -38.400000000000006, -78.6, -21.4, -34.7, -25.2, -23.1, -40.5, -34.7, -22.700000000000003, -29.700000000000006, -73.7, -25.5, -23.299999999999997, -22.700000000000003, -21.700000000000003, -26.700000000000006, -74.69999999999999, -18.700000000000003, -52.8, -34.7, -29.700000000000003, -29.3, -24.700000000000003, -34.70000000000001, -23.700000000000003, -33.7, -29.8, -21.2, -72.69999999999999, -39.7, -30.700000000000006, -27.600000000000005, -29.700000000000006, -37.7, -21.700000000000003, -29.4, -28.3, -32.7, -32.2, -22.700000000000006, -21.6, -49.7, -28.600000000000005, -44.7, -39.70000000000001, -32.3, -23.299999999999997, -24.700000000000006, -22.700000000000003, -83.69999999999999, -20.700000000000003, -26.700000000000006, -39.7, -25.4, -28.0, -21.700000000000003, -23.700000000000006, -79.4, -28.799999999999997, -31.700000000000003, -31.700000000000003, -33.4, -33.7, -56.7, -23.700000000000006, -31.700000000000006, -20.700000000000003, -35.099999999999994, -20.700000000000003, -35.4, -33.7, -31.6, -34.7, -27.700000000000003, -21.7, -31.600000000000005, -29.0, -28.9, -29.700000000000006, -26.700000000000003, -19.700000000000003, -32.60000000000001, -26.400000000000002, -32.7, -85.1, -37.7, -15.699999999999998, -28.700000000000006, -33.5, -60.7, -18.700000000000003, -25.6, -24.700000000000003, -30.700000000000003, -23.700000000000006, -25.6, -20.7, -36.0, -18.700000000000003, -27.700000000000006, -23.700000000000003, -22.700000000000006, -29.700000000000006, -31.700000000000003, -28.700000000000003, -34.7, -31.2], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.453954138767377, "mean_inference_ms": 1.323962914843233, "mean_action_processing_ms": 0.09494354138798655, "mean_env_wait_ms": 4.410437883061863, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 28000, "timesteps_this_iter": 0, "agent_timesteps_total": 28000, "timers": {"sample_time_ms": 10333.144, "sample_throughput": 387.104, "load_time_ms": 0.323, "load_throughput": 12396085.286, "learn_time_ms": 2098.168, "learn_throughput": 1906.425, "update_time_ms": 2.165}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 153.95228576660156, "policy_loss": -0.03169615939259529, "vf_loss": 153.9720001220703, "vf_explained_var": 0.3278285562992096, "kl": 0.017739344388246536, "entropy": 3.332003355026245, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 28000, "num_agent_steps_sampled": 28000, "num_steps_trained": 28000, "num_agent_steps_trained": 28000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1472, "training_iteration": 7, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-06-16", "timestamp": 1642601176, "time_this_iter_s": 9.92434573173523, "time_total_s": 74.10954284667969, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 74.10954284667969, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 44.15714285714285, "ram_util_percent": 62.200000000000024}}
{"episode_reward_max": -14.2, "episode_reward_min": -82.69999999999999, "episode_reward_mean": -29.026886792452828, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.6, -29.700000000000003, -20.4, -16.3, -36.7, -30.5, -32.7, -29.2, -19.199999999999996, -32.8, -27.700000000000006, -25.700000000000003, -33.5, -14.2, -23.700000000000006, -32.7, -24.2, -26.3, -27.700000000000003, -30.700000000000006, -21.700000000000003, -19.7, -22.799999999999997, -30.70000000000001, -30.700000000000006, -33.7, -17.7, -24.700000000000003, -22.4, -25.700000000000006, -31.500000000000007, -27.2, -34.7, -27.700000000000003, -30.700000000000006, -26.2, -31.700000000000006, -17.700000000000003, -29.700000000000003, -18.7, -23.700000000000003, -19.7, -34.7, -23.700000000000006, -31.700000000000003, -25.700000000000006, -28.500000000000004, -25.799999999999997, -22.700000000000003, -22.700000000000003, -27.700000000000006, -34.70000000000001, -28.700000000000006, -56.400000000000006, -23.700000000000003, -29.700000000000006, -21.4, -26.4, -28.0, -32.7, -29.700000000000006, -36.70000000000001, -26.700000000000003, -23.700000000000006, -29.700000000000006, -65.7, -18.7, -34.6, -29.70000000000001, -14.699999999999998, -25.700000000000006, -29.700000000000006, -23.700000000000003, -68.69999999999999, -17.700000000000003, -21.700000000000003, -34.7, -25.2, -26.700000000000003, -25.700000000000006, -33.400000000000006, -26.099999999999998, -25.700000000000006, -28.700000000000006, -24.700000000000003, -16.7, -50.5, -31.2, -26.400000000000002, -26.700000000000006, -33.7, -33.7, -22.6, -24.5, -20.2, -25.700000000000006, -34.7, -23.700000000000003, -25.700000000000006, -34.7, -30.700000000000003, -15.699999999999998, -28.700000000000006, -22.700000000000006, -29.700000000000006, -30.70000000000001, -37.4, -34.7, -26.700000000000003, -47.7, -28.700000000000006, -31.700000000000006, -30.700000000000006, -34.7, -27.700000000000006, -21.299999999999997, -35.6, -19.3, -17.7, -38.70000000000001, -28.500000000000004, -30.600000000000005, -81.9, -25.700000000000006, -35.70000000000001, -20.7, -21.799999999999997, -20.700000000000003, -31.700000000000006, -27.099999999999998, -23.2, -23.9, -27.700000000000006, -30.700000000000006, -51.8, -32.6, -30.4, -19.3, -29.700000000000006, -20.700000000000003, -27.700000000000003, -26.5, -29.700000000000006, -26.700000000000006, -29.700000000000006, -20.700000000000003, -31.6, -33.7, -17.2, -20.700000000000003, -19.5, -26.700000000000006, -29.700000000000006, -82.69999999999999, -27.700000000000006, -23.700000000000003, -28.700000000000006, -21.700000000000003, -36.7, -35.70000000000001, -30.5, -19.5, -32.7, -35.7, -26.2, -22.700000000000006, -27.3, -28.700000000000006, -28.700000000000006, -25.700000000000003, -24.700000000000003, -33.7, -35.0, -26.700000000000006, -27.700000000000006, -30.700000000000006, -26.700000000000003, -27.199999999999996, -20.700000000000003, -24.2, -34.7, -31.700000000000003, -34.8, -29.700000000000006, -36.70000000000001, -33.3, -77.2, -24.0, -31.700000000000003, -21.700000000000003, -28.700000000000006, -24.700000000000003, -36.8, -17.4, -23.700000000000003, -19.1, -31.700000000000006, -30.7, -29.700000000000006, -33.3, -36.7, -26.700000000000006, -24.9, -23.700000000000006, -26.700000000000003, -33.7, -36.5, -32.4, -32.7, -18.7, -23.700000000000003, -30.700000000000006], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4364369762731997, "mean_inference_ms": 1.314758218954301, "mean_action_processing_ms": 0.09428817113478949, "mean_env_wait_ms": 4.384119649810087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 32000, "timesteps_this_iter": 0, "agent_timesteps_total": 32000, "timers": {"sample_time_ms": 10295.926, "sample_throughput": 388.503, "load_time_ms": 0.323, "load_throughput": 12376000.738, "learn_time_ms": 2093.421, "learn_throughput": 1910.748, "update_time_ms": 2.153}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 83.70591735839844, "policy_loss": -0.030574973672628403, "vf_loss": 83.72554779052734, "vf_explained_var": 0.4384247362613678, "kl": 0.016213376075029373, "entropy": 3.2154297828674316, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 32000, "num_agent_steps_sampled": 32000, "num_steps_trained": 32000, "num_agent_steps_trained": 32000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1684, "training_iteration": 8, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-06-26", "timestamp": 1642601186, "time_this_iter_s": 10.10865306854248, "time_total_s": 84.21819591522217, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 84.21819591522217, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 44.699999999999996, "ram_util_percent": 62.200000000000024}}
{"episode_reward_max": -13.699999999999998, "episode_reward_min": -83.69999999999999, "episode_reward_mean": -27.361538461538466, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.7, -16.599999999999998, -25.700000000000006, -28.0, -22.700000000000003, -14.699999999999998, -26.700000000000006, -22.4, -23.8, -28.1, -18.7, -24.700000000000003, -20.700000000000003, -29.700000000000006, -20.700000000000003, -24.700000000000003, -32.3, -59.7, -31.6, -23.700000000000003, -23.8, -31.700000000000006, -27.700000000000006, -29.4, -29.700000000000003, -20.700000000000003, -15.699999999999998, -32.7, -17.7, -27.700000000000006, -28.700000000000006, -26.5, -29.799999999999997, -38.300000000000004, -32.7, -25.700000000000006, -31.700000000000006, -29.70000000000001, -30.700000000000006, -26.5, -25.700000000000006, -22.700000000000003, -24.700000000000003, -31.700000000000006, -21.700000000000003, -23.700000000000003, -36.7, -26.700000000000006, -34.4, -31.700000000000006, -26.700000000000006, -29.3, -21.400000000000002, -20.700000000000003, -20.8, -27.4, -23.700000000000003, -29.3, -35.2, -22.700000000000006, -29.3, -33.7, -25.700000000000003, -21.700000000000003, -30.700000000000006, -29.700000000000006, -24.700000000000003, -24.700000000000003, -19.700000000000003, -20.700000000000003, -32.3, -25.799999999999997, -32.0, -33.70000000000001, -22.700000000000003, -22.600000000000005, -23.700000000000006, -19.700000000000006, -21.7, -83.69999999999999, -20.2, -23.199999999999996, -22.700000000000003, -29.7, -25.700000000000006, -16.2, -23.8, -26.700000000000003, -34.70000000000001, -34.7, -26.700000000000006, -23.700000000000003, -23.700000000000006, -30.700000000000006, -49.6, -28.600000000000005, -25.700000000000006, -25.700000000000003, -25.700000000000003, -21.700000000000003, -33.7, -30.700000000000006, -29.700000000000003, -18.700000000000003, -24.4, -23.700000000000003, -29.60000000000001, -35.5, -16.3, -21.3, -28.700000000000006, -30.5, -34.2, -31.700000000000006, -30.700000000000006, -23.9, -22.700000000000003, -22.700000000000003, -26.700000000000006, -21.700000000000003, -28.600000000000005, -25.700000000000006, -23.700000000000006, -26.700000000000006, -18.7, -18.7, -20.0, -22.700000000000003, -36.0, -33.7, -26.700000000000003, -31.3, -19.099999999999998, -27.2, -22.2, -26.5, -33.7, -23.2, -31.700000000000006, -22.1, -31.700000000000006, -29.700000000000003, -22.700000000000003, -29.700000000000006, -32.7, -32.8, -32.7, -34.2, -23.700000000000003, -27.700000000000006, -24.9, -35.70000000000001, -27.3, -27.700000000000006, -20.3, -29.6, -23.700000000000003, -31.700000000000006, -20.7, -25.700000000000003, -27.7, -31.700000000000006, -19.700000000000003, -24.4, -25.3, -24.700000000000003, -27.700000000000006, -32.8, -33.7, -20.700000000000006, -34.7, -23.5, -28.700000000000003, -45.6, -33.5, -23.700000000000003, -25.500000000000004, -24.700000000000006, -24.700000000000006, -30.6, -34.9, -29.2, -25.70000000000001, -20.7, -26.700000000000003, -33.5, -19.7, -29.700000000000006, -31.700000000000006, -28.700000000000003, -16.7, -30.8, -27.700000000000006, -31.700000000000006, -23.9, -17.700000000000003, -24.6, -34.70000000000001, -28.700000000000003, -33.8, -32.8, -37.8, -36.400000000000006, -21.6, -31.700000000000006, -13.699999999999998, -23.299999999999997, -18.499999999999996], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.439677913961589, "mean_inference_ms": 1.3225408358489679, "mean_action_processing_ms": 0.0948253611354957, "mean_env_wait_ms": 4.412448534686331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 36000, "timesteps_this_iter": 0, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 10370.123, "sample_throughput": 385.723, "load_time_ms": 0.326, "load_throughput": 12281003.985, "learn_time_ms": 2142.444, "learn_throughput": 1867.026, "update_time_ms": 2.26}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 49.285316467285156, "policy_loss": -0.019511865451931953, "vf_loss": 49.296958923339844, "vf_explained_var": 0.49115344882011414, "kl": 0.011665524914860725, "entropy": 3.167145252227783, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 36000, "num_agent_steps_sampled": 36000, "num_steps_trained": 36000, "num_agent_steps_trained": 36000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1892, "training_iteration": 9, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-06-38", "timestamp": 1642601198, "time_this_iter_s": 11.413633108139038, "time_total_s": 95.6318290233612, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 95.6318290233612, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 52.18125, "ram_util_percent": 62.05}}
{"episode_reward_max": -12.699999999999998, "episode_reward_min": -80.69999999999999, "episode_reward_mean": -27.024999999999995, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.700000000000006, -15.599999999999996, -33.3, -15.8, -33.7, -15.699999999999998, -29.700000000000006, -20.700000000000006, -21.7, -60.3, -25.700000000000006, -34.7, -30.2, -33.7, -26.2, -23.600000000000005, -31.4, -24.700000000000003, -22.700000000000003, -25.700000000000006, -33.7, -29.700000000000006, -25.9, -31.700000000000006, -21.7, -25.2, -17.7, -33.7, -26.700000000000006, -27.700000000000003, -26.700000000000006, -18.3, -27.700000000000006, -78.69999999999999, -23.6, -29.700000000000006, -24.4, -32.70000000000001, -26.700000000000006, -28.6, -30.700000000000006, -12.699999999999998, -80.69999999999999, -22.700000000000006, -26.700000000000006, -32.7, -27.700000000000006, -24.700000000000003, -13.7, -27.700000000000006, -28.70000000000001, -19.7, -23.700000000000003, -25.700000000000006, -25.700000000000006, -23.3, -22.700000000000003, -50.7, -15.699999999999998, -26.700000000000006, -35.7, -28.600000000000005, -17.7, -23.700000000000003, -19.5, -23.700000000000003, -25.700000000000006, -32.7, -24.700000000000003, -29.700000000000006, -80.69999999999999, -21.700000000000006, -26.700000000000003, -22.8, -31.700000000000003, -22.700000000000003, -22.7, -27.2, -24.700000000000003, -33.7, -21.700000000000003, -20.700000000000006, -24.700000000000003, -24.700000000000006, -25.700000000000006, -24.700000000000006, -19.7, -22.700000000000003, -79.3, -25.700000000000006, -21.700000000000003, -20.700000000000003, -27.70000000000001, -27.700000000000006, -26.600000000000005, -24.2, -27.700000000000006, -30.6, -79.69999999999999, -22.700000000000003, -34.7, -23.700000000000003, -34.7, -27.700000000000006, -28.7, -19.3, -24.700000000000006, -19.700000000000003, -28.700000000000006, -20.700000000000003, -23.700000000000003, -25.700000000000006, -25.700000000000003, -35.7, -27.3, -27.700000000000006, -33.7, -28.70000000000001, -25.700000000000003, -21.6, -14.699999999999998, -27.700000000000006, -19.2, -25.4, -25.700000000000006, -21.700000000000006, -23.700000000000003, -26.600000000000005, -27.600000000000005, -23.700000000000003, -31.70000000000001, -26.700000000000006, -30.700000000000006, -24.700000000000003, -27.700000000000006, -20.8, -20.700000000000003, -20.700000000000003, -32.7, -27.700000000000003, -25.700000000000006, -29.9, -21.700000000000003, -13.4, -31.700000000000006, -17.699999999999996, -18.7, -20.700000000000003, -18.6, -18.7, -24.700000000000003, -22.700000000000003, -34.70000000000001, -26.700000000000006, -18.4, -14.699999999999998, -27.70000000000001, -26.700000000000006, -26.700000000000003, -28.700000000000006, -24.700000000000006, -33.7, -22.700000000000003, -32.7, -54.7, -22.700000000000006, -22.700000000000003, -22.700000000000003, -23.700000000000003, -21.700000000000003, -28.2, -20.700000000000003, -32.7, -19.700000000000003, -24.700000000000003, -28.699999999999996, -23.700000000000003, -26.700000000000006, -24.700000000000006, -21.7, -24.700000000000006, -24.700000000000003, -20.5, -21.700000000000003, -30.700000000000006, -19.7, -25.700000000000006, -20.700000000000003, -22.700000000000003, -26.700000000000006, -21.0, -20.7, -22.9, -27.700000000000006, -21.700000000000003, -22.700000000000006, -28.700000000000006, -25.700000000000003, -31.2, -18.7, -20.700000000000003, -21.700000000000006, -28.700000000000006, -24.700000000000003, -25.199999999999996, -22.700000000000003, -25.2, -21.700000000000003, -27.700000000000003, -75.2, -18.700000000000003, -20.700000000000003], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.444805794746301, "mean_inference_ms": 1.3237437621651504, "mean_action_processing_ms": 0.09499474318429668, "mean_env_wait_ms": 4.418907386280871, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 40000, "timesteps_this_iter": 0, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 10451.005, "sample_throughput": 382.738, "load_time_ms": 0.326, "load_throughput": 12256879.018, "learn_time_ms": 2188.051, "learn_throughput": 1828.111, "update_time_ms": 2.306}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 90.09966278076172, "policy_loss": -0.019884441047906876, "vf_loss": 90.11116790771484, "vf_explained_var": 0.39184513688087463, "kl": 0.012418613769114017, "entropy": 3.097081184387207, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 40000, "num_steps_trained": 40000, "num_agent_steps_trained": 40000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2104, "training_iteration": 10, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-06-49", "timestamp": 1642601209, "time_this_iter_s": 11.211330890655518, "time_total_s": 106.84315991401672, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 106.84315991401672, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 50.1875, "ram_util_percent": 62.3875}}
{"episode_reward_max": -10.7, "episode_reward_min": -58.5, "episode_reward_mean": -24.21105769230769, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.7, -25.700000000000003, -24.700000000000003, -19.7, -20.6, -20.700000000000003, -23.700000000000006, -25.700000000000003, -24.700000000000003, -22.700000000000003, -22.700000000000003, -23.700000000000006, -23.700000000000003, -30.500000000000004, -28.2, -19.0, -12.699999999999998, -17.7, -26.3, -24.700000000000003, -25.7, -13.699999999999998, -25.700000000000006, -26.700000000000006, -13.699999999999998, -22.700000000000003, -23.4, -19.6, -24.700000000000006, -26.700000000000006, -24.700000000000006, -19.7, -19.1, -31.700000000000003, -27.700000000000006, -32.7, -22.700000000000003, -23.700000000000003, -26.5, -19.7, -30.300000000000004, -26.700000000000006, -23.700000000000006, -25.700000000000006, -25.299999999999997, -26.700000000000006, -24.700000000000006, -18.0, -22.4, -27.700000000000006, -23.700000000000003, -26.0, -26.700000000000003, -25.700000000000006, -24.700000000000003, -22.7, -28.700000000000006, -20.7, -15.699999999999996, -38.0, -23.700000000000003, -22.0, -27.700000000000003, -21.700000000000003, -23.700000000000003, -24.700000000000006, -21.700000000000003, -22.700000000000003, -33.7, -21.700000000000003, -23.700000000000003, -23.700000000000003, -19.5, -22.700000000000003, -26.4, -21.700000000000003, -21.700000000000003, -19.7, -19.7, -16.699999999999996, -20.4, -22.700000000000006, -14.699999999999998, -33.7, -24.199999999999996, -30.700000000000006, -22.700000000000003, -25.700000000000003, -23.500000000000004, -24.700000000000003, -19.700000000000006, -24.600000000000005, -25.700000000000003, -20.6, -15.699999999999998, -24.700000000000003, -21.700000000000003, -19.700000000000003, -17.7, -25.4, -20.6, -14.699999999999998, -21.7, -24.3, -27.700000000000003, -21.700000000000003, -26.700000000000006, -34.7, -17.7, -30.700000000000006, -30.6, -26.700000000000006, -58.5, -29.6, -24.700000000000003, -20.5, -21.9, -22.7, -23.700000000000003, -21.5, -22.700000000000003, -32.7, -29.700000000000006, -25.700000000000006, -27.700000000000006, -31.700000000000006, -26.700000000000006, -23.700000000000003, -21.2, -23.700000000000003, -29.700000000000006, -21.700000000000003, -23.700000000000003, -24.700000000000006, -39.7, -20.5, -27.700000000000006, -22.700000000000003, -24.700000000000003, -28.9, -32.5, -25.799999999999997, -25.700000000000003, -23.700000000000003, -25.700000000000003, -33.7, -22.700000000000003, -25.700000000000003, -27.2, -18.7, -23.700000000000006, -25.600000000000005, -24.700000000000006, -27.700000000000006, -24.5, -15.7, -26.700000000000006, -20.700000000000003, -31.700000000000003, -24.2, -23.3, -29.700000000000003, -19.700000000000003, -29.700000000000006, -22.4, -24.700000000000003, -22.700000000000003, -28.700000000000006, -19.5, -31.700000000000006, -15.699999999999998, -20.700000000000006, -31.700000000000006, -17.7, -28.500000000000004, -29.700000000000006, -22.700000000000006, -23.700000000000003, -31.5, -19.7, -21.700000000000006, -28.700000000000006, -18.7, -19.700000000000003, -21.700000000000003, -22.700000000000003, -21.700000000000003, -29.700000000000006, -15.699999999999998, -21.1, -29.700000000000006, -16.7, -23.700000000000003, -20.700000000000003, -10.7, -21.700000000000003, -22.700000000000003, -26.700000000000006, -19.2, -27.700000000000003, -21.700000000000006, -27.700000000000006, -34.7, -16.7, -20.700000000000003, -30.700000000000006, -21.4, -20.700000000000003], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.445543709586679, "mean_inference_ms": 1.3244821151682773, "mean_action_processing_ms": 0.09494507901181572, "mean_env_wait_ms": 4.414885854213934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 44000, "timesteps_this_iter": 0, "agent_timesteps_total": 44000, "timers": {"sample_time_ms": 10740.251, "sample_throughput": 372.431, "load_time_ms": 0.345, "load_throughput": 11599292.035, "learn_time_ms": 2237.326, "learn_throughput": 1787.849, "update_time_ms": 2.37}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 29.700000762939453, "policy_loss": -0.033190011978149414, "vf_loss": 29.724512100219727, "vf_explained_var": 0.5267314910888672, "kl": 0.012851590290665627, "entropy": 3.072728157043457, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 44000, "num_agent_steps_sampled": 44000, "num_steps_trained": 44000, "num_agent_steps_trained": 44000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2312, "training_iteration": 11, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-00", "timestamp": 1642601220, "time_this_iter_s": 11.31701397895813, "time_total_s": 118.16017389297485, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 118.16017389297485, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 50.94375, "ram_util_percent": 62.39375}}
{"episode_reward_max": -10.699999999999998, "episode_reward_min": -52.2, "episode_reward_mean": -22.722641509433956, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.7, -30.700000000000006, -24.700000000000006, -24.700000000000003, -24.700000000000006, -23.9, -23.700000000000006, -26.700000000000006, -19.7, -18.700000000000003, -12.7, -25.700000000000003, -23.700000000000006, -25.700000000000006, -20.7, -17.7, -24.700000000000006, -24.700000000000006, -14.3, -17.7, -19.7, -24.700000000000003, -34.099999999999994, -22.5, -14.699999999999998, -32.7, -22.4, -23.700000000000003, -20.700000000000003, -18.8, -30.700000000000006, -23.3, -33.70000000000001, -19.7, -22.700000000000006, -20.7, -23.700000000000003, -16.599999999999994, -21.2, -19.7, -19.7, -20.700000000000006, -20.7, -20.700000000000003, -16.699999999999996, -24.700000000000003, -24.700000000000006, -24.700000000000003, -19.700000000000006, -18.700000000000003, -32.9, -18.7, -24.700000000000006, -24.700000000000006, -19.700000000000003, -36.7, -19.7, -17.7, -25.700000000000003, -32.7, -22.700000000000006, -22.700000000000003, -20.2, -22.700000000000003, -21.700000000000003, -30.700000000000006, -17.7, -23.6, -31.699999999999996, -26.700000000000006, -14.1, -21.700000000000003, -23.700000000000003, -20.700000000000003, -16.8, -27.2, -24.5, -10.699999999999998, -27.700000000000006, -20.700000000000003, -22.700000000000003, -20.700000000000003, -18.5, -20.700000000000003, -17.7, -13.699999999999998, -23.6, -15.699999999999998, -17.699999999999996, -52.2, -19.2, -25.700000000000006, -19.700000000000003, -19.7, -20.700000000000003, -28.700000000000006, -12.2, -15.3, -28.700000000000006, -21.700000000000003, -29.500000000000004, -15.699999999999996, -29.6, -18.4, -27.700000000000006, -36.70000000000001, -23.7, -23.700000000000003, -22.700000000000003, -17.7, -15.599999999999998, -20.7, -22.700000000000003, -16.7, -22.700000000000003, -15.699999999999996, -22.7, -30.600000000000005, -19.700000000000003, -32.4, -24.700000000000006, -20.700000000000006, -22.3, -28.700000000000003, -24.5, -23.4, -22.700000000000006, -21.700000000000006, -23.700000000000003, -21.700000000000003, -20.700000000000003, -22.700000000000003, -28.3, -21.7, -23.700000000000006, -22.700000000000003, -23.700000000000006, -13.699999999999998, -24.700000000000003, -20.700000000000003, -25.700000000000006, -19.700000000000003, -34.7, -37.7, -20.700000000000003, -20.700000000000003, -22.700000000000003, -18.9, -19.7, -12.699999999999998, -15.699999999999998, -23.700000000000003, -19.700000000000003, -28.700000000000006, -27.799999999999997, -20.700000000000006, -27.700000000000006, -20.6, -14.699999999999996, -16.699999999999996, -16.6, -21.700000000000003, -23.700000000000003, -24.700000000000003, -21.700000000000003, -26.700000000000006, -23.700000000000006, -19.7, -26.700000000000006, -22.700000000000003, -19.700000000000003, -24.700000000000003, -20.700000000000003, -22.700000000000006, -26.700000000000003, -18.9, -14.699999999999998, -28.700000000000003, -21.700000000000003, -26.700000000000006, -25.5, -22.700000000000003, -18.700000000000003, -28.700000000000006, -24.700000000000003, -16.599999999999998, -28.700000000000006, -20.6, -23.700000000000003, -12.699999999999998, -19.700000000000003, -24.700000000000003, -25.700000000000003, -28.700000000000003, -22.600000000000005, -27.700000000000006, -31.700000000000006, -15.699999999999998, -20.700000000000006, -17.7, -21.700000000000003, -15.699999999999998, -22.6, -28.700000000000006, -23.700000000000006, -31.700000000000006, -20.700000000000003, -18.2, -15.699999999999998, -35.7, -18.700000000000003, -24.700000000000003], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4246026124470275, "mean_inference_ms": 1.3138816988614193, "mean_action_processing_ms": 0.09422042590162673, "mean_env_wait_ms": 4.383735413968924, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 48000, "timesteps_this_iter": 0, "agent_timesteps_total": 48000, "timers": {"sample_time_ms": 10624.416, "sample_throughput": 376.491, "load_time_ms": 0.346, "load_throughput": 11545809.648, "learn_time_ms": 2259.961, "learn_throughput": 1769.942, "update_time_ms": 2.406}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 31.689315795898438, "policy_loss": -0.030509356409311295, "vf_loss": 31.710451126098633, "vf_explained_var": 0.44602078199386597, "kl": 0.013887007720768452, "entropy": 3.032744884490967, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 48000, "num_agent_steps_sampled": 48000, "num_steps_trained": 48000, "num_agent_steps_trained": 48000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2524, "training_iteration": 12, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-10", "timestamp": 1642601230, "time_this_iter_s": 10.12149977684021, "time_total_s": 128.28167366981506, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 128.28167366981506, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 46.63999999999999, "ram_util_percent": 62.15333333333334}}
{"episode_reward_max": -6.699999999999999, "episode_reward_min": -81.5, "episode_reward_mean": -21.185377358490562, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.7, -20.700000000000003, -19.1, -24.700000000000003, -17.7, -14.699999999999996, -13.699999999999998, -20.7, -24.5, -21.6, -13.699999999999998, -21.7, -12.699999999999998, -21.2, -16.7, -20.7, -22.1, -28.8, -14.999999999999998, -21.700000000000003, -19.700000000000003, -22.700000000000003, -31.700000000000006, -29.700000000000006, -23.6, -25.700000000000006, -23.700000000000003, -12.7, -13.699999999999998, -15.599999999999996, -15.699999999999998, -37.7, -24.700000000000006, -21.700000000000003, -22.700000000000006, -17.7, -20.700000000000003, -24.3, -11.699999999999998, -13.199999999999998, -15.699999999999996, -34.7, -20.7, -15.699999999999996, -11.699999999999998, -22.700000000000003, -17.700000000000003, -16.7, -19.700000000000003, -19.7, -22.700000000000003, -24.600000000000005, -21.700000000000003, -30.700000000000003, -28.700000000000003, -15.1, -16.7, -14.699999999999998, -13.699999999999996, -20.700000000000003, -23.700000000000003, -13.499999999999996, -22.700000000000006, -18.7, -13.699999999999998, -16.7, -20.7, -23.700000000000003, -21.4, -18.6, -23.700000000000006, -14.8, -15.699999999999998, -31.700000000000003, -31.700000000000006, -19.7, -20.700000000000003, -18.7, -81.5, -16.7, -22.700000000000003, -20.700000000000006, -20.700000000000003, -28.600000000000005, -21.7, -23.6, -13.4, -21.199999999999996, -19.0, -23.700000000000006, -16.7, -16.299999999999997, -20.700000000000003, -13.4, -21.700000000000003, -26.4, -21.7, -25.700000000000003, -23.700000000000006, -24.700000000000006, -19.599999999999998, -29.700000000000006, -19.700000000000003, -21.700000000000003, -22.700000000000003, -18.700000000000003, -24.700000000000006, -37.7, -13.599999999999998, -17.7, -21.700000000000006, -18.7, -22.7, -15.499999999999996, -26.7, -24.700000000000006, -20.700000000000006, -20.700000000000003, -19.700000000000003, -16.7, -31.700000000000006, -15.699999999999998, -22.700000000000003, -23.0, -20.3, -14.399999999999999, -33.7, -17.7, -24.700000000000003, -19.7, -14.7, -13.699999999999996, -16.700000000000003, -23.7, -14.499999999999998, -12.699999999999998, -15.699999999999998, -20.7, -22.700000000000003, -23.700000000000003, -24.700000000000003, -18.2, -27.700000000000003, -26.700000000000006, -18.700000000000006, -23.700000000000003, -9.7, -14.699999999999996, -19.7, -23.7, -20.700000000000006, -18.6, -27.700000000000006, -25.700000000000003, -24.700000000000006, -25.700000000000003, -23.700000000000003, -16.7, -30.700000000000006, -27.7, -13.699999999999996, -20.3, -23.700000000000003, -21.700000000000006, -16.3, -20.0, -22.2, -15.699999999999998, -16.7, -20.5, -15.699999999999996, -19.6, -21.700000000000006, -18.799999999999997, -47.2, -20.700000000000003, -20.700000000000003, -19.7, -22.700000000000006, -22.7, -13.699999999999998, -23.700000000000003, -21.700000000000003, -14.699999999999996, -24.700000000000003, -26.600000000000005, -20.7, -13.699999999999998, -30.700000000000006, -17.7, -19.7, -25.700000000000006, -18.0, -18.7, -65.7, -21.700000000000003, -13.699999999999998, -22.700000000000003, -6.699999999999999, -14.3, -22.700000000000006, -18.7, -19.700000000000003, -17.2, -18.700000000000006, -12.399999999999999, -30.700000000000006, -16.7, -14.699999999999998, -25.700000000000006, -25.700000000000006, -15.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.408381306513503, "mean_inference_ms": 1.3015921615965593, "mean_action_processing_ms": 0.09342760097502781, "mean_env_wait_ms": 4.343965541178534, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 52000, "timesteps_this_iter": 0, "agent_timesteps_total": 52000, "timers": {"sample_time_ms": 10558.992, "sample_throughput": 378.824, "load_time_ms": 0.351, "load_throughput": 11395242.817, "learn_time_ms": 2317.58, "learn_throughput": 1725.939, "update_time_ms": 2.441}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 53.602359771728516, "policy_loss": -0.027270298451185226, "vf_loss": 53.62025451660156, "vf_explained_var": 0.34114983677864075, "kl": 0.013890810310840607, "entropy": 2.9540538787841797, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 52000, "num_agent_steps_sampled": 52000, "num_steps_trained": 52000, "num_agent_steps_trained": 52000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2736, "training_iteration": 13, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-20", "timestamp": 1642601240, "time_this_iter_s": 9.968537092208862, "time_total_s": 138.25021076202393, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 138.25021076202393, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 46.11428571428571, "ram_util_percent": 62.15000000000002}}
{"episode_reward_max": -8.699999999999998, "episode_reward_min": -54.4, "episode_reward_mean": -19.323076923076922, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.699999999999998, -27.700000000000006, -20.700000000000003, -18.700000000000003, -13.699999999999998, -24.700000000000003, -15.699999999999996, -24.700000000000006, -10.7, -18.7, -23.3, -15.699999999999996, -15.699999999999998, -17.599999999999998, -23.700000000000003, -16.699999999999996, -22.700000000000003, -17.6, -22.700000000000003, -20.6, -15.699999999999998, -28.700000000000003, -29.7, -29.700000000000006, -23.700000000000003, -24.700000000000003, -19.7, -17.7, -18.2, -11.9, -17.7, -17.599999999999998, -12.699999999999998, -13.699999999999996, -24.700000000000006, -16.699999999999996, -27.1, -16.299999999999997, -20.2, -19.7, -15.699999999999998, -15.699999999999996, -20.7, -17.7, -24.600000000000005, -20.700000000000003, -22.700000000000003, -25.700000000000003, -15.699999999999998, -13.699999999999998, -13.599999999999998, -17.700000000000003, -28.700000000000006, -17.7, -17.7, -22.700000000000003, -18.7, -14.699999999999998, -17.7, -25.700000000000006, -14.699999999999998, -39.7, -27.700000000000006, -24.700000000000006, -21.700000000000003, -19.700000000000003, -14.6, -16.7, -18.7, -17.7, -26.700000000000003, -12.699999999999998, -24.700000000000003, -13.599999999999998, -16.7, -17.700000000000003, -17.7, -18.7, -12.299999999999999, -24.700000000000006, -17.7, -22.700000000000003, -17.7, -21.700000000000006, -14.3, -18.700000000000003, -25.700000000000006, -21.700000000000003, -27.5, -9.7, -17.7, -26.699999999999996, -25.700000000000006, -14.699999999999998, -20.700000000000003, -16.7, -16.7, -29.700000000000006, -20.700000000000003, -8.699999999999998, -15.699999999999998, -14.599999999999998, -24.700000000000003, -16.7, -17.7, -21.700000000000003, -14.699999999999996, -18.7, -17.7, -19.700000000000003, -17.7, -19.7, -23.7, -18.7, -17.4, -54.4, -16.699999999999996, -11.699999999999998, -13.699999999999996, -20.7, -17.6, -20.700000000000003, -14.699999999999998, -13.1, -15.699999999999998, -16.7, -19.700000000000003, -16.7, -19.7, -28.4, -12.2, -21.700000000000003, -12.699999999999998, -12.699999999999998, -17.700000000000003, -25.799999999999997, -18.7, -14.699999999999998, -14.499999999999998, -10.599999999999998, -18.7, -22.700000000000006, -16.699999999999996, -26.700000000000006, -22.3, -18.700000000000003, -14.699999999999998, -13.699999999999998, -19.7, -17.599999999999998, -12.699999999999998, -20.5, -17.599999999999998, -19.3, -22.700000000000003, -22.700000000000003, -11.699999999999998, -25.700000000000003, -17.700000000000003, -19.7, -13.9, -22.700000000000003, -19.3, -14.699999999999998, -21.7, -25.700000000000003, -22.700000000000003, -10.7, -19.700000000000003, -18.7, -15.699999999999996, -16.699999999999996, -21.700000000000003, -32.7, -16.7, -24.3, -23.700000000000003, -34.7, -23.700000000000003, -17.7, -15.2, -16.7, -15.600000000000001, -28.700000000000006, -19.7, -17.5, -13.600000000000001, -23.700000000000006, -16.7, -16.699999999999996, -17.699999999999996, -17.7, -20.700000000000006, -14.599999999999996, -20.7, -11.699999999999998, -12.699999999999998, -16.3, -21.700000000000006, -21.700000000000003, -11.699999999999998, -23.700000000000006, -20.700000000000003, -18.700000000000003, -16.4, -18.3, -18.7, -14.599999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3895609371151787, "mean_inference_ms": 1.2905883172624206, "mean_action_processing_ms": 0.0926776533765066, "mean_env_wait_ms": 4.311226055576294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 56000, "timesteps_this_iter": 0, "agent_timesteps_total": 56000, "timers": {"sample_time_ms": 10514.174, "sample_throughput": 380.439, "load_time_ms": 0.349, "load_throughput": 11467680.109, "learn_time_ms": 2379.586, "learn_throughput": 1680.965, "update_time_ms": 2.39}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 31.4915828704834, "policy_loss": -0.03862506151199341, "vf_loss": 31.520578384399414, "vf_explained_var": 0.33912718296051025, "kl": 0.014265792444348335, "entropy": 2.88974928855896, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 56000, "num_agent_steps_sampled": 56000, "num_steps_trained": 56000, "num_agent_steps_trained": 56000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2944, "training_iteration": 14, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-31", "timestamp": 1642601251, "time_this_iter_s": 10.240345239639282, "time_total_s": 148.4905560016632, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 148.4905560016632, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 49.62666666666667, "ram_util_percent": 62.30666666666666}}
{"episode_reward_max": -9.2, "episode_reward_min": -35.7, "episode_reward_mean": -18.359905660377358, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.700000000000006, -29.700000000000006, -15.699999999999998, -19.700000000000003, -17.699999999999996, -13.699999999999996, -22.700000000000003, -20.700000000000003, -15.699999999999998, -12.699999999999996, -12.699999999999996, -24.2, -19.5, -20.7, -10.699999999999998, -20.700000000000003, -21.4, -15.2, -23.3, -13.699999999999996, -19.9, -19.700000000000003, -30.700000000000006, -18.6, -9.699999999999998, -22.700000000000003, -19.700000000000003, -10.699999999999998, -12.699999999999998, -11.699999999999998, -19.700000000000003, -22.4, -12.699999999999998, -17.7, -14.699999999999996, -18.7, -10.699999999999998, -18.700000000000003, -26.700000000000006, -19.7, -13.699999999999998, -13.3, -18.7, -16.7, -19.3, -19.700000000000003, -22.700000000000003, -11.699999999999998, -20.3, -17.7, -18.7, -14.5, -31.700000000000006, -18.7, -18.7, -20.700000000000003, -12.699999999999998, -17.7, -20.6, -18.7, -20.0, -16.7, -26.6, -16.599999999999998, -16.699999999999996, -19.2, -13.599999999999998, -27.700000000000006, -20.6, -22.700000000000003, -26.5, -15.399999999999999, -19.7, -11.699999999999998, -19.700000000000003, -16.4, -12.699999999999998, -27.700000000000003, -13.2, -11.2, -24.099999999999998, -16.7, -16.7, -11.699999999999998, -19.0, -12.699999999999998, -22.2, -18.0, -10.499999999999996, -20.700000000000003, -19.7, -22.700000000000006, -14.699999999999996, -18.6, -18.700000000000003, -19.700000000000003, -18.3, -18.7, -22.2, -25.700000000000006, -14.699999999999998, -12.699999999999998, -22.700000000000003, -21.8, -14.699999999999998, -16.7, -31.700000000000003, -15.699999999999998, -18.7, -15.699999999999998, -24.700000000000003, -18.0, -16.7, -17.7, -12.699999999999998, -21.7, -9.9, -18.3, -10.699999999999998, -20.7, -22.700000000000003, -13.699999999999998, -15.699999999999998, -21.700000000000003, -18.7, -13.4, -16.299999999999997, -13.699999999999998, -18.7, -16.3, -20.700000000000003, -21.700000000000003, -19.7, -17.700000000000003, -27.700000000000006, -14.699999999999998, -13.5, -18.7, -19.700000000000003, -31.700000000000003, -13.699999999999998, -19.7, -24.6, -19.7, -17.7, -28.8, -16.7, -18.2, -25.700000000000006, -13.599999999999996, -17.7, -13.699999999999998, -13.700000000000001, -32.7, -16.7, -12.699999999999998, -19.7, -12.699999999999998, -14.699999999999998, -16.4, -19.7, -17.700000000000003, -20.700000000000003, -9.9, -21.2, -17.7, -21.700000000000003, -15.699999999999998, -11.699999999999998, -15.699999999999996, -20.700000000000003, -15.699999999999998, -29.700000000000006, -17.7, -21.500000000000004, -9.2, -17.7, -16.7, -17.7, -33.7, -20.7, -22.700000000000003, -22.700000000000003, -17.7, -21.7, -13.299999999999999, -14.699999999999998, -19.700000000000003, -16.7, -18.7, -20.5, -17.7, -14.699999999999998, -14.699999999999996, -16.699999999999996, -19.7, -10.699999999999998, -12.699999999999998, -17.7, -24.700000000000003, -15.699999999999996, -14.499999999999998, -10.699999999999998, -17.7, -17.7, -35.7, -18.5, -20.3, -15.699999999999998, -16.7, -17.7, -15.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.412879676010186, "mean_inference_ms": 1.3044754327690509, "mean_action_processing_ms": 0.09361243027066017, "mean_env_wait_ms": 4.361915783869107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 60000, "timesteps_this_iter": 0, "agent_timesteps_total": 60000, "timers": {"sample_time_ms": 10662.057, "sample_throughput": 375.162, "load_time_ms": 0.357, "load_throughput": 11219216.263, "learn_time_ms": 2402.46, "learn_throughput": 1664.96, "update_time_ms": 2.37}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 27.612449645996094, "policy_loss": -0.033709775656461716, "vf_loss": 27.63572883605957, "vf_explained_var": 0.3088655471801758, "kl": 0.015451790764927864, "entropy": 2.845479726791382, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 60000, "num_steps_trained": 60000, "num_agent_steps_trained": 60000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3156, "training_iteration": 15, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-43", "timestamp": 1642601263, "time_this_iter_s": 11.983989000320435, "time_total_s": 160.47454500198364, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 160.47454500198364, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 57.129411764705885, "ram_util_percent": 62.3235294117647}}
{"episode_reward_max": -7.699999999999999, "episode_reward_min": -34.5, "episode_reward_mean": -16.594811320754715, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.399999999999999, -10.699999999999998, -13.699999999999996, -15.699999999999998, -17.7, -14.699999999999998, -16.0, -21.700000000000003, -15.699999999999998, -15.699999999999998, -15.699999999999998, -12.699999999999998, -13.0, -12.699999999999998, -16.7, -20.700000000000006, -15.699999999999998, -11.7, -21.6, -22.3, -27.699999999999996, -20.700000000000003, -11.3, -17.700000000000003, -13.699999999999998, -16.7, -19.2, -16.7, -13.699999999999998, -12.699999999999998, -12.699999999999998, -21.7, -13.699999999999998, -21.700000000000006, -14.699999999999998, -13.699999999999998, -12.699999999999998, -21.700000000000003, -13.699999999999998, -16.7, -13.699999999999998, -13.699999999999998, -20.700000000000003, -19.700000000000003, -14.699999999999998, -12.699999999999998, -12.299999999999999, -18.700000000000003, -12.700000000000001, -8.699999999999998, -18.7, -15.699999999999996, -9.699999999999998, -20.3, -17.7, -25.700000000000003, -17.7, -17.700000000000003, -14.699999999999998, -28.700000000000006, -16.7, -13.699999999999998, -16.7, -25.700000000000006, -18.7, -14.2, -16.7, -15.699999999999998, -16.299999999999997, -11.699999999999996, -19.700000000000003, -10.699999999999998, -18.7, -12.1, -17.7, -12.699999999999996, -16.4, -13.699999999999998, -15.699999999999998, -12.699999999999998, -29.3, -14.699999999999998, -17.7, -16.7, -11.699999999999998, -9.699999999999998, -11.699999999999998, -20.7, -11.699999999999998, -11.7, -23.700000000000003, -12.399999999999999, -15.699999999999998, -10.699999999999998, -13.599999999999998, -15.699999999999998, -20.7, -15.699999999999998, -29.700000000000006, -11.699999999999998, -20.700000000000003, -18.299999999999997, -14.699999999999996, -12.5, -13.9, -14.699999999999998, -9.7, -13.699999999999998, -12.699999999999998, -23.3, -16.3, -18.700000000000003, -22.700000000000006, -14.699999999999998, -15.699999999999998, -19.7, -11.699999999999998, -22.700000000000003, -14.699999999999998, -16.7, -21.700000000000003, -14.699999999999998, -10.699999999999998, -17.700000000000003, -7.699999999999999, -16.7, -15.699999999999998, -16.7, -19.700000000000003, -12.699999999999998, -16.7, -17.7, -18.7, -15.699999999999998, -15.7, -20.700000000000003, -19.700000000000003, -11.699999999999998, -8.9, -13.699999999999998, -20.700000000000003, -26.700000000000003, -22.700000000000003, -17.499999999999996, -10.699999999999998, -13.599999999999998, -11.699999999999998, -25.700000000000003, -20.700000000000003, -13.8, -34.5, -16.7, -14.699999999999998, -14.699999999999998, -13.699999999999998, -12.5, -12.699999999999998, -16.699999999999996, -17.7, -20.700000000000003, -21.700000000000003, -11.699999999999998, -11.699999999999998, -17.700000000000003, -16.7, -13.699999999999998, -21.6, -9.7, -27.700000000000003, -13.699999999999996, -13.3, -14.699999999999998, -31.4, -17.6, -13.699999999999998, -16.7, -12.699999999999998, -13.8, -15.2, -9.699999999999998, -22.700000000000003, -9.699999999999998, -24.700000000000006, -17.700000000000003, -21.700000000000003, -18.7, -11.699999999999998, -10.699999999999998, -16.7, -21.700000000000003, -15.699999999999996, -19.7, -13.699999999999998, -17.7, -17.7, -20.700000000000003, -14.699999999999998, -18.700000000000003, -15.699999999999998, -10.699999999999998, -18.700000000000003, -14.499999999999998, -20.700000000000003, -20.700000000000003, -13.699999999999998, -25.7, -22.700000000000003, -25.0, -16.7, -12.699999999999998, -17.700000000000003, -19.700000000000003], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.407067217355101, "mean_inference_ms": 1.2993166487065413, "mean_action_processing_ms": 0.0932582444931878, "mean_env_wait_ms": 4.344364165008147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 64000, "timesteps_this_iter": 0, "agent_timesteps_total": 64000, "timers": {"sample_time_ms": 10652.561, "sample_throughput": 375.497, "load_time_ms": 0.359, "load_throughput": 11146170.609, "learn_time_ms": 2436.387, "learn_throughput": 1641.775, "update_time_ms": 2.358}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 22.810298919677734, "policy_loss": -0.033695776015520096, "vf_loss": 22.83465576171875, "vf_explained_var": 0.26980870962142944, "kl": 0.01383468322455883, "entropy": 2.7966551780700684, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 64000, "num_agent_steps_sampled": 64000, "num_steps_trained": 64000, "num_agent_steps_trained": 64000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3368, "training_iteration": 16, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-07-53", "timestamp": 1642601273, "time_this_iter_s": 10.253429889678955, "time_total_s": 170.7279748916626, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 170.7279748916626, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 47.79285714285715, "ram_util_percent": 62.328571428571415}}
{"episode_reward_max": -7.699999999999999, "episode_reward_min": -68.7, "episode_reward_mean": -15.852403846153843, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.700000000000006, -10.699999999999998, -13.699999999999998, -11.699999999999998, -13.699999999999998, -13.3, -10.699999999999998, -17.700000000000003, -18.7, -24.0, -20.700000000000003, -13.699999999999998, -20.2, -18.5, -25.8, -8.699999999999998, -14.699999999999998, -18.7, -15.699999999999998, -13.699999999999998, -20.700000000000003, -13.699999999999996, -10.599999999999998, -15.9, -24.700000000000003, -17.600000000000005, -16.700000000000003, -14.299999999999999, -12.699999999999998, -12.699999999999998, -16.699999999999996, -19.299999999999997, -18.7, -11.299999999999999, -11.699999999999998, -10.3, -23.5, -31.700000000000006, -13.699999999999998, -20.700000000000003, -19.7, -13.9, -15.699999999999998, -21.3, -11.699999999999998, -13.699999999999998, -10.699999999999998, -15.5, -9.699999999999998, -10.699999999999998, -21.700000000000003, -12.699999999999996, -13.699999999999998, -12.699999999999998, -24.099999999999998, -21.700000000000003, -17.6, -12.699999999999998, -11.699999999999998, -13.699999999999998, -13.699999999999998, -27.700000000000003, -12.699999999999998, -21.700000000000003, -18.7, -16.699999999999996, -10.699999999999998, -20.700000000000003, -19.7, -11.7, -37.7, -10.3, -9.699999999999998, -13.699999999999998, -11.2, -12.699999999999998, -14.699999999999998, -13.699999999999998, -18.8, -7.699999999999999, -10.2, -19.7, -17.7, -17.700000000000006, -12.699999999999998, -10.699999999999998, -15.699999999999998, -13.1, -24.700000000000003, -15.3, -15.699999999999998, -19.700000000000003, -14.699999999999998, -12.699999999999998, -11.9, -22.700000000000003, -10.1, -17.700000000000003, -17.7, -12.699999999999998, -24.700000000000003, -11.699999999999998, -10.699999999999998, -68.7, -13.699999999999998, -14.699999999999998, -10.699999999999996, -13.699999999999998, -13.699999999999998, -11.2, -12.699999999999998, -21.6, -19.3, -15.699999999999998, -13.5, -18.2, -15.3, -11.699999999999998, -12.999999999999998, -11.699999999999998, -12.699999999999998, -11.699999999999998, -16.599999999999998, -12.699999999999998, -11.699999999999998, -19.7, -10.699999999999998, -26.600000000000005, -18.700000000000003, -10.699999999999998, -11.699999999999998, -12.699999999999998, -9.699999999999998, -15.699999999999996, -14.699999999999996, -10.699999999999998, -14.699999999999998, -12.2, -17.299999999999997, -14.5, -12.399999999999999, -14.699999999999998, -14.699999999999998, -13.699999999999996, -12.699999999999998, -11.499999999999998, -12.699999999999998, -13.699999999999998, -10.7, -21.700000000000003, -12.2, -19.7, -17.699999999999996, -10.699999999999998, -11.699999999999998, -8.7, -11.699999999999998, -12.699999999999998, -12.699999999999998, -13.599999999999998, -13.699999999999998, -13.699999999999998, -9.699999999999998, -23.2, -9.699999999999998, -15.699999999999996, -21.700000000000003, -14.399999999999999, -12.699999999999998, -12.699999999999998, -24.700000000000003, -16.2, -22.700000000000003, -16.7, -25.700000000000006, -15.699999999999998, -18.700000000000003, -19.700000000000003, -18.7, -13.699999999999998, -38.7, -46.7, -13.5, -11.699999999999998, -12.699999999999998, -12.699999999999998, -12.699999999999998, -16.599999999999998, -11.699999999999998, -12.5, -11.599999999999998, -14.699999999999998, -10.699999999999998, -11.699999999999998, -11.699999999999998, -23.700000000000003, -14.699999999999998, -11.499999999999998, -14.699999999999996, -12.699999999999998, -8.599999999999998, -12.699999999999998, -24.699999999999996, -25.700000000000006, -12.299999999999999, -15.699999999999998, -11.5, -12.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.395631081847175, "mean_inference_ms": 1.2930393899148314, "mean_action_processing_ms": 0.09284927300737644, "mean_env_wait_ms": 4.323545652069447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 68000, "timesteps_this_iter": 0, "agent_timesteps_total": 68000, "timers": {"sample_time_ms": 10664.098, "sample_throughput": 375.09, "load_time_ms": 0.361, "load_throughput": 11072608.237, "learn_time_ms": 2490.085, "learn_throughput": 1606.371, "update_time_ms": 2.357}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 39.40331268310547, "policy_loss": -0.02150949276983738, "vf_loss": 39.417869567871094, "vf_explained_var": 0.2229798287153244, "kl": 0.010297877714037895, "entropy": 2.7534687519073486, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 68000, "num_agent_steps_sampled": 68000, "num_steps_trained": 68000, "num_agent_steps_trained": 68000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3576, "training_iteration": 17, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-03", "timestamp": 1642601283, "time_this_iter_s": 10.235594034194946, "time_total_s": 180.96356892585754, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 180.96356892585754, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 46.446666666666665, "ram_util_percent": 62.30666666666664}}
{"episode_reward_max": -6.699999999999999, "episode_reward_min": -45.2, "episode_reward_mean": -14.379245283018866, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.699999999999998, -14.699999999999998, -13.699999999999996, -18.700000000000003, -19.7, -9.3, -9.699999999999998, -15.3, -27.700000000000006, -11.699999999999998, -15.699999999999998, -9.5, -18.700000000000003, -22.6, -23.700000000000003, -8.7, -9.2, -11.699999999999998, -16.8, -15.699999999999998, -19.8, -10.699999999999998, -14.7, -14.699999999999998, -17.7, -16.7, -22.700000000000006, -13.699999999999998, -13.699999999999998, -11.699999999999998, -15.2, -11.599999999999998, -15.699999999999996, -12.699999999999998, -11.399999999999999, -32.699999999999996, -18.7, -10.699999999999998, -13.699999999999998, -11.699999999999998, -12.8, -14.699999999999998, -16.7, -15.699999999999996, -12.699999999999996, -10.699999999999998, -21.700000000000006, -9.5, -9.7, -15.599999999999996, -15.699999999999998, -12.699999999999998, -11.599999999999996, -18.7, -12.699999999999998, -12.1, -9.9, -14.699999999999998, -10.7, -15.699999999999996, -14.699999999999998, -17.2, -16.599999999999998, -26.699999999999996, -9.2, -14.5, -32.7, -18.3, -14.599999999999998, -20.3, -21.700000000000003, -14.699999999999998, -12.699999999999998, -17.7, -11.699999999999998, -18.700000000000003, -18.700000000000003, -11.699999999999998, -12.699999999999998, -10.699999999999998, -11.699999999999998, -10.699999999999998, -11.699999999999998, -11.699999999999998, -12.699999999999998, -10.699999999999998, -16.3, -25.700000000000006, -12.599999999999996, -13.699999999999998, -11.699999999999998, -10.599999999999998, -10.699999999999998, -10.4, -11.1, -13.699999999999998, -21.6, -18.7, -18.7, -15.699999999999996, -11.699999999999998, -21.700000000000003, -9.699999999999998, -9.699999999999998, -12.699999999999998, -10.2, -16.599999999999998, -16.4, -17.4, -14.699999999999998, -14.699999999999996, -18.7, -9.700000000000001, -13.2, -14.699999999999998, -16.7, -14.299999999999997, -16.7, -10.699999999999998, -21.700000000000003, -10.3, -14.699999999999998, -14.699999999999998, -19.5, -11.299999999999999, -24.700000000000003, -11.699999999999998, -8.7, -11.699999999999998, -17.700000000000003, -13.700000000000001, -10.699999999999998, -20.700000000000003, -16.5, -11.699999999999998, -13.699999999999998, -9.699999999999998, -11.699999999999998, -13.699999999999998, -7.6999999999999975, -9.699999999999998, -10.699999999999998, -14.699999999999998, -11.699999999999998, -10.200000000000001, -11.699999999999998, -9.6, -11.699999999999998, -13.699999999999998, -9.699999999999998, -15.699999999999998, -13.699999999999998, -12.599999999999996, -14.299999999999999, -15.699999999999998, -12.699999999999998, -11.699999999999998, -17.7, -9.6, -9.7, -12.699999999999998, -11.699999999999998, -8.3, -17.7, -7.6999999999999975, -23.700000000000006, -19.6, -12.699999999999998, -12.699999999999998, -12.699999999999998, -10.699999999999998, -10.7, -15.699999999999998, -13.699999999999998, -12.699999999999996, -11.699999999999998, -11.3, -9.699999999999998, -9.699999999999998, -10.699999999999998, -20.5, -17.7, -16.2, -26.7, -45.2, -8.600000000000001, -7.699999999999999, -12.9, -11.5, -9.699999999999998, -10.700000000000001, -12.699999999999996, -16.7, -16.2, -13.2, -13.699999999999998, -16.7, -13.699999999999998, -10.699999999999998, -14.699999999999998, -6.699999999999999, -10.5, -12.9, -10.699999999999998, -14.699999999999998, -12.699999999999998, -12.699999999999998, -12.699999999999998, -14.699999999999996, -10.699999999999998, -19.2, -17.699999999999996], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.389013641417394, "mean_inference_ms": 1.2887450040933073, "mean_action_processing_ms": 0.09254643760928247, "mean_env_wait_ms": 4.307967077711611, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 72000, "timesteps_this_iter": 0, "agent_timesteps_total": 72000, "timers": {"sample_time_ms": 10689.65, "sample_throughput": 374.194, "load_time_ms": 0.364, "load_throughput": 10989922.704, "learn_time_ms": 2514.518, "learn_throughput": 1590.762, "update_time_ms": 2.342}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 24.32282829284668, "policy_loss": -0.027875445783138275, "vf_loss": 24.343481063842773, "vf_explained_var": 0.20919625461101532, "kl": 0.010699334554374218, "entropy": 2.667834520339966, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 72000, "num_agent_steps_sampled": 72000, "num_steps_trained": 72000, "num_agent_steps_trained": 72000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3788, "training_iteration": 18, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-13", "timestamp": 1642601293, "time_this_iter_s": 10.069010972976685, "time_total_s": 191.03257989883423, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 191.03257989883423, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 45.93571428571429, "ram_util_percent": 62.328571428571415}}
{"episode_reward_max": -6.699999999999999, "episode_reward_min": -35.7, "episode_reward_mean": -13.57311320754717, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.699999999999996, -11.699999999999998, -11.399999999999999, -11.5, -11.699999999999998, -18.700000000000003, -11.699999999999998, -11.699999999999998, -13.699999999999998, -12.699999999999998, -13.699999999999998, -14.3, -12.699999999999998, -13.699999999999996, -10.699999999999998, -16.7, -10.699999999999998, -12.699999999999998, -9.699999999999998, -12.699999999999998, -18.7, -12.699999999999998, -15.699999999999998, -13.699999999999998, -8.7, -8.699999999999998, -11.699999999999998, -12.699999999999998, -15.7, -12.3, -12.699999999999996, -12.699999999999998, -10.699999999999998, -9.699999999999998, -11.3, -15.699999999999998, -12.699999999999998, -21.7, -18.7, -25.700000000000006, -14.699999999999998, -10.699999999999998, -10.7, -18.700000000000003, -12.699999999999996, -12.699999999999998, -11.3, -16.7, -8.699999999999998, -10.699999999999998, -8.699999999999998, -9.7, -9.399999999999999, -9.699999999999998, -11.699999999999998, -16.7, -12.499999999999996, -15.699999999999998, -16.7, -9.699999999999998, -11.499999999999998, -11.699999999999996, -12.699999999999998, -11.2, -15.699999999999998, -16.599999999999998, -15.699999999999998, -13.699999999999998, -25.700000000000006, -14.699999999999996, -10.699999999999998, -9.699999999999998, -13.699999999999998, -9.7, -10.699999999999998, -35.7, -12.699999999999998, -20.700000000000003, -13.699999999999998, -13.399999999999999, -11.699999999999998, -14.399999999999999, -8.700000000000001, -13.699999999999998, -12.699999999999998, -13.5, -8.699999999999998, -10.2, -13.699999999999998, -17.699999999999996, -21.700000000000003, -7.6999999999999975, -14.699999999999996, -14.699999999999998, -10.699999999999998, -11.699999999999998, -11.699999999999998, -12.699999999999998, -8.5, -14.1, -11.699999999999998, -11.699999999999998, -14.699999999999998, -28.700000000000003, -20.700000000000003, -32.400000000000006, -14.699999999999998, -14.699999999999998, -11.699999999999998, -11.699999999999998, -12.699999999999998, -11.2, -12.699999999999998, -14.699999999999996, -15.699999999999998, -9.599999999999998, -12.699999999999998, -11.699999999999998, -13.699999999999998, -9.499999999999998, -14.699999999999998, -19.700000000000003, -18.7, -11.699999999999998, -12.699999999999998, -11.699999999999998, -17.7, -8.699999999999998, -13.699999999999998, -12.699999999999998, -9.2, -12.699999999999996, -16.7, -6.699999999999999, -15.699999999999998, -9.8, -14.699999999999996, -15.699999999999998, -14.699999999999998, -20.7, -9.699999999999998, -12.3, -23.700000000000003, -15.699999999999996, -12.5, -23.700000000000006, -9.9, -11.299999999999999, -13.699999999999998, -11.699999999999998, -11.699999999999998, -12.699999999999996, -10.699999999999998, -11.699999999999998, -10.699999999999996, -8.699999999999998, -10.699999999999998, -11.699999999999998, -13.5, -10.5, -15.899999999999999, -12.600000000000001, -15.699999999999998, -15.699999999999998, -12.699999999999998, -16.5, -9.699999999999998, -11.699999999999996, -10.699999999999998, -10.699999999999998, -12.699999999999998, -24.700000000000006, -13.699999999999998, -15.699999999999996, -10.699999999999998, -7.699999999999999, -11.599999999999998, -11.699999999999998, -12.699999999999998, -9.699999999999998, -11.699999999999998, -9.9, -10.699999999999998, -14.699999999999998, -9.7, -12.699999999999998, -25.9, -11.599999999999998, -24.699999999999996, -9.699999999999998, -25.700000000000006, -13.699999999999998, -20.0, -8.3, -8.699999999999998, -16.7, -11.0, -12.699999999999998, -12.699999999999998, -17.7, -12.699999999999998, -10.699999999999998, -11.699999999999998, -8.699999999999998, -8.699999999999998, -13.699999999999998, -25.700000000000003, -15.5, -11.9, -11.699999999999998, -16.7, -9.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.380758268281941, "mean_inference_ms": 1.2825503988483316, "mean_action_processing_ms": 0.09214758565567534, "mean_env_wait_ms": 4.2880075140116345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 76000, "timesteps_this_iter": 0, "agent_timesteps_total": 76000, "timers": {"sample_time_ms": 10581.223, "sample_throughput": 378.028, "load_time_ms": 0.365, "load_throughput": 10971237.248, "learn_time_ms": 2496.016, "learn_throughput": 1602.554, "update_time_ms": 2.224}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 21.035913467407227, "policy_loss": -0.02498728036880493, "vf_loss": 21.053070068359375, "vf_explained_var": 0.2149108201265335, "kl": 0.011604118160903454, "entropy": 2.6288774013519287, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 76000, "num_agent_steps_sampled": 76000, "num_steps_trained": 76000, "num_agent_steps_trained": 76000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4000, "training_iteration": 19, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-23", "timestamp": 1642601303, "time_this_iter_s": 9.898437738418579, "time_total_s": 200.9310176372528, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 200.9310176372528, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 45.01428571428571, "ram_util_percent": 62.314285714285695}}
{"episode_reward_max": -6.699999999999999, "episode_reward_min": -49.7, "episode_reward_mean": -13.238461538461536, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.2, -10.699999999999998, -10.699999999999998, -9.599999999999998, -8.699999999999998, -10.3, -13.699999999999998, -9.599999999999998, -18.9, -8.699999999999998, -17.700000000000003, -7.6999999999999975, -10.699999999999998, -15.699999999999996, -15.699999999999998, -11.699999999999998, -11.699999999999998, -13.699999999999998, -16.7, -10.699999999999998, -14.5, -49.7, -10.699999999999998, -20.700000000000006, -11.699999999999998, -19.7, -17.7, -11.699999999999998, -10.699999999999998, -10.699999999999998, -12.699999999999998, -18.7, -10.699999999999998, -12.2, -13.4, -11.699999999999998, -23.700000000000003, -10.699999999999998, -11.2, -19.599999999999998, -11.7, -11.699999999999998, -18.5, -18.7, -10.699999999999998, -9.499999999999998, -12.699999999999998, -11.3, -24.700000000000006, -11.699999999999998, -12.699999999999998, -12.699999999999998, -8.699999999999998, -7.6999999999999975, -16.7, -12.699999999999998, -10.2, -14.700000000000001, -11.699999999999998, -14.4, -11.699999999999998, -17.700000000000003, -8.699999999999998, -13.699999999999998, -14.699999999999998, -8.699999999999998, -15.699999999999996, -12.599999999999998, -18.7, -10.699999999999998, -23.700000000000006, -10.699999999999998, -24.700000000000003, -12.7, -12.699999999999998, -13.699999999999998, -10.699999999999998, -10.699999999999998, -10.699999999999998, -16.7, -9.699999999999998, -9.699999999999998, -9.699999999999998, -11.699999999999998, -11.699999999999998, -14.0, -9.699999999999998, -14.699999999999998, -11.699999999999998, -8.699999999999998, -7.6999999999999975, -14.2, -9.699999999999998, -12.699999999999998, -13.699999999999998, -10.699999999999998, -13.699999999999998, -17.700000000000003, -10.7, -10.699999999999996, -9.1, -16.7, -10.5, -9.699999999999998, -11.9, -29.699999999999996, -9.699999999999998, -11.699999999999998, -12.499999999999998, -14.699999999999998, -17.7, -12.8, -13.2, -11.299999999999997, -7.3, -9.9, -17.7, -15.699999999999998, -8.699999999999998, -20.700000000000003, -14.699999999999998, -16.7, -7.6999999999999975, -7.6999999999999975, -10.699999999999998, -15.699999999999998, -11.699999999999996, -49.5, -6.699999999999999, -13.699999999999998, -10.599999999999998, -10.699999999999998, -12.5, -9.699999999999998, -15.699999999999998, -14.699999999999998, -12.699999999999998, -24.3, -11.699999999999998, -13.699999999999996, -14.899999999999999, -12.699999999999998, -11.699999999999998, -16.6, -10.699999999999998, -11.699999999999998, -12.699999999999998, -12.699999999999998, -9.9, -11.699999999999998, -16.7, -15.699999999999998, -12.699999999999998, -10.699999999999998, -10.6, -12.699999999999998, -7.699999999999999, -9.5, -8.9, -15.699999999999998, -10.2, -8.5, -8.699999999999998, -7.6999999999999975, -14.799999999999999, -10.699999999999998, -14.1, -11.699999999999998, -12.699999999999996, -13.699999999999998, -11.699999999999998, -12.699999999999998, -14.699999999999998, -25.699999999999996, -11.699999999999998, -15.699999999999998, -9.6, -12.699999999999998, -8.7, -8.7, -7.3, -16.7, -12.3, -17.0, -8.3, -8.5, -11.699999999999998, -14.699999999999998, -8.699999999999998, -13.699999999999998, -10.699999999999998, -9.699999999999998, -13.699999999999996, -12.599999999999998, -8.5, -10.699999999999998, -12.9, -15.699999999999996, -11.299999999999999, -11.699999999999998, -13.699999999999998, -13.699999999999998, -9.699999999999998, -18.599999999999994, -11.699999999999998, -24.700000000000006, -14.599999999999996, -13.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3669205774730946, "mean_inference_ms": 1.2751928979555056, "mean_action_processing_ms": 0.09167816309826139, "mean_env_wait_ms": 4.262016306018348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 80000, "timesteps_this_iter": 0, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 10430.33, "sample_throughput": 383.497, "load_time_ms": 0.364, "load_throughput": 10998568.244, "learn_time_ms": 2473.922, "learn_throughput": 1616.866, "update_time_ms": 2.161}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 25.55717658996582, "policy_loss": -0.026584602892398834, "vf_loss": 25.57744789123535, "vf_explained_var": 0.18224787712097168, "kl": 0.009350582957267761, "entropy": 2.581043243408203, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 80000, "num_steps_trained": 80000, "num_agent_steps_trained": 80000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4208, "training_iteration": 20, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-33", "timestamp": 1642601313, "time_this_iter_s": 9.672825813293457, "time_total_s": 210.60384345054626, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 210.60384345054626, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 43.07857142857142, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -4.699999999999999, "episode_reward_min": -48.6, "episode_reward_mean": -13.230188679245282, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.7, -10.699999999999998, -23.700000000000006, -16.7, -16.7, -11.699999999999998, -10.699999999999998, -9.0, -33.7, -11.699999999999998, -9.699999999999998, -9.699999999999998, -14.599999999999998, -11.2, -9.3, -11.699999999999998, -9.699999999999998, -14.699999999999998, -21.700000000000003, -11.699999999999998, -9.7, -7.6999999999999975, -10.699999999999998, -10.699999999999998, -11.699999999999998, -13.7, -23.700000000000003, -13.699999999999998, -29.9, -9.699999999999998, -12.699999999999998, -8.699999999999998, -17.7, -16.7, -9.699999999999998, -14.699999999999996, -11.700000000000001, -12.699999999999996, -8.2, -11.699999999999998, -10.7, -11.699999999999998, -14.699999999999998, -10.699999999999998, -9.699999999999998, -12.2, -10.699999999999998, -10.699999999999998, -8.7, -13.8, -12.599999999999998, -16.299999999999997, -15.699999999999998, -21.700000000000003, -11.699999999999998, -7.7, -12.699999999999998, -12.699999999999998, -6.6999999999999975, -9.700000000000001, -10.1, -10.699999999999998, -10.699999999999998, -8.7, -48.6, -11.699999999999998, -10.699999999999998, -11.699999999999998, -11.699999999999996, -10.699999999999998, -11.699999999999998, -8.699999999999998, -18.7, -8.699999999999998, -12.699999999999998, -11.699999999999998, -9.699999999999998, -11.2, -14.699999999999998, -11.699999999999996, -11.699999999999998, -41.7, -11.2, -14.699999999999998, -39.7, -16.599999999999998, -22.700000000000006, -10.699999999999998, -10.699999999999998, -18.7, -13.699999999999998, -6.6999999999999975, -9.699999999999998, -8.7, -14.699999999999998, -10.0, -21.700000000000006, -10.7, -7.6999999999999975, -14.599999999999998, -10.599999999999998, -17.7, -10.699999999999998, -14.2, -13.699999999999998, -19.9, -12.699999999999998, -9.699999999999998, -13.699999999999998, -12.699999999999998, -11.699999999999998, -26.700000000000003, -12.700000000000001, -12.699999999999998, -14.699999999999998, -8.7, -8.699999999999998, -15.699999999999998, -13.699999999999998, -13.699999999999996, -9.7, -12.699999999999996, -12.3, -8.699999999999998, -9.699999999999998, -13.699999999999998, -14.700000000000001, -17.6, -13.700000000000001, -6.699999999999999, -11.699999999999998, -12.2, -8.699999999999998, -9.100000000000001, -19.7, -10.3, -9.699999999999998, -8.7, -13.699999999999998, -11.3, -9.7, -8.599999999999998, -10.699999999999998, -9.7, -16.8, -13.699999999999998, -11.499999999999998, -12.699999999999998, -13.699999999999996, -12.699999999999998, -8.699999999999998, -11.699999999999998, -13.699999999999998, -8.699999999999998, -9.699999999999998, -11.599999999999998, -7.699999999999999, -22.700000000000006, -20.7, -12.699999999999998, -25.500000000000004, -8.699999999999998, -11.5, -9.699999999999998, -8.699999999999998, -15.699999999999998, -16.6, -11.699999999999998, -12.3, -4.699999999999999, -8.699999999999998, -14.699999999999998, -9.699999999999998, -11.699999999999998, -10.3, -12.699999999999998, -9.699999999999998, -17.700000000000006, -11.699999999999996, -10.9, -14.699999999999998, -16.7, -14.699999999999998, -11.699999999999998, -13.699999999999998, -11.699999999999998, -13.699999999999998, -12.699999999999998, -11.699999999999996, -15.699999999999998, -14.699999999999998, -11.699999999999996, -9.699999999999998, -11.699999999999998, -10.699999999999998, -12.699999999999996, -22.700000000000003, -8.699999999999998, -12.699999999999996, -18.700000000000003, -8.699999999999998, -17.1, -15.699999999999998, -23.700000000000006, -9.699999999999998, -8.699999999999998, -15.699999999999998, -11.699999999999998, -12.699999999999998, -11.399999999999999, -17.7, -15.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3572689566996643, "mean_inference_ms": 1.2682937626656807, "mean_action_processing_ms": 0.09122948255784612, "mean_env_wait_ms": 4.240661262075172, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 84000, "timesteps_this_iter": 0, "agent_timesteps_total": 84000, "timers": {"sample_time_ms": 10295.898, "sample_throughput": 388.504, "load_time_ms": 0.345, "load_throughput": 11594482.377, "learn_time_ms": 2410.083, "learn_throughput": 1659.694, "update_time_ms": 2.131}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 27.816009521484375, "policy_loss": -0.02669573202729225, "vf_loss": 27.836437225341797, "vf_explained_var": 0.18524950742721558, "kl": 0.00928435567766428, "entropy": 2.5325090885162354, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 84000, "num_agent_steps_sampled": 84000, "num_steps_trained": 84000, "num_agent_steps_trained": 84000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4420, "training_iteration": 21, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-42", "timestamp": 1642601322, "time_this_iter_s": 9.59262204170227, "time_total_s": 220.19646549224854, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 220.19646549224854, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 41.86428571428572, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -6.6999999999999975, "episode_reward_min": -34.7, "episode_reward_mean": -12.553365384615383, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.7, -13.399999999999999, -13.0, -11.699999999999996, -11.699999999999998, -10.2, -13.6, -14.699999999999998, -7.699999999999999, -11.7, -9.7, -14.699999999999998, -10.699999999999998, -10.699999999999998, -8.699999999999998, -11.699999999999998, -10.699999999999998, -16.7, -11.699999999999998, -7.6999999999999975, -8.2, -6.699999999999999, -11.599999999999996, -16.7, -12.699999999999998, -7.6999999999999975, -16.299999999999997, -9.699999999999998, -14.699999999999998, -11.699999999999998, -11.699999999999998, -6.699999999999999, -11.7, -9.699999999999998, -8.699999999999998, -9.699999999999998, -14.699999999999998, -14.699999999999998, -9.7, -8.699999999999998, -14.699999999999998, -9.699999999999998, -9.699999999999998, -9.2, -21.700000000000003, -11.3, -9.699999999999998, -7.699999999999999, -8.7, -11.7, -14.699999999999998, -10.699999999999998, -12.499999999999998, -12.699999999999996, -11.7, -14.699999999999998, -13.599999999999998, -13.9, -12.699999999999996, -12.699999999999998, -10.699999999999998, -12.699999999999998, -21.700000000000003, -8.2, -18.6, -8.699999999999998, -10.2, -12.699999999999998, -13.699999999999998, -20.700000000000003, -9.699999999999998, -9.699999999999998, -13.5, -20.7, -16.7, -9.2, -9.7, -9.699999999999998, -8.699999999999998, -18.9, -23.699999999999996, -8.699999999999998, -8.3, -22.700000000000006, -20.6, -13.699999999999998, -14.699999999999998, -11.699999999999998, -14.699999999999998, -22.700000000000003, -11.699999999999998, -9.699999999999998, -10.699999999999998, -7.6999999999999975, -8.699999999999998, -9.7, -13.699999999999998, -8.7, -10.3, -9.699999999999998, -10.699999999999998, -14.699999999999998, -11.699999999999998, -9.699999999999998, -10.9, -9.699999999999998, -8.699999999999998, -8.2, -9.699999999999998, -20.5, -12.200000000000001, -10.7, -13.2, -23.700000000000003, -14.7, -7.5, -10.699999999999998, -20.700000000000003, -8.699999999999998, -12.699999999999998, -10.699999999999998, -15.799999999999999, -13.5, -7.6999999999999975, -8.699999999999998, -11.9, -9.699999999999998, -15.699999999999998, -10.599999999999998, -17.7, -9.699999999999998, -19.700000000000003, -6.6999999999999975, -15.699999999999998, -7.699999999999999, -14.699999999999998, -9.699999999999998, -6.699999999999999, -9.699999999999998, -8.699999999999998, -25.700000000000003, -11.699999999999998, -9.7, -12.699999999999998, -9.699999999999998, -13.699999999999998, -10.699999999999998, -13.699999999999998, -10.699999999999998, -8.7, -12.699999999999998, -16.7, -14.7, -22.4, -21.700000000000006, -7.699999999999999, -13.699999999999998, -15.399999999999999, -19.7, -9.7, -17.7, -18.7, -9.699999999999998, -20.600000000000005, -13.699999999999998, -9.699999999999998, -10.699999999999998, -15.6, -9.5, -14.699999999999998, -13.699999999999998, -13.699999999999998, -14.699999999999996, -7.3, -26.700000000000006, -34.7, -14.699999999999998, -12.699999999999998, -8.7, -11.7, -7.6999999999999975, -13.699999999999998, -9.699999999999998, -9.699999999999998, -9.699999999999998, -8.699999999999998, -10.699999999999998, -10.699999999999996, -17.4, -9.699999999999998, -11.699999999999998, -9.699999999999998, -15.699999999999998, -10.3, -9.2, -8.699999999999998, -11.699999999999998, -8.699999999999998, -8.699999999999998, -11.699999999999998, -18.599999999999998, -18.7, -10.699999999999998, -18.7, -16.7, -9.699999999999998, -7.6999999999999975, -12.699999999999996], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3484538481520625, "mean_inference_ms": 1.2639385099590033, "mean_action_processing_ms": 0.09096288923772702, "mean_env_wait_ms": 4.225417861211985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 88000, "timesteps_this_iter": 0, "agent_timesteps_total": 88000, "timers": {"sample_time_ms": 10212.204, "sample_throughput": 391.688, "load_time_ms": 0.344, "load_throughput": 11637913.43, "learn_time_ms": 2373.027, "learn_throughput": 1685.611, "update_time_ms": 2.163}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 18.33833122253418, "policy_loss": -0.026519523933529854, "vf_loss": 18.35838508605957, "vf_explained_var": 0.19257189333438873, "kl": 0.009582285769283772, "entropy": 2.4780428409576416, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 88000, "num_agent_steps_sampled": 88000, "num_steps_trained": 88000, "num_agent_steps_trained": 88000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4628, "training_iteration": 22, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-08-52", "timestamp": 1642601332, "time_this_iter_s": 9.559520959854126, "time_total_s": 229.75598645210266, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 229.75598645210266, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 42.7, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -4.6000000000000005, "episode_reward_min": -31.700000000000003, "episode_reward_mean": -11.626415094339619, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.699999999999998, -14.699999999999998, -17.700000000000003, -7.6999999999999975, -14.699999999999998, -10.7, -8.7, -10.699999999999998, -21.700000000000003, -8.699999999999998, -7.699999999999999, -6.6999999999999975, -8.7, -10.699999999999998, -13.699999999999998, -8.699999999999998, -11.5, -8.699999999999998, -12.699999999999998, -10.699999999999998, -15.700000000000001, -10.699999999999998, -10.699999999999998, -10.699999999999998, -28.700000000000003, -11.699999999999998, -8.699999999999998, -8.7, -8.699999999999998, -11.699999999999998, -18.700000000000006, -8.499999999999998, -23.700000000000003, -8.699999999999998, -11.699999999999998, -14.699999999999998, -10.699999999999998, -9.699999999999998, -9.7, -8.699999999999998, -8.699999999999998, -10.699999999999998, -8.699999999999998, -12.699999999999998, -13.699999999999998, -9.699999999999998, -8.699999999999998, -8.7, -7.6999999999999975, -7.6999999999999975, -9.699999999999998, -23.9, -11.699999999999998, -12.699999999999998, -18.700000000000003, -7.699999999999999, -10.599999999999998, -8.699999999999998, -16.699999999999996, -10.699999999999996, -7.699999999999999, -7.699999999999999, -13.699999999999996, -7.6999999999999975, -7.699999999999999, -7.7, -16.7, -14.1, -8.7, -9.699999999999998, -12.699999999999998, -9.699999999999998, -10.7, -9.499999999999998, -8.699999999999998, -9.699999999999998, -14.699999999999996, -7.6999999999999975, -13.499999999999998, -15.699999999999996, -11.699999999999998, -9.699999999999998, -13.699999999999998, -9.699999999999998, -14.699999999999998, -10.699999999999998, -8.699999999999998, -13.7, -17.7, -12.699999999999998, -14.699999999999998, -11.699999999999998, -10.699999999999998, -13.4, -10.699999999999998, -11.699999999999998, -9.7, -9.1, -11.699999999999998, -10.499999999999998, -21.6, -6.699999999999999, -12.699999999999998, -9.5, -12.699999999999998, -12.5, -13.599999999999998, -13.699999999999998, -10.699999999999998, -9.699999999999998, -9.699999999999998, -11.599999999999996, -31.700000000000003, -14.499999999999998, -9.699999999999998, -10.699999999999998, -11.699999999999998, -13.4, -8.699999999999998, -14.699999999999998, -21.700000000000003, -8.699999999999998, -7.6999999999999975, -8.699999999999998, -13.699999999999998, -10.699999999999998, -11.699999999999998, -4.6000000000000005, -8.699999999999998, -10.2, -16.7, -8.699999999999998, -15.6, -15.1, -9.699999999999998, -9.699999999999998, -10.699999999999998, -23.4, -11.2, -9.5, -11.699999999999998, -11.699999999999998, -8.699999999999998, -8.7, -10.699999999999998, -10.699999999999996, -9.699999999999998, -9.699999999999998, -7.6999999999999975, -14.699999999999998, -9.7, -9.7, -8.699999999999998, -12.699999999999998, -9.699999999999998, -10.3, -9.699999999999998, -8.699999999999998, -9.699999999999998, -10.699999999999998, -9.699999999999998, -7.3, -6.699999999999999, -24.700000000000006, -9.3, -7.699999999999999, -9.699999999999998, -9.7, -21.1, -10.699999999999998, -8.7, -8.699999999999998, -10.699999999999998, -14.699999999999998, -13.699999999999998, -11.699999999999998, -17.299999999999997, -11.399999999999999, -8.7, -23.700000000000006, -16.7, -10.699999999999998, -10.699999999999998, -11.699999999999998, -9.699999999999998, -16.2, -8.5, -9.699999999999998, -11.2, -11.699999999999998, -18.700000000000003, -9.599999999999998, -10.299999999999999, -14.2, -9.7, -8.699999999999998, -18.700000000000003, -9.699999999999996, -6.6999999999999975, -6.699999999999999, -10.699999999999998, -13.699999999999998, -9.699999999999998, -6.699999999999999, -10.699999999999998, -12.699999999999998, -11.699999999999998, -11.699999999999998, -9.7, -13.699999999999998, -12.699999999999998, -11.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3486765797908062, "mean_inference_ms": 1.2632437744512126, "mean_action_processing_ms": 0.09093507311301752, "mean_env_wait_ms": 4.222009618470662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 92000, "timesteps_this_iter": 0, "agent_timesteps_total": 92000, "timers": {"sample_time_ms": 10230.076, "sample_throughput": 391.004, "load_time_ms": 0.344, "load_throughput": 11644375.347, "learn_time_ms": 2364.644, "learn_throughput": 1691.586, "update_time_ms": 2.111}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 15.760763168334961, "policy_loss": -0.025411395356059074, "vf_loss": 15.779040336608887, "vf_explained_var": 0.20833876729011536, "kl": 0.010569619946181774, "entropy": 2.4622716903686523, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 92000, "num_agent_steps_sampled": 92000, "num_steps_trained": 92000, "num_agent_steps_trained": 92000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4840, "training_iteration": 23, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-03", "timestamp": 1642601343, "time_this_iter_s": 10.424020051956177, "time_total_s": 240.18000650405884, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 240.18000650405884, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 47.660000000000004, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -5.699999999999999, "episode_reward_min": -24.700000000000006, "episode_reward_mean": -11.975471698113209, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.699999999999998, -10.699999999999998, -12.699999999999998, -7.699999999999999, -12.699999999999998, -9.2, -9.699999999999998, -7.699999999999999, -7.6999999999999975, -11.4, -9.9, -9.2, -9.699999999999998, -12.699999999999998, -13.699999999999998, -7.699999999999999, -8.699999999999998, -12.0, -7.6999999999999975, -15.699999999999996, -22.700000000000003, -8.699999999999998, -9.699999999999998, -24.700000000000006, -17.7, -14.699999999999998, -9.7, -7.699999999999999, -6.6999999999999975, -6.699999999999999, -10.699999999999998, -10.699999999999998, -10.699999999999998, -9.699999999999998, -7.6999999999999975, -15.999999999999998, -10.699999999999998, -7.6999999999999975, -9.7, -9.7, -9.9, -11.699999999999998, -9.699999999999998, -8.699999999999998, -13.7, -17.7, -10.7, -18.700000000000003, -8.699999999999998, -13.699999999999998, -8.699999999999998, -10.699999999999998, -9.699999999999998, -10.699999999999998, -17.7, -14.299999999999999, -7.699999999999999, -18.7, -12.699999999999998, -10.499999999999998, -12.699999999999998, -10.700000000000001, -8.9, -11.699999999999998, -10.699999999999998, -23.700000000000006, -16.7, -6.699999999999999, -8.699999999999998, -11.699999999999998, -12.699999999999996, -15.699999999999998, -14.699999999999998, -13.699999999999998, -9.699999999999998, -9.499999999999998, -10.299999999999999, -7.699999999999999, -13.7, -11.699999999999998, -9.699999999999998, -10.699999999999998, -14.699999999999996, -8.4, -8.699999999999998, -6.6999999999999975, -10.9, -9.699999999999998, -10.699999999999998, -11.699999999999998, -11.599999999999998, -9.699999999999998, -20.700000000000003, -9.699999999999998, -14.699999999999998, -11.7, -17.7, -22.700000000000003, -8.699999999999998, -7.6999999999999975, -11.699999999999998, -11.699999999999998, -12.699999999999998, -13.1, -13.699999999999998, -10.899999999999999, -8.7, -9.699999999999998, -11.699999999999998, -11.699999999999998, -11.699999999999998, -8.699999999999998, -7.699999999999999, -18.7, -7.699999999999999, -9.699999999999998, -12.699999999999998, -13.699999999999998, -19.700000000000003, -8.7, -11.700000000000001, -11.699999999999998, -9.699999999999998, -7.2, -17.700000000000003, -11.699999999999998, -9.699999999999998, -8.699999999999998, -12.299999999999999, -23.7, -12.7, -9.699999999999998, -8.7, -9.699999999999998, -11.399999999999999, -11.699999999999998, -23.700000000000006, -6.700000000000001, -13.699999999999998, -10.699999999999998, -6.6999999999999975, -6.2, -10.699999999999998, -11.699999999999998, -8.699999999999998, -9.2, -17.7, -9.699999999999998, -11.699999999999998, -10.699999999999998, -12.699999999999998, -9.699999999999998, -9.699999999999998, -11.699999999999998, -7.699999999999999, -10.699999999999998, -16.7, -12.699999999999996, -20.7, -19.700000000000006, -10.699999999999998, -8.699999999999998, -15.699999999999998, -14.699999999999998, -11.299999999999999, -8.699999999999998, -8.699999999999998, -7.5, -8.7, -12.599999999999998, -10.699999999999998, -22.700000000000003, -10.699999999999998, -9.699999999999998, -11.5, -10.699999999999998, -14.299999999999999, -18.7, -10.5, -10.699999999999998, -22.7, -20.700000000000003, -10.699999999999998, -24.700000000000006, -12.699999999999998, -12.699999999999998, -18.7, -19.700000000000006, -13.699999999999996, -8.699999999999998, -9.699999999999998, -24.700000000000006, -8.7, -23.700000000000003, -5.699999999999999, -11.699999999999998, -14.399999999999999, -7.6999999999999975, -12.699999999999998, -19.7, -8.7, -11.699999999999998, -11.699999999999998, -8.699999999999998, -8.699999999999998, -8.699999999999998, -12.0, -9.7, -12.7, -8.699999999999998, -10.699999999999998, -10.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.351998967442144, "mean_inference_ms": 1.2647627761009248, "mean_action_processing_ms": 0.09101850281883828, "mean_env_wait_ms": 4.226609265465056, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 96000, "timesteps_this_iter": 0, "agent_timesteps_total": 96000, "timers": {"sample_time_ms": 10327.447, "sample_throughput": 387.317, "load_time_ms": 0.343, "load_throughput": 11658130.776, "learn_time_ms": 2285.93, "learn_throughput": 1749.835, "update_time_ms": 2.146}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 16.45482635498047, "policy_loss": -0.02027329057455063, "vf_loss": 16.468257904052734, "vf_explained_var": 0.18158338963985443, "kl": 0.01013515330851078, "entropy": 2.4039077758789062, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 96000, "num_agent_steps_sampled": 96000, "num_steps_trained": 96000, "num_agent_steps_trained": 96000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5052, "training_iteration": 24, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-13", "timestamp": 1642601353, "time_this_iter_s": 10.51001501083374, "time_total_s": 250.69002151489258, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 250.69002151489258, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 46.93999999999999, "ram_util_percent": 62.31333333333331}}
{"episode_reward_max": -5.699999999999999, "episode_reward_min": -27.700000000000003, "episode_reward_mean": -11.432692307692308, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.699999999999998, -9.699999999999998, -8.699999999999998, -10.399999999999999, -9.699999999999998, -9.699999999999998, -11.8, -7.6999999999999975, -21.700000000000003, -8.699999999999998, -10.699999999999998, -27.700000000000003, -17.1, -14.699999999999998, -8.699999999999998, -8.3, -9.699999999999998, -11.699999999999998, -10.699999999999998, -8.699999999999998, -12.2, -14.699999999999998, -15.699999999999998, -11.699999999999998, -10.5, -9.700000000000001, -9.699999999999998, -11.699999999999998, -12.699999999999998, -8.5, -7.699999999999999, -6.6999999999999975, -9.100000000000001, -9.699999999999998, -11.699999999999998, -12.699999999999998, -9.699999999999998, -12.699999999999998, -8.6, -15.699999999999998, -25.699999999999996, -9.699999999999998, -9.4, -25.700000000000003, -10.699999999999998, -8.7, -9.2, -12.699999999999998, -13.699999999999998, -12.2, -21.700000000000003, -8.699999999999998, -11.699999999999998, -9.699999999999998, -8.9, -11.7, -8.7, -7.6999999999999975, -10.699999999999998, -7.6999999999999975, -13.699999999999998, -13.0, -11.699999999999998, -8.699999999999998, -10.699999999999998, -11.699999999999998, -12.699999999999998, -8.699999999999998, -9.699999999999998, -9.699999999999998, -11.699999999999996, -9.699999999999998, -13.699999999999998, -9.1, -12.699999999999998, -8.7, -12.9, -8.699999999999998, -11.700000000000001, -26.700000000000003, -9.599999999999998, -8.7, -9.7, -7.6999999999999975, -11.699999999999998, -7.6999999999999975, -7.6999999999999975, -7.5, -5.699999999999999, -15.699999999999998, -19.700000000000003, -6.6999999999999975, -14.700000000000001, -6.699999999999999, -8.699999999999998, -10.699999999999998, -9.7, -12.699999999999998, -8.2, -6.699999999999999, -11.2, -10.7, -13.9, -10.699999999999998, -19.700000000000003, -11.699999999999998, -11.699999999999998, -12.699999999999998, -11.2, -7.699999999999999, -5.699999999999999, -17.7, -5.699999999999999, -7.699999999999999, -14.699999999999998, -22.6, -11.699999999999998, -8.699999999999998, -9.699999999999998, -19.700000000000003, -18.7, -16.4, -8.7, -11.699999999999998, -15.699999999999998, -7.6999999999999975, -8.2, -6.3, -24.700000000000006, -8.7, -13.699999999999996, -10.699999999999998, -9.700000000000001, -8.699999999999998, -11.699999999999996, -10.699999999999998, -10.699999999999998, -8.699999999999998, -8.699999999999998, -8.699999999999998, -13.699999999999998, -17.7, -20.700000000000003, -10.699999999999998, -6.699999999999999, -14.699999999999998, -14.6, -11.699999999999998, -9.5, -9.5, -7.6999999999999975, -10.699999999999998, -8.7, -8.7, -9.699999999999998, -8.699999999999998, -10.699999999999998, -12.699999999999998, -7.699999999999999, -9.9, -7.6999999999999975, -10.699999999999998, -11.699999999999996, -11.699999999999998, -7.699999999999999, -11.699999999999998, -11.699999999999998, -9.699999999999998, -9.699999999999998, -11.299999999999999, -11.699999999999998, -13.699999999999998, -11.699999999999998, -5.699999999999999, -22.700000000000003, -8.2, -8.7, -8.7, -7.7, -8.699999999999998, -13.5, -11.699999999999998, -21.700000000000006, -7.699999999999999, -12.8, -11.699999999999998, -9.699999999999998, -12.699999999999998, -9.699999999999998, -21.0, -10.699999999999998, -9.699999999999998, -8.699999999999998, -10.2, -15.200000000000001, -16.699999999999996, -6.699999999999999, -13.699999999999998, -10.699999999999998, -8.699999999999998, -19.700000000000003, -7.6999999999999975, -8.699999999999998, -13.4, -11.699999999999996, -7.699999999999999, -12.299999999999999, -9.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.350150947594451, "mean_inference_ms": 1.2642393793651023, "mean_action_processing_ms": 0.09098706600747201, "mean_env_wait_ms": 4.224165032555649, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 100000, "timesteps_this_iter": 0, "agent_timesteps_total": 100000, "timers": {"sample_time_ms": 10099.349, "sample_throughput": 396.065, "load_time_ms": 0.342, "load_throughput": 11703673.526, "learn_time_ms": 2244.948, "learn_throughput": 1781.778, "update_time_ms": 2.171}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 16.97203826904297, "policy_loss": -0.026058869436383247, "vf_loss": 16.99135398864746, "vf_explained_var": 0.16456344723701477, "kl": 0.009988147765398026, "entropy": 2.358402729034424, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 100000, "num_steps_trained": 100000, "num_agent_steps_trained": 100000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5260, "training_iteration": 25, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-23", "timestamp": 1642601363, "time_this_iter_s": 10.087156295776367, "time_total_s": 260.77717781066895, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 260.77717781066895, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 45.23571428571428, "ram_util_percent": 62.314285714285695}}
{"episode_reward_max": -4.699999999999998, "episode_reward_min": -31.2, "episode_reward_mean": -11.304245283018869, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.7, -14.699999999999998, -20.700000000000003, -10.699999999999998, -8.699999999999998, -11.699999999999998, -8.699999999999998, -10.2, -18.2, -17.7, -7.6999999999999975, -10.699999999999998, -8.699999999999998, -17.9, -9.9, -13.599999999999998, -10.699999999999998, -6.699999999999999, -10.699999999999998, -8.7, -9.7, -9.699999999999998, -10.699999999999998, -10.7, -9.699999999999998, -7.6999999999999975, -8.7, -9.699999999999998, -9.699999999999998, -7.599999999999998, -9.699999999999998, -17.700000000000006, -8.699999999999998, -9.7, -8.699999999999998, -8.699999999999998, -9.699999999999998, -6.699999999999999, -5.699999999999999, -19.7, -26.5, -11.699999999999998, -7.6999999999999975, -23.6, -7.6999999999999975, -6.699999999999999, -10.699999999999998, -12.699999999999998, -8.9, -8.7, -8.699999999999998, -9.699999999999998, -8.699999999999998, -20.700000000000003, -7.6999999999999975, -9.7, -17.8, -9.699999999999998, -10.699999999999998, -8.699999999999998, -7.6999999999999975, -14.7, -8.699999999999998, -9.699999999999998, -13.7, -9.7, -8.100000000000001, -12.699999999999998, -9.299999999999999, -8.699999999999998, -11.6, -9.699999999999998, -14.699999999999998, -13.699999999999998, -6.699999999999999, -11.699999999999998, -6.699999999999999, -23.700000000000003, -7.6999999999999975, -31.2, -11.7, -22.700000000000003, -9.699999999999998, -6.699999999999999, -12.699999999999998, -8.7, -15.699999999999998, -10.699999999999998, -10.699999999999998, -20.7, -20.700000000000003, -19.7, -6.699999999999999, -8.7, -7.6999999999999975, -25.3, -8.699999999999998, -9.699999999999998, -9.7, -8.7, -13.699999999999998, -9.7, -7.699999999999999, -8.699999999999998, -8.7, -7.6999999999999975, -8.2, -8.699999999999998, -11.699999999999998, -18.700000000000003, -9.699999999999998, -8.699999999999998, -18.7, -6.699999999999999, -7.699999999999999, -6.699999999999999, -9.699999999999998, -11.699999999999998, -20.4, -9.7, -7.3, -17.7, -10.699999999999996, -8.7, -6.6999999999999975, -8.699999999999998, -15.0, -7.699999999999999, -11.699999999999998, -8.699999999999998, -10.699999999999998, -23.700000000000006, -13.699999999999998, -10.699999999999998, -8.699999999999998, -9.699999999999998, -9.7, -7.699999999999999, -13.699999999999998, -20.700000000000003, -12.5, -9.7, -8.699999999999998, -10.7, -7.699999999999999, -18.7, -8.699999999999998, -17.7, -7.699999999999999, -9.699999999999998, -26.400000000000002, -6.699999999999999, -11.699999999999998, -13.5, -18.700000000000003, -10.7, -7.6999999999999975, -9.699999999999998, -7.699999999999999, -8.699999999999998, -10.699999999999998, -5.699999999999999, -13.699999999999998, -8.7, -7.6, -11.699999999999998, -9.699999999999998, -9.699999999999998, -10.2, -9.7, -12.299999999999999, -20.700000000000003, -4.699999999999998, -9.699999999999998, -9.699999999999998, -13.7, -7.5, -11.699999999999998, -10.699999999999998, -16.5, -9.699999999999998, -6.6999999999999975, -10.599999999999996, -11.0, -8.699999999999998, -9.499999999999998, -7.699999999999999, -10.7, -19.6, -11.699999999999998, -12.699999999999998, -6.699999999999999, -8.699999999999998, -13.699999999999998, -6.699999999999999, -8.699999999999998, -13.699999999999996, -8.699999999999998, -9.699999999999998, -6.6999999999999975, -9.7, -8.7, -15.699999999999998, -10.699999999999998, -9.699999999999998, -7.699999999999999, -7.6999999999999975, -18.7, -11.699999999999998, -12.699999999999998, -9.699999999999998, -11.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.35037606320268, "mean_inference_ms": 1.2639507798615621, "mean_action_processing_ms": 0.09097827314839933, "mean_env_wait_ms": 4.222707449759452, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 104000, "timesteps_this_iter": 0, "agent_timesteps_total": 104000, "timers": {"sample_time_ms": 10087.897, "sample_throughput": 396.515, "load_time_ms": 0.341, "load_throughput": 11717569.493, "learn_time_ms": 2221.441, "learn_throughput": 1800.633, "update_time_ms": 2.14}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 17.19410514831543, "policy_loss": -0.025027232244610786, "vf_loss": 17.211223602294922, "vf_explained_var": 0.17453670501708984, "kl": 0.011717699468135834, "entropy": 2.3384487628936768, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 104000, "num_agent_steps_sampled": 104000, "num_steps_trained": 104000, "num_agent_steps_trained": 104000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5472, "training_iteration": 26, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-34", "timestamp": 1642601374, "time_this_iter_s": 10.309531927108765, "time_total_s": 271.0867097377777, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 271.0867097377777, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 45.22666666666666, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -5.699999999999999, "episode_reward_min": -32.7, "episode_reward_mean": -10.880188679245284, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.2, -12.699999999999998, -7.300000000000001, -18.7, -8.699999999999998, -9.7, -15.699999999999998, -12.699999999999998, -9.699999999999998, -8.699999999999998, -10.699999999999998, -10.699999999999998, -22.700000000000003, -9.7, -14.699999999999998, -12.699999999999998, -14.100000000000001, -9.699999999999998, -11.699999999999998, -7.6999999999999975, -20.299999999999997, -8.699999999999998, -7.6999999999999975, -18.700000000000003, -9.699999999999998, -32.7, -12.699999999999998, -10.699999999999998, -9.699999999999998, -11.7, -7.6999999999999975, -8.499999999999998, -6.699999999999999, -11.699999999999998, -16.7, -8.7, -10.7, -14.7, -12.699999999999998, -11.699999999999998, -6.6999999999999975, -9.699999999999998, -11.699999999999998, -8.699999999999998, -8.7, -12.699999999999998, -11.699999999999996, -11.9, -7.699999999999999, -9.699999999999998, -8.7, -8.699999999999998, -20.7, -12.699999999999998, -7.6999999999999975, -12.699999999999998, -9.699999999999998, -12.699999999999998, -16.7, -7.6999999999999975, -7.699999999999999, -7.6999999999999975, -8.5, -10.699999999999998, -5.699999999999999, -10.699999999999998, -7.6999999999999975, -5.700000000000001, -13.699999999999998, -9.699999999999998, -11.699999999999998, -8.699999999999998, -5.700000000000001, -10.699999999999998, -10.7, -9.699999999999998, -7.6999999999999975, -9.7, -7.6999999999999975, -12.699999999999998, -13.599999999999998, -11.699999999999998, -7.6999999999999975, -9.699999999999998, -8.699999999999998, -12.699999999999996, -7.6999999999999975, -7.699999999999999, -8.7, -19.700000000000003, -9.699999999999998, -9.699999999999998, -8.699999999999998, -6.699999999999999, -10.699999999999998, -6.699999999999999, -8.699999999999998, -18.6, -23.700000000000003, -9.699999999999998, -7.699999999999999, -8.699999999999998, -10.699999999999998, -9.699999999999998, -9.7, -7.699999999999999, -10.699999999999998, -16.699999999999996, -9.699999999999998, -7.6999999999999975, -10.699999999999998, -6.699999999999999, -10.599999999999998, -7.699999999999999, -7.6999999999999975, -10.699999999999998, -9.699999999999998, -15.699999999999998, -6.699999999999999, -9.699999999999998, -8.3, -9.699999999999998, -6.700000000000001, -7.6999999999999975, -17.6, -17.7, -10.699999999999998, -16.699999999999996, -8.699999999999998, -9.699999999999998, -8.699999999999998, -18.700000000000003, -11.499999999999998, -15.499999999999998, -9.699999999999998, -15.599999999999998, -5.700000000000001, -7.6999999999999975, -7.6999999999999975, -11.699999999999998, -10.699999999999998, -7.699999999999999, -9.7, -7.5, -9.699999999999998, -9.599999999999998, -9.699999999999996, -7.699999999999999, -10.699999999999998, -9.699999999999998, -8.7, -12.8, -9.699999999999998, -10.699999999999998, -9.699999999999998, -8.499999999999998, -7.6999999999999975, -11.0, -8.699999999999998, -9.7, -9.2, -6.699999999999999, -8.7, -5.699999999999999, -8.699999999999998, -9.499999999999998, -9.699999999999998, -15.7, -16.7, -7.6, -9.7, -12.699999999999998, -7.699999999999999, -13.699999999999998, -6.699999999999999, -18.7, -22.700000000000006, -9.699999999999998, -22.700000000000006, -6.699999999999999, -13.699999999999998, -9.9, -7.699999999999999, -10.699999999999998, -9.699999999999998, -9.699999999999998, -29.5, -8.699999999999998, -8.2, -9.699999999999998, -8.699999999999998, -10.699999999999998, -17.7, -7.6999999999999975, -8.699999999999998, -14.699999999999998, -19.7, -6.699999999999999, -6.6999999999999975, -8.7, -13.699999999999998, -9.699999999999998, -10.7, -10.699999999999998, -9.7, -11.699999999999998, -8.699999999999998, -11.699999999999998, -12.699999999999998, -14.699999999999998, -7.6999999999999975, -6.6999999999999975], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.351968711201586, "mean_inference_ms": 1.2640421454374278, "mean_action_processing_ms": 0.0909657850251728, "mean_env_wait_ms": 4.223047265352698, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 108000, "timesteps_this_iter": 0, "agent_timesteps_total": 108000, "timers": {"sample_time_ms": 10121.227, "sample_throughput": 395.209, "load_time_ms": 0.339, "load_throughput": 11814940.845, "learn_time_ms": 2170.722, "learn_throughput": 1842.705, "update_time_ms": 2.124}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 15.583454132080078, "policy_loss": -0.012643269263207912, "vf_loss": 15.590812683105469, "vf_explained_var": 0.17584316432476044, "kl": 0.00782742165029049, "entropy": 2.2811288833618164, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 108000, "num_agent_steps_sampled": 108000, "num_steps_trained": 108000, "num_agent_steps_trained": 108000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5684, "training_iteration": 27, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-44", "timestamp": 1642601384, "time_this_iter_s": 10.296558141708374, "time_total_s": 281.3832678794861, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 281.3832678794861, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 45.73571428571428, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -4.6999999999999975, "episode_reward_min": -28.2, "episode_reward_mean": -9.75625, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.6999999999999975, -8.100000000000001, -10.499999999999998, -12.699999999999998, -9.699999999999998, -4.699999999999999, -9.699999999999998, -6.699999999999999, -8.7, -8.699999999999998, -7.699999999999999, -16.5, -8.7, -9.699999999999998, -9.699999999999998, -7.6999999999999975, -8.7, -14.699999999999998, -9.699999999999998, -7.699999999999999, -8.699999999999998, -9.699999999999998, -11.8, -9.699999999999998, -12.699999999999998, -9.7, -7.6999999999999975, -7.6999999999999975, -7.6999999999999975, -6.6999999999999975, -6.699999999999999, -8.699999999999998, -6.6999999999999975, -7.699999999999999, -4.700000000000001, -5.699999999999999, -8.699999999999998, -20.8, -7.6999999999999975, -7.699999999999999, -12.699999999999998, -11.699999999999998, -10.699999999999998, -8.699999999999998, -7.6999999999999975, -9.699999999999998, -10.699999999999998, -21.700000000000003, -9.699999999999998, -7.7, -13.699999999999998, -5.699999999999999, -10.699999999999998, -8.699999999999998, -8.7, -6.699999999999999, -8.599999999999998, -8.7, -20.700000000000006, -10.699999999999998, -8.7, -7.699999999999999, -4.699999999999999, -10.7, -6.6999999999999975, -8.699999999999998, -5.6999999999999975, -9.699999999999998, -7.2, -5.7, -12.5, -9.699999999999998, -12.699999999999998, -7.6999999999999975, -11.699999999999998, -7.7, -8.7, -9.7, -7.9, -18.700000000000003, -9.699999999999998, -13.299999999999999, -8.699999999999998, -14.699999999999998, -12.699999999999998, -8.699999999999998, -8.699999999999998, -8.699999999999998, -6.6999999999999975, -8.7, -12.699999999999998, -10.7, -6.6999999999999975, -9.7, -7.699999999999999, -5.700000000000001, -6.699999999999999, -10.7, -7.6999999999999975, -7.699999999999999, -6.699999999999999, -6.699999999999999, -8.699999999999998, -13.699999999999998, -7.699999999999999, -7.699999999999999, -8.699999999999998, -17.599999999999998, -7.699999999999999, -10.2, -5.6999999999999975, -8.299999999999999, -7.699999999999999, -8.7, -8.699999999999998, -6.699999999999999, -7.699999999999999, -5.699999999999999, -15.699999999999996, -13.699999999999998, -6.2, -7.699999999999999, -8.699999999999998, -10.699999999999998, -16.7, -13.2, -9.699999999999998, -8.699999999999998, -6.700000000000001, -4.699999999999999, -9.7, -7.6999999999999975, -9.7, -8.7, -7.6999999999999975, -9.699999999999998, -8.699999999999998, -7.699999999999999, -10.699999999999998, -8.5, -8.499999999999998, -8.699999999999998, -8.7, -4.6999999999999975, -17.700000000000003, -7.6999999999999975, -28.2, -6.699999999999999, -11.699999999999998, -11.699999999999998, -19.700000000000003, -7.6999999999999975, -8.7, -9.7, -8.699999999999998, -9.699999999999998, -10.699999999999998, -7.6999999999999975, -25.700000000000006, -8.699999999999998, -12.699999999999998, -8.7, -10.2, -8.699999999999998, -8.699999999999998, -18.7, -17.7, -8.699999999999998, -8.5, -10.7, -5.6999999999999975, -5.7, -9.699999999999998, -7.6999999999999975, -7.6999999999999975, -7.699999999999999, -8.100000000000001, -19.7, -7.699999999999999, -10.9, -23.700000000000003, -6.699999999999999, -4.699999999999998, -10.699999999999998, -5.700000000000001, -7.700000000000001, -8.7, -6.699999999999999, -7.699999999999999, -12.699999999999998, -8.699999999999998, -5.700000000000001, -9.699999999999998, -8.699999999999998, -7.6999999999999975, -13.699999999999998, -10.7, -9.499999999999998, -10.699999999999998, -6.699999999999999, -5.6999999999999975, -8.2, -13.699999999999998, -11.699999999999998, -10.699999999999998, -27.699999999999996, -7.6999999999999975, -7.9], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3499101912318405, "mean_inference_ms": 1.2640350014221444, "mean_action_processing_ms": 0.09092948789328516, "mean_env_wait_ms": 4.220113954877501, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 112000, "timesteps_this_iter": 0, "agent_timesteps_total": 112000, "timers": {"sample_time_ms": 10093.715, "sample_throughput": 396.286, "load_time_ms": 0.337, "load_throughput": 11877675.044, "learn_time_ms": 2141.651, "learn_throughput": 1867.718, "update_time_ms": 2.139}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 13.106864929199219, "policy_loss": -0.02204044908285141, "vf_loss": 13.120999336242676, "vf_explained_var": 0.176822230219841, "kl": 0.01171148382127285, "entropy": 2.2521729469299316, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 112000, "num_agent_steps_sampled": 112000, "num_steps_trained": 112000, "num_agent_steps_trained": 112000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5892, "training_iteration": 28, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-09-54", "timestamp": 1642601394, "time_this_iter_s": 10.015497207641602, "time_total_s": 291.3987650871277, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 291.3987650871277, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 43.88, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -3.700000000000001, "episode_reward_min": -45.7, "episode_reward_mean": -9.893867924528301, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.699999999999998, -6.699999999999999, -16.7, -15.699999999999998, -6.699999999999999, -5.500000000000001, -9.7, -7.1000000000000005, -7.6999999999999975, -6.699999999999999, -7.699999999999999, -6.6999999999999975, -17.7, -9.3, -7.300000000000001, -6.699999999999999, -5.6, -9.7, -12.699999999999998, -8.699999999999998, -4.699999999999999, -5.6999999999999975, -11.7, -7.6999999999999975, -8.699999999999998, -14.699999999999998, -8.7, -15.699999999999998, -8.699999999999998, -8.699999999999998, -8.699999999999998, -7.699999999999999, -7.699999999999999, -8.699999999999998, -6.699999999999999, -11.699999999999998, -6.699999999999999, -8.2, -8.699999999999998, -8.699999999999998, -23.700000000000003, -9.3, -8.299999999999999, -13.699999999999998, -8.699999999999998, -20.700000000000003, -13.2, -10.700000000000001, -13.699999999999998, -45.7, -30.700000000000003, -7.5, -8.699999999999998, -8.9, -8.699999999999998, -5.699999999999999, -3.700000000000001, -7.6999999999999975, -5.699999999999999, -7.699999999999999, -22.700000000000003, -7.699999999999999, -10.699999999999998, -6.699999999999999, -14.7, -10.699999999999998, -5.699999999999999, -7.6999999999999975, -5.699999999999999, -7.6999999999999975, -15.699999999999998, -31.700000000000003, -8.299999999999999, -5.6999999999999975, -8.7, -7.699999999999999, -17.0, -11.699999999999998, -8.699999999999998, -8.7, -7.699999999999999, -7.699999999999999, -8.7, -6.699999999999999, -7.699999999999999, -8.7, -8.7, -8.7, -11.699999999999998, -6.699999999999999, -6.699999999999999, -14.7, -9.9, -6.6999999999999975, -13.7, -8.699999999999998, -30.700000000000003, -15.7, -10.699999999999998, -11.7, -11.699999999999998, -7.6999999999999975, -18.700000000000003, -19.7, -4.700000000000001, -8.699999999999998, -10.699999999999998, -6.6999999999999975, -8.7, -7.699999999999999, -12.699999999999998, -9.7, -10.7, -6.700000000000001, -9.699999999999998, -10.699999999999998, -5.699999999999999, -6.6999999999999975, -14.699999999999998, -7.699999999999999, -8.5, -7.6, -5.699999999999999, -6.699999999999999, -6.6999999999999975, -9.699999999999998, -7.699999999999999, -10.699999999999998, -8.699999999999998, -8.7, -9.7, -14.699999999999998, -7.1, -22.700000000000003, -10.7, -11.7, -7.6999999999999975, -3.700000000000001, -10.699999999999998, -6.6999999999999975, -7.699999999999999, -10.699999999999998, -8.699999999999998, -11.699999999999998, -5.699999999999999, -4.699999999999999, -21.700000000000003, -5.699999999999999, -7.699999999999999, -5.699999999999999, -7.6999999999999975, -5.699999999999999, -8.699999999999998, -9.7, -9.7, -14.699999999999996, -9.2, -7.699999999999999, -4.699999999999999, -6.699999999999999, -6.699999999999999, -10.699999999999998, -7.6999999999999975, -5.699999999999999, -10.699999999999998, -6.6999999999999975, -9.699999999999998, -5.699999999999999, -9.699999999999998, -10.699999999999998, -9.699999999999998, -10.2, -6.699999999999999, -13.699999999999998, -8.699999999999998, -5.700000000000001, -6.699999999999999, -8.2, -7.699999999999999, -8.7, -8.7, -4.7, -7.6, -5.699999999999999, -16.7, -6.699999999999999, -8.5, -8.7, -5.699999999999999, -8.699999999999998, -9.7, -7.6999999999999975, -5.700000000000001, -15.699999999999998, -10.699999999999998, -4.7, -17.7, -9.7, -13.7, -7.699999999999999, -8.7, -13.699999999999998, -9.7, -9.7, -5.699999999999999, -10.699999999999998, -4.699999999999999, -7.699999999999999, -7.699999999999999, -23.9, -9.699999999999998, -8.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.349281145792115, "mean_inference_ms": 1.2634736000063138, "mean_action_processing_ms": 0.09088553887746043, "mean_env_wait_ms": 4.218283036565671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 116000, "timesteps_this_iter": 0, "agent_timesteps_total": 116000, "timers": {"sample_time_ms": 10126.062, "sample_throughput": 395.02, "load_time_ms": 0.334, "load_throughput": 11987150.614, "learn_time_ms": 2105.955, "learn_throughput": 1899.376, "update_time_ms": 2.136}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 20.208187103271484, "policy_loss": -0.016265837475657463, "vf_loss": 20.218610763549805, "vf_explained_var": 0.1276155710220337, "kl": 0.008655711077153683, "entropy": 2.247356414794922, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 116000, "num_agent_steps_sampled": 116000, "num_steps_trained": 116000, "num_agent_steps_trained": 116000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6104, "training_iteration": 29, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-04", "timestamp": 1642601404, "time_this_iter_s": 10.156344175338745, "time_total_s": 301.55510926246643, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 301.55510926246643, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 44.542857142857144, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -2.700000000000001, "episode_reward_min": -29.700000000000003, "episode_reward_mean": -9.928365384615384, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.699999999999999, -12.699999999999998, -6.699999999999999, -13.299999999999999, -5.699999999999999, -9.699999999999998, -9.699999999999998, -8.699999999999998, -9.7, -20.7, -16.1, -5.699999999999999, -5.700000000000001, -9.699999999999996, -5.699999999999999, -21.700000000000006, -6.6999999999999975, -20.7, -7.699999999999999, -7.6999999999999975, -9.699999999999998, -16.7, -5.700000000000001, -24.700000000000003, -13.699999999999998, -8.7, -6.6999999999999975, -7.699999999999999, -13.7, -6.699999999999999, -9.699999999999998, -8.7, -14.699999999999998, -23.700000000000003, -9.7, -19.700000000000006, -5.699999999999999, -12.6, -4.699999999999998, -8.3, -4.700000000000001, -21.700000000000003, -5.700000000000001, -7.6999999999999975, -7.6999999999999975, -7.2, -12.699999999999998, -7.699999999999999, -10.7, -5.699999999999999, -6.699999999999999, -8.699999999999998, -8.699999999999998, -7.699999999999999, -21.700000000000003, -7.699999999999999, -6.6999999999999975, -13.699999999999998, -10.699999999999998, -7.699999999999999, -4.7, -4.699999999999999, -26.700000000000003, -8.699999999999998, -4.700000000000001, -9.699999999999998, -4.700000000000001, -8.699999999999998, -7.699999999999999, -14.699999999999998, -7.5, -6.7, -5.5, -21.700000000000006, -6.6999999999999975, -10.699999999999998, -12.699999999999996, -7.699999999999999, -16.7, -8.7, -14.699999999999996, -7.699999999999999, -6.699999999999999, -9.2, -6.300000000000001, -6.699999999999999, -21.4, -11.699999999999998, -6.5, -6.6999999999999975, -7.699999999999999, -10.699999999999998, -10.699999999999998, -6.6999999999999975, -11.699999999999996, -6.699999999999999, -17.700000000000003, -12.699999999999998, -8.7, -6.699999999999999, -6.699999999999999, -8.7, -4.699999999999998, -8.7, -5.700000000000001, -12.699999999999998, -10.699999999999998, -6.700000000000001, -10.699999999999998, -5.6999999999999975, -6.699999999999999, -9.699999999999998, -7.6999999999999975, -2.700000000000001, -6.699999999999999, -6.700000000000001, -18.2, -7.6999999999999975, -9.2, -5.6999999999999975, -4.699999999999999, -10.7, -23.8, -10.699999999999998, -10.699999999999998, -5.699999999999999, -5.700000000000001, -8.699999999999998, -11.8, -8.699999999999998, -9.699999999999998, -7.6999999999999975, -11.699999999999998, -5.700000000000001, -7.699999999999999, -9.7, -16.0, -6.6999999999999975, -8.699999999999998, -7.6999999999999975, -9.8, -6.699999999999999, -8.7, -5.6999999999999975, -9.699999999999998, -6.9, -6.700000000000001, -8.7, -18.7, -8.7, -9.699999999999998, -5.6999999999999975, -8.699999999999998, -8.7, -7.6999999999999975, -9.100000000000001, -7.699999999999999, -5.699999999999999, -7.700000000000001, -10.7, -6.699999999999999, -6.6999999999999975, -5.700000000000001, -2.700000000000001, -5.699999999999999, -8.699999999999998, -13.699999999999998, -9.699999999999998, -29.700000000000003, -14.699999999999998, -16.7, -7.699999999999999, -8.7, -6.699999999999999, -9.699999999999998, -7.699999999999999, -7.699999999999999, -9.7, -26.700000000000006, -7.2, -8.699999999999998, -11.699999999999998, -8.699999999999998, -10.7, -6.1, -10.699999999999998, -7.6999999999999975, -15.699999999999998, -21.7, -7.699999999999999, -25.700000000000006, -9.699999999999998, -21.6, -5.699999999999999, -8.699999999999998, -6.699999999999999, -5.699999999999999, -11.699999999999998, -22.700000000000006, -8.7, -11.2, -10.699999999999998, -7.699999999999999, -4.7, -5.5, -3.700000000000001, -9.699999999999998, -6.699999999999999], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.348207604117817, "mean_inference_ms": 1.2629428075466993, "mean_action_processing_ms": 0.0908505276462912, "mean_env_wait_ms": 4.215697024942283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 120000, "timesteps_this_iter": 0, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 10167.284, "sample_throughput": 393.419, "load_time_ms": 0.334, "load_throughput": 11991434.494, "learn_time_ms": 2066.867, "learn_throughput": 1935.296, "update_time_ms": 2.124}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 18.359691619873047, "policy_loss": -0.030462676659226418, "vf_loss": 18.383665084838867, "vf_explained_var": 0.13580603897571564, "kl": 0.009613297879695892, "entropy": 2.199246644973755, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 120000, "num_steps_trained": 120000, "num_agent_steps_trained": 120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6312, "training_iteration": 30, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-14", "timestamp": 1642601414, "time_this_iter_s": 10.05157208442688, "time_total_s": 311.6066813468933, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 311.6066813468933, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 44.03333333333333, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -3.7, "episode_reward_min": -34.7, "episode_reward_mean": -8.4561320754717, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.699999999999999, -6.6999999999999975, -8.7, -5.699999999999999, -7.6999999999999975, -8.7, -18.700000000000003, -6.699999999999999, -21.700000000000003, -16.7, -12.699999999999998, -5.699999999999999, -13.699999999999998, -4.700000000000001, -7.6999999999999975, -8.5, -4.2, -5.699999999999999, -5.6999999999999975, -3.700000000000001, -5.699999999999999, -9.7, -8.699999999999998, -4.6999999999999975, -4.7, -5.6999999999999975, -7.6999999999999975, -4.699999999999999, -4.699999999999999, -10.699999999999998, -10.7, -7.699999999999999, -14.699999999999998, -7.6999999999999975, -5.699999999999999, -13.699999999999998, -8.699999999999998, -8.699999999999998, -8.699999999999998, -7.699999999999999, -11.5, -8.699999999999998, -7.699999999999999, -6.699999999999999, -5.699999999999999, -4.6999999999999975, -5.699999999999999, -15.699999999999998, -12.7, -9.699999999999998, -4.699999999999999, -7.699999999999999, -5.700000000000001, -8.7, -7.6999999999999975, -6.699999999999999, -6.699999999999999, -5.699999999999999, -13.699999999999998, -5.699999999999999, -5.6999999999999975, -7.699999999999999, -11.499999999999998, -8.699999999999998, -6.6999999999999975, -6.699999999999999, -6.699999999999999, -7.699999999999999, -20.7, -6.699999999999999, -6.699999999999999, -8.699999999999998, -10.699999999999998, -3.7, -5.699999999999999, -4.7, -6.6, -6.699999999999999, -10.699999999999998, -5.699999999999999, -6.699999999999999, -13.699999999999998, -6.699999999999999, -11.7, -8.699999999999998, -11.699999999999998, -7.6999999999999975, -6.700000000000001, -4.7, -6.6999999999999975, -7.299999999999999, -9.699999999999998, -8.699999999999998, -6.6999999999999975, -5.700000000000001, -3.700000000000001, -8.699999999999998, -7.699999999999999, -8.699999999999998, -11.699999999999998, -10.699999999999998, -8.699999999999998, -7.6999999999999975, -7.699999999999999, -5.699999999999999, -6.699999999999999, -8.2, -7.6999999999999975, -7.700000000000001, -7.6999999999999975, -5.699999999999999, -5.7, -4.7, -11.699999999999998, -6.699999999999999, -10.699999999999998, -6.6999999999999975, -7.6999999999999975, -6.6999999999999975, -8.8, -3.700000000000001, -6.700000000000001, -7.699999999999999, -7.9, -6.699999999999999, -10.699999999999998, -9.699999999999998, -7.699999999999999, -8.7, -6.699999999999999, -7.6999999999999975, -8.7, -7.6999999999999975, -5.700000000000001, -7.6999999999999975, -5.699999999999999, -4.699999999999998, -12.699999999999998, -6.6999999999999975, -4.700000000000001, -8.7, -4.699999999999999, -17.7, -6.6999999999999975, -6.699999999999999, -8.699999999999998, -4.7, -8.7, -7.6999999999999975, -12.7, -29.700000000000003, -11.699999999999998, -16.7, -7.6999999999999975, -6.6999999999999975, -7.699999999999999, -17.7, -5.699999999999999, -5.699999999999999, -13.699999999999998, -7.300000000000001, -6.699999999999999, -6.6999999999999975, -5.699999999999999, -34.7, -6.699999999999999, -7.6999999999999975, -7.6999999999999975, -7.6999999999999975, -6.6999999999999975, -15.699999999999998, -12.699999999999998, -7.699999999999999, -7.6999999999999975, -8.7, -9.699999999999998, -8.699999999999998, -6.6999999999999975, -5.699999999999999, -3.7000000000000006, -10.699999999999998, -6.5, -10.699999999999998, -7.699999999999999, -4.700000000000001, -7.7, -8.699999999999998, -5.699999999999999, -10.699999999999998, -3.7000000000000015, -11.699999999999998, -5.699999999999999, -4.9, -6.6999999999999975, -7.1000000000000005, -8.7, -3.700000000000001, -7.6999999999999975, -8.7, -7.300000000000001, -4.700000000000001, -26.700000000000003, -5.699999999999999, -8.699999999999998, -4.699999999999999, -7.699999999999999, -9.7, -19.700000000000003, -4.700000000000001, -16.2, -8.7, -6.6999999999999975], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3465870211252935, "mean_inference_ms": 1.261736465221043, "mean_action_processing_ms": 0.09077509573700235, "mean_env_wait_ms": 4.210552803251321, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 124000, "timesteps_this_iter": 0, "agent_timesteps_total": 124000, "timers": {"sample_time_ms": 10171.1, "sample_throughput": 393.271, "load_time_ms": 0.334, "load_throughput": 11980302.771, "learn_time_ms": 2059.501, "learn_throughput": 1942.218, "update_time_ms": 2.092}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 13.01938533782959, "policy_loss": -0.023952223360538483, "vf_loss": 13.034310340881348, "vf_explained_var": 0.15582942962646484, "kl": 0.013375852257013321, "entropy": 2.1608500480651855, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 124000, "num_agent_steps_sampled": 124000, "num_steps_trained": 124000, "num_agent_steps_trained": 124000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6524, "training_iteration": 31, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-24", "timestamp": 1642601424, "time_this_iter_s": 9.952424764633179, "time_total_s": 321.5591061115265, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 321.5591061115265, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 43.971428571428575, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -2.7000000000000006, "episode_reward_min": -27.700000000000006, "episode_reward_mean": -8.828301886792454, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.700000000000001, -3.700000000000001, -5.699999999999999, -21.7, -10.7, -4.699999999999999, -5.699999999999999, -4.5, -7.6999999999999975, -6.1000000000000005, -7.699999999999999, -3.7000000000000015, -13.699999999999998, -20.700000000000003, -7.6999999999999975, -4.700000000000001, -11.5, -7.699999999999999, -18.7, -8.699999999999998, -10.699999999999996, -6.6999999999999975, -4.699999999999999, -8.699999999999998, -3.7000000000000006, -4.699999999999999, -5.2, -22.700000000000003, -10.7, -5.699999999999999, -9.7, -12.7, -14.699999999999998, -6.699999999999999, -12.699999999999998, -6.6999999999999975, -5.699999999999999, -13.7, -7.699999999999999, -8.7, -10.7, -6.699999999999999, -15.699999999999998, -17.700000000000003, -5.699999999999999, -27.699999999999996, -25.700000000000006, -17.599999999999998, -5.6999999999999975, -10.699999999999998, -6.6999999999999975, -21.700000000000006, -8.699999999999998, -4.700000000000001, -7.6999999999999975, -11.699999999999998, -6.6999999999999975, -7.6999999999999975, -7.6999999999999975, -14.699999999999998, -8.699999999999998, -6.699999999999999, -9.7, -5.699999999999999, -3.700000000000001, -19.700000000000003, -3.700000000000001, -6.699999999999999, -3.700000000000001, -19.700000000000003, -7.699999999999999, -8.699999999999998, -5.699999999999999, -5.700000000000001, -6.699999999999999, -18.9, -10.499999999999998, -7.6999999999999975, -5.699999999999999, -16.7, -4.700000000000001, -4.7, -6.5, -7.699999999999999, -23.700000000000006, -3.700000000000001, -4.700000000000001, -5.699999999999999, -7.699999999999999, -4.699999999999999, -22.700000000000003, -12.699999999999998, -5.699999999999999, -6.699999999999999, -6.6999999999999975, -4.700000000000001, -12.699999999999998, -5.699999999999999, -5.699999999999999, -5.699999999999999, -7.6999999999999975, -16.2, -8.699999999999998, -3.7, -7.6999999999999975, -2.7000000000000006, -5.6, -5.699999999999999, -7.699999999999999, -9.7, -16.7, -6.6999999999999975, -7.699999999999999, -8.7, -3.7000000000000006, -4.2, -3.7, -8.7, -10.699999999999998, -10.7, -8.7, -18.700000000000003, -4.699999999999999, -3.700000000000001, -4.2, -2.700000000000001, -5.699999999999999, -5.700000000000001, -6.699999999999999, -7.6999999999999975, -10.699999999999998, -4.700000000000001, -10.699999999999998, -5.699999999999999, -11.5, -19.7, -4.700000000000001, -9.7, -7.6999999999999975, -4.6999999999999975, -8.7, -12.699999999999998, -6.699999999999999, -9.699999999999998, -4.699999999999999, -19.7, -5.699999999999999, -6.699999999999999, -14.699999999999998, -4.7, -6.699999999999999, -8.699999999999998, -6.699999999999999, -11.7, -6.699999999999999, -8.6, -6.299999999999999, -4.7, -5.699999999999999, -3.700000000000001, -9.699999999999998, -4.700000000000001, -8.7, -8.7, -6.5, -4.699999999999999, -11.7, -12.7, -4.700000000000001, -4.7, -7.699999999999999, -4.699999999999998, -4.6, -4.700000000000001, -3.700000000000001, -8.7, -12.599999999999998, -10.4, -27.700000000000006, -15.699999999999998, -7.699999999999999, -5.699999999999999, -14.699999999999998, -6.699999999999999, -15.699999999999998, -26.700000000000003, -6.699999999999999, -6.6999999999999975, -11.699999999999998, -4.6999999999999975, -7.6999999999999975, -8.7, -5.700000000000001, -5.699999999999999, -12.7, -20.700000000000003, -6.6999999999999975, -8.7, -6.699999999999999, -5.699999999999999, -4.699999999999999, -6.699999999999999, -7.699999999999999, -8.699999999999998, -2.7000000000000006, -4.700000000000001, -3.7000000000000015, -4.699999999999999, -5.699999999999999, -7.6999999999999975, -8.699999999999998, -4.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.345180165778473, "mean_inference_ms": 1.261254241066364, "mean_action_processing_ms": 0.09075321706696333, "mean_env_wait_ms": 4.20903724073071, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128000, "timesteps_this_iter": 0, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 10204.659, "sample_throughput": 391.978, "load_time_ms": 0.335, "load_throughput": 11947031.261, "learn_time_ms": 2063.624, "learn_throughput": 1938.338, "update_time_ms": 2.048}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 18.323362350463867, "policy_loss": -0.020007742568850517, "vf_loss": 18.335643768310547, "vf_explained_var": 0.11938020586967468, "kl": 0.011443685740232468, "entropy": 2.1005449295043945, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6736, "training_iteration": 32, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-34", "timestamp": 1642601434, "time_this_iter_s": 10.011127710342407, "time_total_s": 331.5702338218689, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 331.5702338218689, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 44.59285714285714, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -30.700000000000006, "episode_reward_mean": -7.855769230769231, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -4.700000000000001, -5.699999999999999, -7.6999999999999975, -12.7, -9.7, -5.7, -4.700000000000001, -4.699999999999999, -6.699999999999999, -5.699999999999999, -4.700000000000001, -11.7, -6.699999999999999, -8.5, -4.700000000000001, -8.7, -4.700000000000001, -18.299999999999997, -6.9, -10.7, -4.699999999999999, -3.7000000000000015, -7.5, -4.6999999999999975, -16.7, -10.699999999999998, -5.699999999999999, -4.3, -12.7, -6.6999999999999975, -11.699999999999998, -5.700000000000001, -7.699999999999999, -1.7000000000000004, -3.7000000000000006, -5.699999999999999, -7.699999999999999, -14.699999999999998, -12.699999999999998, -7.699999999999999, -5.699999999999999, -7.700000000000001, -11.699999999999998, -11.7, -14.699999999999998, -9.299999999999999, -3.700000000000001, -7.699999999999999, -5.699999999999999, -3.2, -4.7, -13.699999999999998, -13.7, -7.699999999999999, -5.699999999999999, -3.700000000000001, -5.699999999999999, -5.699999999999999, -15.699999999999998, -4.700000000000001, -5.699999999999999, -3.7000000000000006, -30.700000000000006, -10.299999999999999, -4.700000000000001, -14.699999999999998, -25.3, -5.699999999999999, -5.700000000000001, -5.700000000000001, -5.699999999999999, -1.7000000000000004, -4.7, -5.6999999999999975, -5.700000000000001, -5.7, -3.700000000000001, -3.7, -5.699999999999999, -5.699999999999999, -4.700000000000001, -5.699999999999999, -14.7, -7.699999999999999, -6.699999999999999, -3.7000000000000006, -13.7, -4.699999999999999, -21.700000000000006, -2.7000000000000006, -5.700000000000001, -3.500000000000001, -5.2, -8.7, -10.699999999999998, -5.7, -3.7, -2.7, -12.699999999999998, -3.7000000000000006, -6.6999999999999975, -3.700000000000001, -9.7, -20.8, -4.7, -13.7, -19.700000000000003, -3.7000000000000006, -3.700000000000001, -7.699999999999999, -3.7000000000000006, -9.7, -4.700000000000001, -11.699999999999998, -4.500000000000001, -7.6999999999999975, -10.699999999999998, -4.699999999999998, -6.699999999999999, -2.7, -4.699999999999999, -3.7000000000000006, -8.699999999999998, -4.700000000000001, -5.700000000000001, -5.699999999999999, -6.699999999999999, -5.6999999999999975, -6.700000000000001, -5.699999999999999, -3.7, -6.699999999999999, -6.6999999999999975, -6.2, -5.6999999999999975, -6.6999999999999975, -4.700000000000001, -4.700000000000001, -7.699999999999999, -2.7, -4.699999999999998, -4.699999999999999, -12.699999999999998, -6.6999999999999975, -3.700000000000001, -7.699999999999999, -5.6999999999999975, -13.1, -5.699999999999999, -5.699999999999999, -5.699999999999999, -14.699999999999998, -16.7, -3.7, -14.699999999999998, -5.6999999999999975, -10.7, -5.699999999999999, -6.699999999999999, -9.7, -6.6999999999999975, -5.699999999999999, -5.7, -8.699999999999998, -12.699999999999998, -3.7000000000000006, -3.7, -4.700000000000001, -6.699999999999999, -19.700000000000003, -8.699999999999998, -5.699999999999999, -5.699999999999999, -4.700000000000001, -7.6999999999999975, -10.7, -5.699999999999999, -9.7, -16.7, -6.699999999999999, -11.699999999999998, -5.699999999999999, -8.699999999999998, -7.699999999999999, -11.699999999999998, -3.7000000000000006, -2.7000000000000006, -26.700000000000006, -19.7, -5.699999999999999, -1.7000000000000004, -12.7, -12.699999999999998, -11.699999999999998, -4.7, -5.699999999999999, -6.6999999999999975, -9.699999999999998, -7.699999999999999, -6.6999999999999975, -4.699999999999999, -6.699999999999999, -14.7, -5.700000000000001, -8.699999999999998, -19.700000000000003, -6.6999999999999975], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.342573995174941, "mean_inference_ms": 1.2601799381302687, "mean_action_processing_ms": 0.09068848599029641, "mean_env_wait_ms": 4.205604836180811, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 132000, "timesteps_this_iter": 0, "agent_timesteps_total": 132000, "timers": {"sample_time_ms": 10192.216, "sample_throughput": 392.456, "load_time_ms": 0.334, "load_throughput": 11964070.456, "learn_time_ms": 2023.497, "learn_throughput": 1976.776, "update_time_ms": 2.071}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 14.279184341430664, "policy_loss": -0.02848045527935028, "vf_loss": 14.300042152404785, "vf_explained_var": 0.13665999472141266, "kl": 0.011293184943497181, "entropy": 2.0155012607574463, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 132000, "num_agent_steps_sampled": 132000, "num_steps_trained": 132000, "num_agent_steps_trained": 132000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6944, "training_iteration": 33, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-44", "timestamp": 1642601444, "time_this_iter_s": 9.866935014724731, "time_total_s": 341.4371688365936, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 341.4371688365936, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 44.07142857142857, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -2.7, "episode_reward_min": -24.700000000000006, "episode_reward_mean": -7.482075471698114, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.699999999999998, -2.7000000000000006, -5.700000000000001, -11.7, -7.6999999999999975, -6.699999999999999, -3.7000000000000006, -4.700000000000001, -9.7, -14.699999999999998, -11.699999999999998, -14.699999999999998, -2.7000000000000015, -2.7000000000000006, -16.7, -4.7, -9.7, -15.699999999999998, -5.6999999999999975, -6.699999999999999, -8.7, -15.699999999999998, -6.699999999999999, -7.699999999999999, -4.7, -5.699999999999999, -3.7000000000000015, -3.7000000000000006, -9.699999999999998, -6.5, -8.699999999999998, -11.699999999999998, -3.7000000000000006, -7.6999999999999975, -5.699999999999999, -4.699999999999999, -6.6999999999999975, -5.699999999999999, -5.500000000000001, -4.700000000000001, -4.700000000000001, -7.699999999999999, -5.699999999999999, -5.700000000000001, -2.7, -4.699999999999999, -2.7000000000000006, -7.6999999999999975, -7.699999999999999, -15.699999999999998, -6.6999999999999975, -12.699999999999998, -5.700000000000001, -4.700000000000001, -6.699999999999999, -3.7000000000000006, -2.7, -3.700000000000001, -12.7, -4.699999999999999, -24.700000000000003, -2.7, -10.7, -2.700000000000001, -5.6999999999999975, -3.700000000000001, -4.700000000000001, -15.699999999999996, -4.700000000000001, -10.7, -5.2, -21.700000000000003, -6.700000000000001, -5.700000000000001, -4.699999999999999, -4.699999999999998, -4.700000000000001, -9.699999999999998, -5.6000000000000005, -3.3, -4.699999999999999, -6.699999999999999, -3.700000000000001, -11.7, -4.700000000000001, -5.699999999999999, -10.2, -12.699999999999998, -2.7000000000000006, -9.7, -2.700000000000001, -2.7000000000000015, -9.7, -5.699999999999999, -5.2, -8.9, -9.7, -4.700000000000001, -4.699999999999999, -2.7000000000000006, -7.699999999999999, -6.700000000000001, -2.700000000000001, -8.2, -4.7, -4.699999999999999, -13.7, -6.6999999999999975, -14.1, -9.7, -4.700000000000001, -4.7, -5.700000000000001, -23.700000000000003, -23.700000000000003, -5.700000000000001, -6.9, -8.699999999999998, -3.1, -7.699999999999999, -4.699999999999999, -4.700000000000001, -10.7, -4.699999999999999, -8.7, -4.700000000000001, -10.7, -6.699999999999999, -3.7000000000000015, -11.699999999999996, -11.7, -16.700000000000003, -5.699999999999999, -8.7, -7.6999999999999975, -11.399999999999999, -5.699999999999999, -4.700000000000001, -14.0, -4.700000000000001, -3.7000000000000006, -4.700000000000001, -8.699999999999998, -6.6999999999999975, -4.699999999999999, -4.699999999999999, -3.7000000000000006, -11.699999999999998, -4.699999999999999, -5.699999999999999, -7.699999999999999, -21.700000000000003, -3.7000000000000015, -11.699999999999998, -5.700000000000001, -2.700000000000001, -12.699999999999998, -3.7000000000000006, -10.699999999999996, -5.699999999999999, -5.699999999999999, -15.699999999999998, -8.100000000000001, -11.699999999999998, -4.699999999999999, -13.699999999999998, -5.699999999999999, -13.699999999999998, -9.7, -3.7000000000000006, -2.700000000000001, -2.700000000000001, -3.7000000000000006, -5.699999999999999, -5.300000000000001, -19.700000000000003, -5.699999999999999, -6.699999999999999, -8.699999999999998, -2.700000000000001, -8.699999999999998, -3.7000000000000006, -8.7, -8.7, -4.7, -3.7000000000000006, -5.699999999999999, -8.699999999999998, -18.700000000000003, -4.699999999999999, -5.699999999999999, -2.7000000000000006, -4.699999999999998, -4.699999999999999, -5.6999999999999975, -7.6999999999999975, -8.699999999999998, -6.700000000000001, -7.700000000000001, -24.700000000000006, -4.700000000000001, -5.700000000000001, -4.699999999999998, -4.699999999999999, -5.2, -3.700000000000001, -3.7000000000000015, -11.699999999999998, -10.7, -5.700000000000001, -3.700000000000001, -8.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3432562731353017, "mean_inference_ms": 1.259949078563662, "mean_action_processing_ms": 0.09068471292008973, "mean_env_wait_ms": 4.204190885988053, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 136000, "timesteps_this_iter": 0, "agent_timesteps_total": 136000, "timers": {"sample_time_ms": 10098.359, "sample_throughput": 396.104, "load_time_ms": 0.335, "load_throughput": 11938529.851, "learn_time_ms": 2020.185, "learn_throughput": 1980.017, "update_time_ms": 1.997}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 12.633448600769043, "policy_loss": -0.02780417911708355, "vf_loss": 12.653749465942383, "vf_explained_var": 0.1188337430357933, "kl": 0.011115203611552715, "entropy": 1.9580659866333008, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 136000, "num_agent_steps_sampled": 136000, "num_steps_trained": 136000, "num_agent_steps_trained": 136000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7156, "training_iteration": 34, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-10-54", "timestamp": 1642601454, "time_this_iter_s": 9.944446325302124, "time_total_s": 351.38161516189575, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 351.38161516189575, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 45.09285714285715, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -29.700000000000003, "episode_reward_mean": -7.051886792452832, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.700000000000001, -7.6999999999999975, -3.7000000000000006, -2.7000000000000006, -6.699999999999999, -15.699999999999998, -2.7, -4.7, -7.5, -4.700000000000001, -6.6999999999999975, -4.699999999999998, -3.7000000000000015, -4.9, -3.7, -5.2, -5.6999999999999975, -5.699999999999999, -2.7000000000000006, -5.100000000000001, -5.700000000000001, -4.699999999999999, -7.699999999999999, -6.699999999999999, -2.7000000000000015, -2.7000000000000006, -4.700000000000001, -5.699999999999999, -4.700000000000001, -2.7000000000000006, -12.7, -10.699999999999998, -3.7000000000000006, -5.700000000000001, -22.700000000000006, -14.7, -5.6999999999999975, -5.700000000000001, -11.5, -2.700000000000001, -4.300000000000001, -8.2, -11.7, -12.699999999999998, -3.700000000000001, -6.700000000000001, -15.699999999999998, -3.2, -6.699999999999999, -5.699999999999999, -8.7, -3.700000000000001, -6.6999999999999975, -6.700000000000001, -6.9, -20.700000000000003, -10.7, -5.699999999999999, -7.699999999999999, -5.699999999999999, -4.699999999999998, -14.699999999999998, -1.7000000000000004, -13.699999999999998, -4.699999999999999, -3.7, -10.699999999999998, -5.699999999999999, -15.699999999999998, -4.699999999999998, -4.699999999999999, -4.700000000000001, -4.699999999999998, -7.6999999999999975, -15.7, -11.2, -11.7, -3.700000000000001, -2.7000000000000015, -10.699999999999998, -4.699999999999999, -4.7, -10.699999999999998, -4.699999999999999, -5.699999999999998, -3.7000000000000015, -5.700000000000001, -6.699999999999999, -21.700000000000003, -8.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -15.699999999999998, -3.700000000000001, -4.699999999999999, -4.700000000000001, -5.699999999999999, -6.699999999999999, -14.699999999999998, -9.699999999999998, -3.7000000000000006, -4.700000000000001, -4.699999999999999, -18.700000000000003, -29.700000000000003, -4.6999999999999975, -3.700000000000001, -4.700000000000001, -3.700000000000001, -4.699999999999999, -11.699999999999998, -3.700000000000001, -6.699999999999999, -13.699999999999998, -6.6999999999999975, -3.7000000000000015, -2.7, -4.699999999999999, -3.6000000000000014, -2.7000000000000015, -5.699999999999999, -5.6, -12.7, -1.7000000000000004, -5.699999999999999, -10.699999999999998, -19.0, -11.699999999999998, -17.7, -8.7, -3.700000000000001, -4.700000000000001, -18.700000000000006, -21.700000000000003, -7.6999999999999975, -4.700000000000001, -1.7000000000000004, -3.700000000000001, -4.699999999999999, -10.7, -5.699999999999999, -4.700000000000001, -14.699999999999998, -2.7000000000000006, -4.1, -2.7000000000000006, -4.699999999999999, -2.7, -5.699999999999999, -4.7, -4.699999999999998, -11.699999999999998, -5.700000000000001, -4.699999999999999, -5.700000000000001, -3.700000000000001, -3.7000000000000006, -2.700000000000001, -3.7, -3.700000000000001, -10.7, -21.700000000000003, -5.599999999999999, -4.699999999999999, -11.7, -15.7, -4.700000000000001, -7.699999999999999, -4.700000000000001, -3.7000000000000015, -10.7, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -10.699999999999998, -4.7, -2.7000000000000015, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -3.7, -5.6999999999999975, -3.700000000000001, -4.699999999999998, -3.700000000000001, -3.700000000000001, -13.699999999999998, -4.9, -10.699999999999998, -5.699999999999999, -4.7, -9.699999999999998, -12.7, -3.700000000000001, -4.699999999999998, -4.7, -10.7, -2.7000000000000006, -11.699999999999998, -6.699999999999999, -4.700000000000001, -6.699999999999999, -3.7000000000000015, -8.7, -5.700000000000001, -10.7, -4.7, -4.700000000000001, -6.700000000000001, -2.7, -17.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3416408501108434, "mean_inference_ms": 1.2591404048535715, "mean_action_processing_ms": 0.09063745286784097, "mean_env_wait_ms": 4.199736465921007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 140000, "timesteps_this_iter": 0, "agent_timesteps_total": 140000, "timers": {"sample_time_ms": 10064.635, "sample_throughput": 397.431, "load_time_ms": 0.328, "load_throughput": 12198950.047, "learn_time_ms": 2016.096, "learn_throughput": 1984.033, "update_time_ms": 2.034}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 13.201769828796387, "policy_loss": -0.02574591338634491, "vf_loss": 13.221561431884766, "vf_explained_var": 0.10850419849157333, "kl": 0.008821964263916016, "entropy": 1.913130283355713, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 140000, "num_steps_trained": 140000, "num_agent_steps_trained": 140000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7368, "training_iteration": 35, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-04", "timestamp": 1642601464, "time_this_iter_s": 9.752791166305542, "time_total_s": 361.1344063282013, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 361.1344063282013, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 44.207142857142856, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -27.699999999999996, "episode_reward_mean": -6.198076923076924, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.699999999999999, -8.7, -3.700000000000001, -4.700000000000001, -4.7, -2.7000000000000006, -4.699999999999999, -6.699999999999999, -4.699999999999999, -8.2, -7.699999999999999, -17.700000000000003, -2.7000000000000006, -4.699999999999998, -6.2, -2.9, -3.7000000000000006, -4.1, -6.5, -3.700000000000001, -4.699999999999999, -4.699999999999999, -1.7000000000000004, -11.699999999999998, -8.7, -4.7, -18.7, -4.700000000000001, -3.7000000000000015, -5.699999999999999, -7.6999999999999975, -3.700000000000001, -3.7000000000000015, -5.699999999999999, -10.699999999999998, -3.700000000000001, -9.2, -9.699999999999998, -4.699999999999999, -1.7000000000000004, -4.699999999999999, -5.699999999999999, -9.7, -5.699999999999999, -5.700000000000001, -16.7, -3.7000000000000006, -2.7000000000000006, -3.700000000000001, -3.7, -5.2, -3.7000000000000006, -5.699999999999999, -8.699999999999998, -7.6999999999999975, -2.7000000000000006, -4.699999999999998, -4.699999999999998, -3.7000000000000015, -7.699999999999999, -4.699999999999999, -2.7, -11.699999999999998, -4.699999999999999, -4.600000000000001, -22.700000000000003, -1.7000000000000004, -11.7, -27.699999999999996, -5.5, -3.7000000000000006, -3.7000000000000006, -2.7000000000000006, -4.699999999999998, -10.699999999999998, -4.7, -3.7000000000000015, -3.7, -11.699999999999998, -2.7000000000000015, -5.699999999999999, -5.699999999999999, -3.700000000000001, -3.700000000000001, -3.700000000000001, -3.7000000000000015, -4.9, -6.600000000000001, -1.7000000000000004, -7.6999999999999975, -4.700000000000001, -4.699999999999999, -8.699999999999998, -4.699999999999999, -2.7, -4.699999999999999, -3.7000000000000015, -3.7000000000000006, -8.699999999999998, -3.7000000000000006, -12.699999999999998, -3.7000000000000006, -5.699999999999999, -3.7000000000000015, -1.7000000000000004, -19.700000000000003, -21.700000000000003, -4.699999999999998, -9.7, -6.700000000000001, -2.700000000000001, -3.700000000000001, -3.7000000000000006, -11.699999999999998, -4.7, -4.700000000000001, -1.7000000000000004, -4.700000000000001, -4.700000000000001, -2.7000000000000006, -3.7000000000000015, -4.700000000000001, -5.699999999999999, -1.7000000000000004, -3.7000000000000006, -9.2, -7.699999999999999, -1.7000000000000004, -9.699999999999998, -3.7000000000000006, -3.7000000000000006, -4.700000000000001, -3.7000000000000006, -6.5, -6.699999999999999, -15.7, -1.7000000000000004, -8.7, -3.7000000000000006, -4.7, -18.7, -1.7000000000000004, -3.700000000000001, -9.7, -1.7000000000000004, -10.7, -3.7000000000000006, -3.700000000000001, -16.8, -9.699999999999998, -4.699999999999999, -3.7000000000000006, -4.699999999999999, -2.7000000000000006, -3.7000000000000006, -3.7000000000000006, -4.7, -4.7, -4.700000000000001, -3.7000000000000006, -5.699999999999999, -3.7000000000000006, -5.699999999999999, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -3.700000000000001, -6.6, -4.700000000000001, -4.699999999999999, -2.700000000000001, -11.699999999999998, -3.700000000000001, -18.700000000000006, -3.7000000000000006, -2.7000000000000006, -5.699999999999999, -3.7, -4.700000000000001, -5.700000000000001, -2.7, -4.7, -3.700000000000001, -3.9000000000000004, -1.7000000000000004, -5.699999999999999, -13.299999999999999, -2.7, -17.7, -11.7, -17.7, -12.699999999999998, -3.700000000000001, -11.7, -5.700000000000001, -6.6999999999999975, -6.6999999999999975, -22.700000000000006, -3.7000000000000015, -5.6999999999999975, -3.7000000000000006, -3.2, -6.699999999999999, -2.7000000000000015, -4.699999999999999, -6.699999999999999, -2.7000000000000006, -12.499999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3422094835930007, "mean_inference_ms": 1.2601953304985138, "mean_action_processing_ms": 0.090705062319135, "mean_env_wait_ms": 4.202302545412544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 144000, "timesteps_this_iter": 0, "agent_timesteps_total": 144000, "timers": {"sample_time_ms": 10061.735, "sample_throughput": 397.546, "load_time_ms": 0.327, "load_throughput": 12225618.305, "learn_time_ms": 2042.058, "learn_throughput": 1958.808, "update_time_ms": 2.075}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 11.626898765563965, "policy_loss": -0.03004695661365986, "vf_loss": 11.649958610534668, "vf_explained_var": 0.11952473968267441, "kl": 0.010350730270147324, "entropy": 1.8540399074554443, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 144000, "num_agent_steps_sampled": 144000, "num_steps_trained": 144000, "num_agent_steps_trained": 144000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7576, "training_iteration": 36, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-14", "timestamp": 1642601474, "time_this_iter_s": 10.571170091629028, "time_total_s": 371.7055764198303, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 371.7055764198303, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 48.20666666666667, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -39.7, "episode_reward_mean": -6.421226415094342, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.699999999999998, -2.7000000000000006, -3.700000000000001, -9.699999999999998, -3.7000000000000006, -13.7, -3.7000000000000015, -4.700000000000001, -1.7000000000000004, -5.699999999999999, -3.700000000000001, -3.7000000000000006, -4.700000000000001, -5.2, -5.700000000000001, -9.7, -4.699999999999999, -17.700000000000003, -1.7000000000000004, -3.5000000000000004, -3.7000000000000006, -5.700000000000001, -4.7, -3.7000000000000006, -12.699999999999998, -5.700000000000001, -3.7, -3.7, -5.600000000000001, -11.7, -4.700000000000001, -5.700000000000001, -16.7, -3.7000000000000015, -9.7, -5.699999999999999, -4.700000000000001, -11.7, -3.7000000000000006, -19.700000000000003, -3.1, -14.699999999999998, -5.699999999999999, -4.700000000000001, -4.7, -9.699999999999998, -3.7000000000000006, -4.7, -5.700000000000001, -2.7, -4.300000000000001, -2.2, -4.7, -3.7000000000000015, -3.7000000000000006, -9.7, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -18.7, -5.699999999999999, -3.700000000000001, -4.700000000000001, -5.699999999999999, -4.700000000000001, -39.7, -3.700000000000001, -5.699999999999999, -3.700000000000001, -5.699999999999999, -4.6999999999999975, -28.7, -3.7000000000000006, -1.7000000000000004, -17.7, -6.700000000000001, -3.700000000000001, -5.699999999999999, -4.700000000000001, -1.7000000000000004, -4.699999999999999, -7.6999999999999975, -13.699999999999998, -5.2, -3.7000000000000015, -1.7000000000000004, -9.1, -9.7, -2.7000000000000015, -4.699999999999999, -5.700000000000001, -3.700000000000001, -2.7000000000000006, -18.700000000000006, -13.699999999999998, -7.699999999999999, -6.6999999999999975, -3.7000000000000015, -13.699999999999998, -11.7, -3.700000000000001, -9.7, -2.7000000000000015, -6.699999999999999, -1.7000000000000004, -8.699999999999998, -4.700000000000001, -3.7000000000000006, -3.7000000000000006, -3.7000000000000006, -5.6999999999999975, -12.699999999999998, -2.7, -3.7000000000000006, -6.700000000000001, -4.7, -4.700000000000001, -5.700000000000001, -2.7000000000000006, -5.700000000000001, -3.7000000000000006, -9.7, -4.700000000000001, -3.7000000000000015, -3.700000000000001, -1.7000000000000004, -8.7, -12.7, -7.699999999999999, -9.699999999999998, -4.700000000000001, -18.7, -5.700000000000001, -2.7, -4.699999999999998, -2.7, -3.7, -3.700000000000001, -3.7000000000000006, -11.699999999999998, -6.700000000000001, -3.7000000000000015, -1.7000000000000004, -3.7000000000000015, -5.699999999999999, -4.700000000000001, -5.700000000000001, -1.7000000000000004, -5.700000000000001, -4.700000000000001, -5.6, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -4.699999999999999, -6.700000000000001, -3.700000000000001, -25.700000000000006, -2.7000000000000015, -5.700000000000001, -4.699999999999999, -4.700000000000001, -2.7000000000000006, -3.700000000000001, -3.7000000000000006, -8.7, -3.700000000000001, -5.699999999999999, -1.7000000000000004, -4.699999999999999, -6.699999999999999, -2.7000000000000006, -3.700000000000001, -4.700000000000001, -11.7, -14.299999999999999, -12.7, -3.7000000000000015, -13.7, -4.700000000000001, -5.700000000000001, -5.5, -3.7000000000000015, -2.7000000000000006, -8.7, -5.699999999999999, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -12.7, -2.7000000000000006, -8.7, -13.699999999999998, -2.7, -6.699999999999999, -16.700000000000003, -5.699999999999999, -11.699999999999998, -4.699999999999999, -16.700000000000003, -5.699999999999999, -3.7000000000000015, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -3.700000000000001, -5.699999999999999, -11.7, -3.700000000000001, -2.7, -4.699999999999998, -2.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3501485538645044, "mean_inference_ms": 1.2630065522745868, "mean_action_processing_ms": 0.09088345190753247, "mean_env_wait_ms": 4.211071349392678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 148000, "timesteps_this_iter": 0, "agent_timesteps_total": 148000, "timers": {"sample_time_ms": 10143.78, "sample_throughput": 394.33, "load_time_ms": 0.328, "load_throughput": 12176815.213, "learn_time_ms": 2049.311, "learn_throughput": 1951.876, "update_time_ms": 2.135}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 15.993721008300781, "policy_loss": -0.020864183083176613, "vf_loss": 16.008358001708984, "vf_explained_var": 0.09142697602510452, "kl": 0.009221388958394527, "entropy": 1.8508450984954834, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 148000, "num_agent_steps_sampled": 148000, "num_steps_trained": 148000, "num_agent_steps_trained": 148000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7788, "training_iteration": 37, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-25", "timestamp": 1642601485, "time_this_iter_s": 10.928107023239136, "time_total_s": 382.63368344306946, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 382.63368344306946, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 49.49375, "ram_util_percent": 62.3}}
{"episode_reward_max": -1.7, "episode_reward_min": -25.700000000000003, "episode_reward_mean": -5.634433962264152, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000006, -2.7000000000000006, -11.7, -14.699999999999998, -6.699999999999999, -2.700000000000001, -3.7000000000000006, -4.699999999999999, -9.699999999999998, -10.699999999999998, -2.700000000000001, -25.700000000000003, -3.700000000000001, -3.700000000000001, -5.700000000000001, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -2.700000000000001, -5.700000000000001, -3.7, -12.7, -3.7000000000000015, -1.7000000000000004, -4.2, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -5.1, -3.7000000000000015, -9.699999999999998, -2.7000000000000006, -12.699999999999998, -4.7, -5.2, -3.7000000000000015, -4.699999999999999, -3.700000000000001, -1.7000000000000004, -3.700000000000001, -8.7, -9.7, -4.6999999999999975, -4.699999999999998, -16.7, -2.7, -5.2, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -5.699999999999999, -3.700000000000001, -10.699999999999998, -14.699999999999998, -3.700000000000001, -3.7000000000000006, -2.7000000000000015, -9.7, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -8.2, -12.699999999999998, -3.7000000000000015, -14.699999999999998, -4.7, -7.699999999999999, -4.699999999999999, -11.699999999999998, -1.7000000000000004, -5.700000000000001, -9.7, -13.699999999999998, -8.699999999999998, -3.7000000000000015, -16.7, -3.7000000000000015, -2.7000000000000006, -3.700000000000001, -3.7, -14.699999999999998, -8.7, -10.699999999999998, -9.7, -5.699999999999999, -1.7000000000000004, -2.7000000000000006, -5.699999999999999, -2.700000000000001, -2.7000000000000015, -9.699999999999998, -2.7000000000000006, -4.699999999999999, -8.699999999999998, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -4.700000000000001, -3.5000000000000004, -3.7000000000000015, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -3.5000000000000004, -3.7000000000000006, -4.7, -2.7000000000000006, -3.7000000000000006, -3.700000000000001, -10.699999999999998, -3.7000000000000006, -3.7000000000000015, -15.699999999999998, -2.7000000000000015, -4.7, -4.700000000000001, -3.700000000000001, -2.7, -4.700000000000001, -2.7000000000000006, -3.7000000000000015, -8.699999999999998, -1.7000000000000004, -5.700000000000001, -3.7, -2.7000000000000015, -2.7000000000000006, -4.6999999999999975, -6.699999999999999, -4.7, -1.7000000000000004, -3.7000000000000015, -8.7, -11.7, -4.699999999999999, -2.7000000000000006, -2.7000000000000006, -1.7, -4.699999999999999, -4.700000000000001, -7.699999999999999, -3.700000000000001, -10.7, -4.699999999999999, -4.700000000000001, -4.700000000000001, -3.7, -2.7000000000000015, -9.7, -4.699999999999998, -4.700000000000001, -3.700000000000001, -11.699999999999998, -3.7000000000000006, -17.3, -5.700000000000001, -3.7000000000000015, -2.7000000000000006, -22.700000000000006, -16.7, -3.7000000000000015, -2.5, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -4.6999999999999975, -2.7000000000000015, -3.700000000000001, -6.699999999999999, -7.699999999999999, -3.7000000000000015, -6.699999999999999, -17.700000000000003, -5.699999999999999, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -3.2, -3.700000000000001, -3.7000000000000006, -1.7000000000000004, -8.5, -2.7000000000000006, -2.7, -3.7000000000000006, -2.700000000000001, -10.7, -13.7, -2.7000000000000006, -19.700000000000003, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -8.6, -4.7, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -4.699999999999998, -20.2, -3.7000000000000015, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -3.7000000000000015, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3486650224415984, "mean_inference_ms": 1.262578179104034, "mean_action_processing_ms": 0.09088138885138669, "mean_env_wait_ms": 4.208293321185927, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 152000, "timesteps_this_iter": 0, "agent_timesteps_total": 152000, "timers": {"sample_time_ms": 10146.841, "sample_throughput": 394.211, "load_time_ms": 0.341, "load_throughput": 11741350.689, "learn_time_ms": 2054.611, "learn_throughput": 1946.841, "update_time_ms": 2.156}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.717345237731934, "policy_loss": -0.018450718373060226, "vf_loss": 10.729588508605957, "vf_explained_var": 0.10438337177038193, "kl": 0.009193836711347103, "entropy": 1.8412344455718994, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 152000, "num_agent_steps_sampled": 152000, "num_steps_trained": 152000, "num_agent_steps_trained": 152000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8000, "training_iteration": 38, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-35", "timestamp": 1642601495, "time_this_iter_s": 10.025022983551025, "time_total_s": 392.6587064266205, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 392.6587064266205, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 45.90714285714285, "ram_util_percent": 62.050000000000004}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -33.2, "episode_reward_mean": -5.85048076923077, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -4.699999999999999, -2.7, -5.300000000000001, -6.699999999999999, -4.699999999999999, -2.7000000000000015, -3.700000000000001, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -5.600000000000001, -3.7000000000000006, -2.7, -3.700000000000001, -5.699999999999999, -7.699999999999999, -1.7000000000000004, -12.699999999999998, -5.700000000000001, -3.700000000000001, -3.7000000000000006, -19.700000000000003, -3.7000000000000015, -11.7, -15.699999999999998, -4.699999999999999, -3.7000000000000015, -1.7000000000000004, -4.699999999999999, -4.700000000000001, -5.699999999999999, -1.7000000000000004, -2.7, -2.7000000000000006, -14.699999999999998, -3.700000000000001, -2.7, -6.700000000000001, -3.7000000000000015, -17.7, -2.7000000000000006, -4.3, -3.700000000000001, -5.699999999999999, -3.7000000000000006, -6.6999999999999975, -1.7000000000000004, -6.699999999999999, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -10.7, -8.7, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -4.7, -6.700000000000001, -5.6, -3.700000000000001, -2.7000000000000015, -2.7000000000000015, -13.699999999999998, -9.7, -11.7, -4.699999999999999, -3.700000000000001, -33.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -15.699999999999998, -2.7, -4.700000000000001, -9.7, -3.7000000000000015, -10.699999999999998, -2.700000000000001, -2.7000000000000015, -2.7000000000000006, -9.7, -2.700000000000001, -21.700000000000003, -4.699999999999999, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -19.700000000000003, -5.2, -2.7000000000000015, -4.1, -2.700000000000001, -9.9, -3.7000000000000015, -4.699999999999999, -2.7000000000000006, -5.6999999999999975, -2.7000000000000006, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -9.7, -12.699999999999998, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -4.700000000000001, -5.6999999999999975, -4.700000000000001, -3.7000000000000015, -6.699999999999999, -2.700000000000001, -13.699999999999998, -25.700000000000003, -8.7, -2.7, -2.7000000000000015, -9.699999999999998, -2.7000000000000006, -5.2, -3.7000000000000015, -3.7, -3.7000000000000006, -7.699999999999999, -5.699999999999999, -4.699999999999999, -2.7000000000000006, -4.699999999999999, -4.700000000000001, -14.699999999999998, -1.7000000000000004, -2.7000000000000006, -12.699999999999998, -3.700000000000001, -6.700000000000001, -5.700000000000001, -3.700000000000001, -7.700000000000001, -2.7000000000000015, -3.7000000000000006, -4.699999999999999, -3.7000000000000006, -2.7000000000000006, -6.699999999999999, -2.700000000000001, -4.699999999999999, -1.7000000000000004, -30.700000000000003, -4.700000000000001, -1.7000000000000004, -4.600000000000001, -2.7000000000000006, -5.699999999999999, -11.699999999999998, -7.6, -8.699999999999998, -2.7, -3.700000000000001, -3.700000000000001, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -3.700000000000001, -2.7000000000000006, -14.699999999999998, -4.699999999999998, -3.3, -2.7, -9.699999999999998, -2.700000000000001, -9.7, -12.5, -6.700000000000001, -6.699999999999999, -3.7000000000000006, -4.699999999999999, -23.400000000000002, -1.7000000000000004, -3.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -11.7, -15.7, -1.7000000000000004, -2.7000000000000006, -5.699999999999999, -4.699999999999998, -2.7000000000000006, -3.2, -5.699999999999999, -5.699999999999999, -4.699999999999998, -4.700000000000001, -13.5, -4.699999999999998, -2.7000000000000006, -6.699999999999999, -1.7000000000000004, -14.699999999999998, -3.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3645736163055147, "mean_inference_ms": 1.273635786217465, "mean_action_processing_ms": 0.09160337409974122, "mean_env_wait_ms": 4.243379536202245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 156000, "timesteps_this_iter": 0, "agent_timesteps_total": 156000, "timers": {"sample_time_ms": 10397.135, "sample_throughput": 384.721, "load_time_ms": 0.344, "load_throughput": 11635492.059, "learn_time_ms": 2081.378, "learn_throughput": 1921.803, "update_time_ms": 2.191}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 14.487932205200195, "policy_loss": -0.01732264831662178, "vf_loss": 14.499674797058105, "vf_explained_var": 0.08691100776195526, "kl": 0.008268116042017937, "entropy": 1.815523386001587, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 156000, "num_agent_steps_sampled": 156000, "num_steps_trained": 156000, "num_agent_steps_trained": 156000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8208, "training_iteration": 39, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-48", "timestamp": 1642601508, "time_this_iter_s": 12.869718074798584, "time_total_s": 405.52842450141907, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 405.52842450141907, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 59.06842105263158, "ram_util_percent": 62.33684210526317}}
{"episode_reward_max": -1.2, "episode_reward_min": -28.700000000000006, "episode_reward_mean": -5.853773584905663, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.700000000000001, -3.9000000000000004, -4.700000000000001, -24.700000000000006, -4.700000000000001, -5.7, -10.7, -3.7000000000000015, -28.700000000000006, -3.7000000000000006, -2.7000000000000006, -3.7000000000000006, -3.700000000000001, -4.699999999999998, -9.9, -11.699999999999998, -4.5, -1.7000000000000004, -11.7, -4.7, -2.7000000000000006, -2.7000000000000015, -15.699999999999998, -6.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -9.7, -2.7000000000000006, -4.699999999999998, -3.7000000000000006, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -4.699999999999999, -2.7, -1.7000000000000004, -3.7000000000000006, -3.7000000000000015, -4.7, -2.7000000000000006, -4.700000000000001, -3.7000000000000006, -2.7, -5.699999999999999, -2.7000000000000006, -5.699999999999999, -4.7, -3.7000000000000015, -4.700000000000001, -2.700000000000001, -2.7000000000000006, -3.700000000000001, -13.699999999999998, -1.7000000000000004, -8.7, -3.700000000000001, -6.5, -1.7000000000000004, -5.699999999999999, -7.699999999999999, -2.7, -2.700000000000001, -4.7, -1.7000000000000004, -7.699999999999999, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -12.699999999999998, -2.7, -4.7, -11.200000000000001, -5.1, -4.700000000000001, -2.7000000000000015, -2.7, -1.2, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -9.9, -14.699999999999998, -1.7000000000000004, -14.699999999999998, -2.7000000000000015, -3.7000000000000015, -8.7, -2.7000000000000006, -13.699999999999998, -4.7, -15.2, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -10.7, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -3.700000000000001, -8.7, -1.2, -2.700000000000001, -11.699999999999998, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -14.7, -5.700000000000001, -3.7000000000000006, -1.7000000000000004, -8.699999999999998, -15.699999999999998, -3.7000000000000015, -2.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -8.699999999999998, -7.5, -2.2, -4.7, -19.700000000000003, -11.699999999999998, -1.7000000000000004, -2.7000000000000015, -2.7, -15.7, -12.7, -1.7000000000000004, -7.6, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -7.699999999999999, -2.7000000000000006, -2.700000000000001, -18.700000000000003, -4.700000000000001, -7.699999999999999, -8.7, -17.7, -26.700000000000006, -2.7000000000000006, -2.7000000000000015, -4.5, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -23.7, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -14.299999999999999, -12.7, -1.7000000000000004, -2.7000000000000006, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -3.500000000000001, -5.6999999999999975, -3.7000000000000015, -15.5, -2.7000000000000015, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -16.700000000000003, -3.7000000000000015, -3.7000000000000006, -10.699999999999998, -4.7, -4.5, -5.700000000000001, -8.699999999999998, -13.7, -3.700000000000001, -1.7000000000000004, -2.7, -9.7, -1.7000000000000004, -5.699999999999999, -2.7000000000000006, -3.700000000000001, -9.699999999999998, -2.7000000000000006, -3.700000000000001, -9.7, -3.700000000000001, -3.700000000000001, -20.7, -1.7000000000000004, -4.699999999999998, -10.699999999999998, -16.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.364594201285143, "mean_inference_ms": 1.2733791101628822, "mean_action_processing_ms": 0.09158792854776944, "mean_env_wait_ms": 4.2417279625144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 160000, "timesteps_this_iter": 0, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 10433.523, "sample_throughput": 383.38, "load_time_ms": 0.344, "load_throughput": 11618570.637, "learn_time_ms": 2086.421, "learn_throughput": 1917.159, "update_time_ms": 2.19}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 14.678135871887207, "policy_loss": -0.026048725470900536, "vf_loss": 14.698243141174316, "vf_explained_var": 0.049553535878658295, "kl": 0.008801457472145557, "entropy": 1.8055821657180786, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 160000, "num_steps_trained": 160000, "num_agent_steps_trained": 160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8420, "training_iteration": 40, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-11-59", "timestamp": 1642601519, "time_this_iter_s": 10.195811033248901, "time_total_s": 415.72423553466797, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 415.72423553466797, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 46.87857142857144, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -38.7, "episode_reward_mean": -5.872115384615385, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.699999999999998, -2.7000000000000015, -15.699999999999998, -2.7000000000000006, -18.7, -5.700000000000001, -6.699999999999999, -13.699999999999998, -2.7000000000000015, -2.7000000000000015, -3.700000000000001, -6.6999999999999975, -5.699999999999999, -6.100000000000001, -1.7000000000000004, -9.7, -3.700000000000001, -2.7000000000000015, -3.7000000000000006, -9.699999999999998, -2.7, -4.699999999999999, -6.699999999999999, -2.700000000000001, -3.7000000000000006, -2.7, -2.700000000000001, -6.699999999999999, -2.7000000000000006, -4.699999999999998, -2.7000000000000015, -2.7000000000000015, -12.2, -1.7000000000000004, -8.7, -14.7, -4.699999999999998, -2.700000000000001, -2.7, -2.700000000000001, -9.7, -5.699999999999999, -3.7000000000000006, -33.7, -1.7000000000000004, -3.7000000000000015, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -4.699999999999999, -12.7, -2.7000000000000006, -3.0999999999999996, -2.7000000000000015, -2.7000000000000006, -3.7000000000000015, -2.7000000000000006, -3.7000000000000015, -11.7, -9.7, -3.700000000000001, -3.1, -10.7, -16.6, -2.7000000000000015, -8.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -32.7, -1.7000000000000004, -11.699999999999998, -12.7, -12.699999999999998, -6.100000000000001, -10.699999999999998, -3.7000000000000006, -2.7000000000000015, -5.600000000000001, -2.700000000000001, -2.7000000000000015, -9.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -12.699999999999998, -4.7, -4.700000000000001, -2.700000000000001, -12.699999999999998, -3.7, -3.7, -4.699999999999999, -3.7000000000000015, -3.700000000000001, -2.7000000000000006, -6.699999999999999, -7.699999999999999, -2.7000000000000006, -11.699999999999998, -4.6999999999999975, -2.7000000000000006, -2.7, -2.7000000000000006, -3.7000000000000006, -3.700000000000001, -12.699999999999998, -15.7, -3.7000000000000015, -1.7000000000000004, -5.699999999999999, -5.699999999999999, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -3.7000000000000006, -3.700000000000001, -1.7000000000000004, -7.699999999999999, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -9.699999999999998, -1.7000000000000004, -13.699999999999998, -8.7, -3.7000000000000015, -2.7, -2.7000000000000006, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -5.7, -10.699999999999998, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -9.7, -3.900000000000001, -5.699999999999999, -1.7000000000000004, -10.7, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -4.7, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -3.7000000000000015, -4.699999999999998, -2.7000000000000006, -6.700000000000001, -1.7000000000000004, -6.700000000000001, -4.700000000000001, -16.7, -2.700000000000001, -12.2, -4.700000000000001, -9.7, -3.700000000000001, -2.7000000000000015, -10.699999999999998, -9.7, -3.7000000000000015, -23.700000000000006, -3.7000000000000006, -2.7000000000000006, -10.699999999999998, -11.699999999999998, -9.7, -18.1, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.5, -7.699999999999999, -10.699999999999998, -3.7000000000000006, -1.7000000000000004, -4.7, -4.700000000000001, -1.7000000000000004, -5.700000000000001, -2.700000000000001, -38.7, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3626326709278485, "mean_inference_ms": 1.2742569657588092, "mean_action_processing_ms": 0.0915600074180431, "mean_env_wait_ms": 4.240635171093239, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 164000, "timesteps_this_iter": 0, "agent_timesteps_total": 164000, "timers": {"sample_time_ms": 10468.107, "sample_throughput": 382.113, "load_time_ms": 0.345, "load_throughput": 11608923.332, "learn_time_ms": 2081.478, "learn_throughput": 1921.711, "update_time_ms": 2.168}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 15.293800354003906, "policy_loss": -0.02485365979373455, "vf_loss": 15.313223838806152, "vf_explained_var": 0.042821675539016724, "kl": 0.008044089190661907, "entropy": 1.79198157787323, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 164000, "num_agent_steps_sampled": 164000, "num_steps_trained": 164000, "num_agent_steps_trained": 164000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8628, "training_iteration": 41, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-12-09", "timestamp": 1642601529, "time_this_iter_s": 10.198879957199097, "time_total_s": 425.92311549186707, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 425.92311549186707, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 46.586666666666666, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.5, "episode_reward_min": -25.700000000000003, "episode_reward_mean": -5.097169811320757, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000015, -2.7000000000000006, -20.700000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -12.7, -12.2, -1.5, -1.7000000000000004, -3.700000000000001, -2.7000000000000015, -15.699999999999998, -11.699999999999998, -4.700000000000001, -2.7, -1.7000000000000004, -2.7, -4.699999999999999, -12.699999999999998, -1.7000000000000004, -3.7000000000000015, -10.699999999999998, -4.7, -1.7000000000000004, -3.700000000000001, -4.699999999999998, -2.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7, -2.700000000000001, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -4.1, -3.7000000000000015, -6.699999999999999, -4.700000000000001, -2.700000000000001, -1.7000000000000004, -8.7, -3.7000000000000006, -10.7, -5.699999999999999, -1.7000000000000004, -4.7, -3.700000000000001, -11.699999999999998, -7.699999999999999, -3.7000000000000006, -2.5, -3.700000000000001, -1.7000000000000004, -5.700000000000001, -14.699999999999998, -2.3, -5.699999999999999, -3.7000000000000006, -1.7000000000000004, -7.699999999999999, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -16.7, -2.7000000000000015, -2.0999999999999996, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -5.6999999999999975, -21.700000000000006, -4.700000000000001, -3.7000000000000006, -3.7000000000000015, -2.7000000000000006, -5.700000000000001, -7.699999999999999, -14.699999999999998, -9.7, -8.7, -1.7000000000000004, -10.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -6.699999999999999, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.6999999999999975, -3.7000000000000006, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7, -4.699999999999999, -1.7000000000000004, -6.6999999999999975, -7.699999999999999, -8.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -5.700000000000001, -2.7000000000000006, -8.700000000000001, -1.7000000000000004, -13.7, -12.699999999999998, -2.7000000000000006, -4.700000000000001, -3.700000000000001, -5.699999999999999, -1.7000000000000004, -3.7000000000000006, -14.699999999999998, -2.7000000000000006, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -4.700000000000001, -7.699999999999999, -2.700000000000001, -4.700000000000001, -17.700000000000006, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -4.700000000000001, -6.2, -1.7000000000000004, -8.7, -3.7000000000000006, -3.5, -3.7, -3.7000000000000015, -2.7000000000000015, -8.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -22.700000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -14.699999999999998, -14.699999999999998, -11.699999999999998, -1.7000000000000004, -2.7000000000000015, -11.699999999999998, -1.7000000000000004, -2.7, -8.7, -2.700000000000001, -3.7000000000000015, -4.6999999999999975, -9.699999999999998, -3.700000000000001, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7, -4.699999999999999, -1.7000000000000004, -4.699999999999998, -12.699999999999998, -1.7000000000000004, -9.7, -3.700000000000001, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -4.699999999999999, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -8.7, -25.700000000000003, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -3.7000000000000015, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -9.7, -12.7, -1.7000000000000004, -4.1, -2.7000000000000015, -3.7000000000000015, -2.7, -2.700000000000001, -2.7000000000000015], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3615887081568308, "mean_inference_ms": 1.2736553913190112, "mean_action_processing_ms": 0.09152871001768938, "mean_env_wait_ms": 4.238653276929435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 168000, "timesteps_this_iter": 0, "agent_timesteps_total": 168000, "timers": {"sample_time_ms": 10478.327, "sample_throughput": 381.74, "load_time_ms": 0.344, "load_throughput": 11619375.303, "learn_time_ms": 2072.857, "learn_throughput": 1929.704, "update_time_ms": 2.179}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.66821575164795, "policy_loss": -0.010327335447072983, "vf_loss": 10.674137115478516, "vf_explained_var": 0.06874825060367584, "kl": 0.006527457851916552, "entropy": 1.7956737279891968, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 168000, "num_agent_steps_sampled": 168000, "num_steps_trained": 168000, "num_agent_steps_trained": 168000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8840, "training_iteration": 42, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-12-19", "timestamp": 1642601539, "time_this_iter_s": 10.075859069824219, "time_total_s": 435.9989745616913, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 435.9989745616913, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 46.50714285714285, "ram_util_percent": 62.314285714285695}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -27.699999999999996, "episode_reward_mean": -4.888207547169813, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.699999999999998, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -6.699999999999999, -1.7000000000000004, -2.7000000000000006, -9.7, -3.2, -7.699999999999999, -4.699999999999999, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -11.699999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -3.7000000000000015, -11.699999999999998, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -21.700000000000003, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -13.699999999999998, -2.700000000000001, -2.7000000000000006, -10.7, -3.7000000000000015, -14.699999999999998, -3.7000000000000015, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -2.7000000000000006, -11.699999999999998, -4.7, -2.7000000000000015, -4.7, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -11.7, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7, -4.699999999999998, -3.700000000000001, -14.699999999999998, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -2.700000000000001, -2.7000000000000015, -2.7000000000000015, -3.7000000000000006, -9.7, -10.7, -1.7000000000000004, -1.7000000000000004, -12.7, -1.7000000000000004, -3.7000000000000006, -3.700000000000001, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -3.7000000000000015, -2.7000000000000015, -10.7, -8.7, -9.7, -7.7, -3.5000000000000013, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -5.700000000000001, -1.7000000000000004, -14.699999999999998, -8.7, -2.7000000000000006, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.7, -7.9, -2.7000000000000015, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -9.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -4.699999999999998, -18.700000000000003, -4.7, -2.7000000000000015, -2.7000000000000015, -3.7000000000000015, -16.7, -3.7000000000000015, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -5.700000000000001, -3.7000000000000006, -3.7, -13.699999999999998, -4.700000000000001, -1.7000000000000004, -8.7, -2.7000000000000006, -11.7, -20.700000000000003, -4.7, -1.7000000000000004, -2.7000000000000015, -5.700000000000001, -9.7, -2.7000000000000006, -9.6, -1.7000000000000004, -11.100000000000001, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -10.699999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -4.500000000000001, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -17.2, -7.699999999999999, -3.7000000000000015, -2.7000000000000006, -4.700000000000001, -4.7, -1.7000000000000004, -13.7, -4.7, -3.7000000000000006, -2.7, -10.7, -2.700000000000001, -4.5, -11.7, -1.7000000000000004, -8.7, -2.700000000000001, -4.7, -27.699999999999996, -3.7, -1.7000000000000004, -4.6999999999999975, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.699999999999999, -3.7000000000000015, -13.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3613549831820015, "mean_inference_ms": 1.2728549242546383, "mean_action_processing_ms": 0.09148985293712099, "mean_env_wait_ms": 4.235687150458634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 172000, "timesteps_this_iter": 0, "agent_timesteps_total": 172000, "timers": {"sample_time_ms": 10481.32, "sample_throughput": 381.631, "load_time_ms": 0.346, "load_throughput": 11569695.883, "learn_time_ms": 2070.867, "learn_throughput": 1931.558, "update_time_ms": 2.168}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.820728302001953, "policy_loss": -0.02701394073665142, "vf_loss": 10.843192100524902, "vf_explained_var": 0.07440528273582458, "kl": 0.006741936784237623, "entropy": 1.7202613353729248, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 172000, "num_agent_steps_sampled": 172000, "num_steps_trained": 172000, "num_agent_steps_trained": 172000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9052, "training_iteration": 43, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-12-29", "timestamp": 1642601549, "time_this_iter_s": 9.961757898330688, "time_total_s": 445.960732460022, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 445.960732460022, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 45.949999999999996, "ram_util_percent": 62.12857142857144}}
{"episode_reward_max": -1.2, "episode_reward_min": -26.700000000000003, "episode_reward_mean": -4.541826923076925, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -4.699999999999999, -2.7000000000000015, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -3.7000000000000015, -6.699999999999999, -3.7000000000000015, -3.7000000000000006, -3.7000000000000015, -9.699999999999998, -8.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -6.700000000000001, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -9.3, -1.7000000000000004, -1.7000000000000004, -6.700000000000001, -2.700000000000001, -16.7, -1.7000000000000004, -6.699999999999999, -8.7, -10.699999999999998, -11.699999999999998, -1.7000000000000004, -15.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.7, -4.7, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -5.699999999999999, -4.700000000000001, -11.7, -4.699999999999999, -11.699999999999998, -15.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -4.700000000000001, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -9.7, -1.7000000000000004, -2.7, -3.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -9.699999999999998, -3.7000000000000015, -2.7000000000000006, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -2.7, -10.699999999999998, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -8.699999999999998, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -12.699999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.5, -1.7000000000000004, -3.700000000000001, -4.700000000000001, -20.700000000000003, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -2.7000000000000006, -15.7, -2.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -5.700000000000001, -10.699999999999998, -17.7, -1.7000000000000004, -1.2, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -3.900000000000001, -10.699999999999998, -1.7000000000000004, -3.700000000000001, -3.7000000000000015, -2.700000000000001, -9.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -9.7, -5.6999999999999975, -11.7, -2.7000000000000006, -17.700000000000003, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -16.700000000000003, -3.7000000000000015, -2.7, -4.699999999999998, -2.7, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -4.699999999999998, -9.699999999999998, -2.7, -7.699999999999999, -2.700000000000001, -5.699999999999999, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -7.699999999999999, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -10.699999999999998, -2.700000000000001, -14.699999999999998, -6.699999999999999, -11.7, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -3.7000000000000015, -26.700000000000003], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3592721914443664, "mean_inference_ms": 1.2719722117178252, "mean_action_processing_ms": 0.09143030650778083, "mean_env_wait_ms": 4.232359750414812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 176000, "timesteps_this_iter": 0, "agent_timesteps_total": 176000, "timers": {"sample_time_ms": 10477.811, "sample_throughput": 381.759, "load_time_ms": 0.345, "load_throughput": 11590477.375, "learn_time_ms": 2066.382, "learn_throughput": 1935.751, "update_time_ms": 2.167}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.071914672851562, "policy_loss": -0.039397262036800385, "vf_loss": 8.106613159179688, "vf_explained_var": 0.06867104023694992, "kl": 0.006961232051253319, "entropy": 1.6989976167678833, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 176000, "num_agent_steps_sampled": 176000, "num_steps_trained": 176000, "num_agent_steps_trained": 176000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9260, "training_iteration": 44, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-12-39", "timestamp": 1642601559, "time_this_iter_s": 9.882702112197876, "time_total_s": 455.84343457221985, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 455.84343457221985, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 44.75714285714285, "ram_util_percent": 62.185714285714305}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -5.24669811320755, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -15.699999999999998, -2.7, -20.700000000000003, -5.700000000000001, -4.699999999999999, -4.699999999999999, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -2.7000000000000015, -3.7000000000000015, -13.699999999999998, -9.699999999999998, -2.7, -3.7000000000000015, -8.7, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -4.699999999999998, -4.700000000000001, -3.7000000000000015, -20.700000000000003, -3.7, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -3.7000000000000006, -2.7000000000000006, -4.7, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -23.700000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -20.700000000000003, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000006, -3.7000000000000015, -2.7000000000000015, -2.7000000000000006, -13.699999999999998, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -8.7, -10.699999999999998, -5.699999999999999, -2.7, -1.7000000000000004, -1.7, -1.7000000000000004, -2.7, -8.7, -5.700000000000001, -2.7000000000000006, -7.699999999999999, -3.7000000000000006, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -13.399999999999999, -13.699999999999998, -2.7000000000000006, -3.700000000000001, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -9.7, -3.7000000000000015, -1.7000000000000004, -10.7, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -17.7, -2.7000000000000006, -1.7000000000000004, -11.7, -8.699999999999998, -4.699999999999999, -2.700000000000001, -7.699999999999999, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -4.699999999999999, -2.7000000000000015, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.0999999999999996, -2.7000000000000006, -4.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -18.7, -4.7, -12.699999999999998, -1.7000000000000004, -2.7000000000000015, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -4.700000000000001, -8.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -11.699999999999998, -2.7000000000000015, -3.7000000000000015, -2.7000000000000006, -3.3, -3.7000000000000015, -9.7, -21.700000000000003, -2.7000000000000015, -2.700000000000001, -3.5000000000000013, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -15.699999999999998, -4.699999999999998, -1.7000000000000004, -2.7000000000000015, -12.699999999999998, -3.7000000000000006, -1.7000000000000004, -3.7, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -5.700000000000001, -7.699999999999999, -2.7, -3.7000000000000015, -6.700000000000001, -3.6000000000000014, -7.699999999999999, -3.700000000000001, -1.7000000000000004, -16.7, -12.699999999999998, -2.7000000000000006, -3.7000000000000015, -3.7, -15.699999999999998, -1.2, -7.699999999999999, -21.700000000000003, -2.700000000000001, -18.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -20.700000000000003, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.364019611586926, "mean_inference_ms": 1.2758521699277048, "mean_action_processing_ms": 0.09166646413264178, "mean_env_wait_ms": 4.244469424909555, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 180000, "timesteps_this_iter": 0, "agent_timesteps_total": 180000, "timers": {"sample_time_ms": 10618.885, "sample_throughput": 376.687, "load_time_ms": 0.346, "load_throughput": 11564113.593, "learn_time_ms": 2095.142, "learn_throughput": 1909.178, "update_time_ms": 2.133}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 13.653334617614746, "policy_loss": -0.014584071934223175, "vf_loss": 13.662698745727539, "vf_explained_var": 0.057782191783189774, "kl": 0.007734654936939478, "entropy": 1.7223464250564575, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 180000, "num_steps_trained": 180000, "num_agent_steps_trained": 180000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9472, "training_iteration": 45, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-12-50", "timestamp": 1642601570, "time_this_iter_s": 11.49500584602356, "time_total_s": 467.3384404182434, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 467.3384404182434, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 50.53529411764706, "ram_util_percent": 62.3}}
{"episode_reward_max": -1.2, "episode_reward_min": -30.700000000000003, "episode_reward_mean": -5.013207547169812, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.699999999999999, -1.7000000000000004, -2.7, -9.699999999999998, -13.699999999999998, -1.7000000000000004, -2.7000000000000015, -2.7, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -5.700000000000001, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -2.700000000000001, -2.7, -5.700000000000001, -11.699999999999998, -2.700000000000001, -8.699999999999998, -4.700000000000001, -2.7000000000000015, -3.700000000000001, -14.699999999999998, -2.7000000000000015, -3.7000000000000015, -9.6, -18.7, -3.7000000000000015, -2.7000000000000015, -2.7000000000000006, -2.7000000000000015, -11.699999999999998, -2.7000000000000006, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.2, -10.699999999999998, -1.7000000000000004, -12.699999999999998, -8.699999999999998, -2.700000000000001, -8.7, -9.699999999999998, -4.7, -2.7000000000000015, -2.700000000000001, -8.700000000000001, -1.7000000000000004, -4.699999999999998, -2.700000000000001, -2.7000000000000006, -11.699999999999998, -2.700000000000001, -3.5, -10.7, -7.6999999999999975, -2.7000000000000006, -9.699999999999998, -2.7000000000000006, -2.7, -2.7000000000000006, -10.7, -2.7000000000000015, -2.7, -6.699999999999999, -4.7, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7, -2.700000000000001, -2.7000000000000006, -16.7, -12.699999999999998, -2.7, -5.700000000000001, -3.7000000000000015, -3.7000000000000015, -2.700000000000001, -14.699999999999998, -4.700000000000001, -8.7, -8.7, -3.7000000000000015, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -2.7000000000000015, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7, -15.699999999999998, -8.7, -13.699999999999998, -8.700000000000001, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -1.2, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -11.699999999999998, -2.7000000000000006, -2.2, -13.699999999999998, -9.7, -8.7, -4.2, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -13.699999999999998, -4.700000000000001, -10.699999999999998, -2.7000000000000006, -9.7, -2.7000000000000006, -2.7000000000000006, -5.700000000000001, -2.700000000000001, -2.700000000000001, -5.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.6000000000000014, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -11.699999999999998, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -4.699999999999999, -15.699999999999998, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -19.700000000000003, -8.7, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -23.700000000000006, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -30.700000000000003, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -8.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.5, -2.700000000000001, -1.7000000000000004, -8.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7000000000000015, -3.7000000000000015, -2.7000000000000015, -2.7000000000000006, -3.5000000000000004, -1.7000000000000004, -3.9, -2.7000000000000015, -4.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -2.7000000000000006, -2.7000000000000015], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.36597536636465, "mean_inference_ms": 1.276474968640354, "mean_action_processing_ms": 0.09171497728256518, "mean_env_wait_ms": 4.245618612014073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 184000, "timesteps_this_iter": 0, "agent_timesteps_total": 184000, "timers": {"sample_time_ms": 10668.176, "sample_throughput": 374.947, "load_time_ms": 0.352, "load_throughput": 11359750.829, "learn_time_ms": 2091.695, "learn_throughput": 1912.324, "update_time_ms": 2.139}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 11.623549461364746, "policy_loss": -0.014224066399037838, "vf_loss": 11.632404327392578, "vf_explained_var": 0.08578699082136154, "kl": 0.007956000976264477, "entropy": 1.6996690034866333, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 184000, "num_agent_steps_sampled": 184000, "num_steps_trained": 184000, "num_agent_steps_trained": 184000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9684, "training_iteration": 46, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-01", "timestamp": 1642601581, "time_this_iter_s": 10.755127906799316, "time_total_s": 478.0935683250427, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 478.0935683250427, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 48.080000000000005, "ram_util_percent": 62.32666666666665}}
{"episode_reward_max": -1.2, "episode_reward_min": -28.700000000000003, "episode_reward_mean": -5.224519230769232, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -8.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -3.7000000000000015, -1.7000000000000004, -20.700000000000003, -5.699999999999999, -1.7000000000000004, -2.7, -2.7000000000000015, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.7000000000000015, -18.700000000000003, -4.700000000000001, -3.7000000000000006, -21.700000000000003, -17.700000000000003, -2.7000000000000006, -3.700000000000001, -9.699999999999998, -28.700000000000003, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -7.2, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -9.699999999999998, -3.7000000000000015, -21.700000000000003, -3.7000000000000015, -10.7, -2.7000000000000015, -2.7, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -21.700000000000003, -19.700000000000003, -3.2, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.9, -3.7000000000000006, -1.7000000000000004, -1.2, -3.9000000000000004, -1.7000000000000004, -20.700000000000003, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -2.700000000000001, -4.7, -9.699999999999998, -6.699999999999999, -3.7000000000000015, -2.7, -1.7000000000000004, -9.699999999999998, -24.700000000000006, -2.700000000000001, -10.7, -14.699999999999998, -15.699999999999998, -1.7000000000000004, -8.7, -5.700000000000001, -3.7000000000000015, -1.7000000000000004, -5.700000000000001, -8.700000000000001, -7.699999999999999, -16.7, -3.7, -2.7000000000000015, -3.7000000000000015, -13.1, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -4.700000000000001, -4.7, -2.7000000000000015, -11.699999999999998, -2.7000000000000015, -10.7, -2.7000000000000006, -1.7000000000000004, -4.2, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -9.699999999999998, -2.7000000000000015, -3.7000000000000015, -2.7, -9.7, -6.699999999999999, -1.7000000000000004, -8.7, -3.7000000000000006, -3.7000000000000006, -7.699999999999999, -13.699999999999998, -3.0999999999999996, -15.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -5.700000000000001, -11.699999999999998, -4.699999999999999, -3.9000000000000004, -8.7, -3.7000000000000015, -1.7000000000000004, -7.6999999999999975, -1.7000000000000004, -1.7000000000000004, -4.2, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -11.7, -5.699999999999999, -4.699999999999999, -7.699999999999999, -8.700000000000001, -4.699999999999999, -2.7000000000000015, -1.7000000000000004, -8.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -10.7, -3.700000000000001, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -2.9, -2.7000000000000006, -4.7, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -3.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3699428032784793, "mean_inference_ms": 1.2796975618189836, "mean_action_processing_ms": 0.09193046887208396, "mean_env_wait_ms": 4.255281206430348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 188000, "timesteps_this_iter": 0, "agent_timesteps_total": 188000, "timers": {"sample_time_ms": 10681.124, "sample_throughput": 374.492, "load_time_ms": 0.351, "load_throughput": 11382872.651, "learn_time_ms": 2090.472, "learn_throughput": 1913.443, "update_time_ms": 2.1}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 13.652095794677734, "policy_loss": -0.017414811998605728, "vf_loss": 13.664374351501465, "vf_explained_var": 0.05392103269696236, "kl": 0.007609875872731209, "entropy": 1.7094944715499878, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 188000, "num_agent_steps_sampled": 188000, "num_steps_trained": 188000, "num_agent_steps_trained": 188000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9892, "training_iteration": 47, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-12", "timestamp": 1642601592, "time_this_iter_s": 11.08107614517212, "time_total_s": 489.17464447021484, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 489.17464447021484, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 50.59375, "ram_util_percent": 62.349999999999994}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -22.700000000000003, "episode_reward_mean": -4.360377358490567, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7, -4.699999999999998, -1.7000000000000004, -5.599999999999998, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.9, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -22.700000000000003, -10.699999999999998, -3.700000000000001, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -8.7, -1.7000000000000004, -4.7, -15.699999999999998, -2.7000000000000006, -19.700000000000003, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -4.7, -3.700000000000001, -1.7000000000000004, -3.5, -1.7000000000000004, -2.7000000000000015, -18.700000000000003, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -3.100000000000001, -1.7000000000000004, -10.699999999999998, -6.699999999999999, -3.700000000000001, -9.7, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -15.699999999999998, -2.7000000000000006, -10.7, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -10.699999999999998, -12.699999999999998, -4.700000000000001, -1.7000000000000004, -3.7000000000000006, -2.7, -2.7, -4.7, -7.6999999999999975, -10.699999999999998, -2.7000000000000015, -3.7000000000000015, -3.7000000000000015, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -2.7000000000000015, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -4.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -13.699999999999998, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -3.7000000000000015, -5.699999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -3.7000000000000015, -14.699999999999998, -6.699999999999999, -1.7000000000000004, -10.699999999999996, -1.7000000000000004, -8.7, -2.7000000000000006, -17.700000000000003, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -4.7, -1.7000000000000004, -2.7000000000000015, -2.7, -3.700000000000001, -9.7, -1.7000000000000004, -2.7000000000000006, -4.699999999999998, -11.699999999999998, -3.7000000000000015, -3.700000000000001, -20.700000000000003, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -2.5000000000000004, -3.7000000000000015, -1.7000000000000004, -4.100000000000001, -1.7000000000000004, -14.699999999999998, -2.7000000000000015, -4.2, -3.7000000000000015, -2.7, -2.7, -12.699999999999998, -1.7000000000000004, -5.699999999999999, -1.7000000000000004, -17.7, -3.7, -7.699999999999999, -2.7000000000000015, -2.700000000000001, -2.7000000000000015, -10.699999999999998, -1.7000000000000004, -8.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.367947600076145, "mean_inference_ms": 1.2786263478417932, "mean_action_processing_ms": 0.09187366144823182, "mean_env_wait_ms": 4.251224541772899, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 192000, "timesteps_this_iter": 0, "agent_timesteps_total": 192000, "timers": {"sample_time_ms": 10676.563, "sample_throughput": 374.652, "load_time_ms": 0.338, "load_throughput": 11848316.384, "learn_time_ms": 2126.879, "learn_throughput": 1880.69, "update_time_ms": 2.066}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.854660034179688, "policy_loss": -0.019259009510278702, "vf_loss": 8.86993408203125, "vf_explained_var": 0.03701239824295044, "kl": 0.0059046559035778046, "entropy": 1.6372052431106567, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 192000, "num_agent_steps_sampled": 192000, "num_steps_trained": 192000, "num_agent_steps_trained": 192000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10104, "training_iteration": 48, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-23", "timestamp": 1642601603, "time_this_iter_s": 10.355320930480957, "time_total_s": 499.5299654006958, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 499.5299654006958, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 45.25999999999999, "ram_util_percent": 62.18000000000002}}
{"episode_reward_max": -1.5, "episode_reward_min": -24.700000000000006, "episode_reward_mean": -4.699038461538462, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.699999999999999, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -1.7000000000000004, -8.7, -3.7000000000000015, -10.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -9.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -5.700000000000001, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -20.700000000000003, -4.700000000000001, -3.7000000000000015, -2.7000000000000015, -2.700000000000001, -5.700000000000001, -3.7000000000000006, -8.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -4.7, -5.699999999999999, -3.7000000000000015, -3.7000000000000006, -2.7000000000000015, -10.699999999999998, -1.7000000000000004, -4.700000000000001, -10.699999999999998, -5.699999999999999, -2.7000000000000006, -2.7, -11.699999999999998, -1.7000000000000004, -5.699999999999999, -10.699999999999998, -7.699999999999999, -22.700000000000003, -1.7000000000000004, -12.6, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -9.699999999999998, -1.7000000000000004, -2.2, -1.7000000000000004, -7.699999999999999, -24.700000000000006, -2.700000000000001, -2.7000000000000006, -4.7, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -8.7, -3.7000000000000006, -2.7000000000000006, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -8.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -8.7, -10.699999999999998, -2.7000000000000006, -3.7000000000000006, -7.699999999999999, -21.700000000000003, -1.7000000000000004, -9.7, -1.7000000000000004, -3.7000000000000015, -10.699999999999998, -3.7000000000000006, -13.699999999999998, -3.700000000000001, -16.7, -3.7, -5.700000000000001, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -8.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -4.6999999999999975, -1.7000000000000004, -4.7, -10.699999999999998, -2.3, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -4.7, -1.7000000000000004, -2.7000000000000006, -12.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -15.699999999999998, -7.699999999999999, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000015, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -1.5, -1.7000000000000004, -3.7000000000000015, -2.7, -13.699999999999998, -18.700000000000003, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.377387676985199, "mean_inference_ms": 1.2841197483948437, "mean_action_processing_ms": 0.09223242997709594, "mean_env_wait_ms": 4.268322034075889, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 196000, "timesteps_this_iter": 0, "agent_timesteps_total": 196000, "timers": {"sample_time_ms": 10639.752, "sample_throughput": 375.949, "load_time_ms": 0.336, "load_throughput": 11897890.93, "learn_time_ms": 2143.359, "learn_throughput": 1866.23, "update_time_ms": 2.066}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.957070350646973, "policy_loss": -0.01892714574933052, "vf_loss": 10.970816612243652, "vf_explained_var": 0.007446665316820145, "kl": 0.007674269378185272, "entropy": 1.6098464727401733, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 196000, "num_agent_steps_sampled": 196000, "num_steps_trained": 196000, "num_agent_steps_trained": 196000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10312, "training_iteration": 49, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-35", "timestamp": 1642601615, "time_this_iter_s": 12.30475902557373, "time_total_s": 511.83472442626953, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 511.83472442626953, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 53.800000000000004, "ram_util_percent": 62.27058823529413}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -22.700000000000003, "episode_reward_mean": -4.428301886792454, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -11.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.2, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -9.699999999999998, -6.699999999999999, -2.700000000000001, -4.7, -14.699999999999998, -2.7, -13.699999999999998, -14.699999999999998, -5.700000000000001, -20.700000000000003, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -6.700000000000001, -2.7000000000000015, -2.7000000000000006, -11.7, -2.700000000000001, -2.700000000000001, -8.699999999999998, -9.699999999999998, -3.7, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.700000000000001, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -9.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -15.699999999999998, -10.7, -3.700000000000001, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.3, -2.700000000000001, -11.699999999999998, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.2, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -11.7, -8.7, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.5000000000000013, -2.6000000000000014, -1.7000000000000004, -1.9, -2.7000000000000015, -8.7, -1.7000000000000004, -3.7000000000000006, -4.6, -1.7000000000000004, -4.7, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.5000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -13.699999999999998, -10.699999999999998, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -3.7000000000000015, -4.7, -1.7000000000000004, -4.699999999999998, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -2.700000000000001, -9.699999999999998, -2.7, -1.7000000000000004, -10.699999999999998, -5.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -11.7, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -8.7, -22.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -4.7, -2.7000000000000015, -3.700000000000001, -17.7, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000015, -1.7000000000000004, -11.9, -15.699999999999998, -1.7000000000000004, -2.7000000000000015, -19.7, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3839770144256236, "mean_inference_ms": 1.2869954762445737, "mean_action_processing_ms": 0.09242182304753256, "mean_env_wait_ms": 4.278378814118511, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 200000, "timesteps_this_iter": 0, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 10766.212, "sample_throughput": 371.533, "load_time_ms": 0.337, "load_throughput": 11857527.74, "learn_time_ms": 2183.914, "learn_throughput": 1831.574, "update_time_ms": 2.067}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.866467475891113, "policy_loss": -0.016077635809779167, "vf_loss": 9.877670288085938, "vf_explained_var": -0.03632986545562744, "kl": 0.007220541127026081, "entropy": 1.6067124605178833, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 200000, "num_steps_trained": 200000, "num_agent_steps_trained": 200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10524, "training_iteration": 50, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-47", "timestamp": 1642601627, "time_this_iter_s": 11.699551820755005, "time_total_s": 523.5342762470245, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 523.5342762470245, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 52.41176470588236, "ram_util_percent": 62.4}}
{"episode_reward_max": -1.5, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.295283018867925, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.3000000000000007, -11.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.7, -1.7000000000000004, -2.700000000000001, -23.700000000000006, -1.7, -4.1000000000000005, -1.7000000000000004, -2.7000000000000015, -9.699999999999998, -23.700000000000006, -1.7000000000000004, -2.5, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -4.699999999999999, -11.699999999999998, -2.7000000000000015, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -20.700000000000003, -1.7000000000000004, -2.7, -4.7, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -12.599999999999998, -1.7000000000000004, -14.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -9.699999999999998, -1.7000000000000004, -5.700000000000001, -10.699999999999998, -2.7000000000000015, -6.699999999999999, -1.7000000000000004, -2.7000000000000006, -5.699999999999998, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -16.7, -14.699999999999998, -12.699999999999998, -2.700000000000001, -15.699999999999998, -1.7000000000000004, -3.7000000000000015, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7, -2.700000000000001, -14.699999999999998, -2.7000000000000006, -1.7000000000000004, -5.700000000000001, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -2.7000000000000015, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7000000000000006, -4.7, -14.699999999999998, -1.7000000000000004, -12.9, -4.7, -1.7000000000000004, -8.7, -3.7000000000000015, -2.9, -1.7000000000000004, -2.0999999999999996, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -2.0999999999999996, -7.699999999999999, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -9.699999999999998, -9.699999999999998, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -13.699999999999998, -2.5, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7, -1.7000000000000004, -2.7000000000000015, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -10.699999999999998, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -18.599999999999998, -4.7, -2.700000000000001, -2.7000000000000015, -2.7000000000000015, -3.7000000000000015, -13.699999999999998, -6.699999999999999, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -21.700000000000006], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3797131625323367, "mean_inference_ms": 1.2847975231554436, "mean_action_processing_ms": 0.092278141402368, "mean_env_wait_ms": 4.269681374972147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 204000, "timesteps_this_iter": 0, "agent_timesteps_total": 204000, "timers": {"sample_time_ms": 10732.01, "sample_throughput": 372.717, "load_time_ms": 0.337, "load_throughput": 11875152.888, "learn_time_ms": 2214.588, "learn_throughput": 1806.205, "update_time_ms": 2.114}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.71560287475586, "policy_loss": -0.0313163660466671, "vf_loss": 8.742349624633789, "vf_explained_var": 0.019114356487989426, "kl": 0.006770548410713673, "entropy": 1.6218515634536743, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 204000, "num_agent_steps_sampled": 204000, "num_steps_trained": 204000, "num_agent_steps_trained": 204000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10736, "training_iteration": 51, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-13-56", "timestamp": 1642601636, "time_this_iter_s": 9.744224071502686, "time_total_s": 533.2785003185272, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 533.2785003185272, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 43.42142857142857, "ram_util_percent": 62.314285714285695}}
{"episode_reward_max": -1.2, "episode_reward_min": -26.699999999999996, "episode_reward_mean": -4.6000000000000005, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -11.3, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -8.7, -18.700000000000003, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -7.699999999999999, -4.700000000000001, -1.7000000000000004, -16.700000000000003, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -4.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7000000000000015, -8.700000000000001, -2.7, -3.900000000000001, -2.700000000000001, -2.7, -11.699999999999998, -2.7000000000000015, -1.2, -2.7000000000000006, -4.100000000000001, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -13.699999999999998, -2.700000000000001, -3.7, -1.7000000000000004, -1.7000000000000004, -1.2, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -2.700000000000001, -9.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -18.299999999999997, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -26.699999999999996, -13.699999999999998, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -20.1, -13.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -13.499999999999998, -14.699999999999998, -8.700000000000001, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -9.5, -10.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7, -1.2, -2.7000000000000006, -1.7000000000000004, -2.7, -10.2, -4.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -11.499999999999998, -1.7000000000000004, -5.9, -16.7, -11.599999999999998, -4.700000000000001, -2.700000000000001, -8.7, -2.7000000000000015, -23.700000000000006, -2.700000000000001, -8.7, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -9.699999999999998, -3.7000000000000015, -1.7000000000000004, -2.0999999999999996, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -11.7, -11.8, -2.7000000000000015, -1.7000000000000004, -9.7, -3.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -6.700000000000001, -3.700000000000001, -1.7, -2.700000000000001, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -8.7, -2.7000000000000006, -22.2, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3768478552998626, "mean_inference_ms": 1.2834580507955353, "mean_action_processing_ms": 0.0921921939479028, "mean_env_wait_ms": 4.265346250126736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 208000, "timesteps_this_iter": 0, "agent_timesteps_total": 208000, "timers": {"sample_time_ms": 10733.348, "sample_throughput": 372.67, "load_time_ms": 0.337, "load_throughput": 11871791.678, "learn_time_ms": 2226.657, "learn_throughput": 1796.415, "update_time_ms": 2.119}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 12.746479988098145, "policy_loss": -0.01691349223256111, "vf_loss": 12.758429527282715, "vf_explained_var": 0.054313380271196365, "kl": 0.007354377303272486, "entropy": 1.5830475091934204, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 208000, "num_agent_steps_sampled": 208000, "num_steps_trained": 208000, "num_agent_steps_trained": 208000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10944, "training_iteration": 52, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-06", "timestamp": 1642601646, "time_this_iter_s": 9.892025232315063, "time_total_s": 543.1705255508423, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 543.1705255508423, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 44.74999999999999, "ram_util_percent": 62.37857142857142}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -21.700000000000006, "episode_reward_mean": -4.481603773584906, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -8.7, -8.7, -2.7000000000000006, -2.700000000000001, -8.7, -3.7000000000000006, -1.7000000000000004, -2.7000000000000015, -8.7, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -14.2, -3.7, -1.7000000000000004, -6.699999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7, -4.7, -10.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -11.7, -9.699999999999998, -4.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7, -1.7000000000000004, -16.7, -21.700000000000006, -16.7, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -7.699999999999999, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -8.7, -7.6999999999999975, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -10.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.7, -1.7000000000000004, -2.7000000000000015, -7.699999999999999, -2.7, -12.7, -1.7000000000000004, -1.7000000000000004, -4.7, -8.7, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -15.699999999999998, -11.699999999999998, -4.700000000000001, -2.7000000000000006, -5.699999999999999, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -3.5000000000000013, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.700000000000001, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -2.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -15.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -3.7000000000000015, -10.699999999999998, -1.7000000000000004, -16.7, -2.7000000000000006, -8.7, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -4.7, -21.700000000000006, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -4.7, -7.2, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.2, -4.1, -4.7, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -2.700000000000001, -3.700000000000001, -4.7, -2.700000000000001, -7.699999999999999, -9.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -9.7, -2.7000000000000015, -1.7000000000000004, -10.7, -14.699999999999998, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -4.699999999999999, -2.7000000000000015, -1.7000000000000004, -19.700000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -3.700000000000001, -5.699999999999999, -2.7000000000000015, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.376497383376422, "mean_inference_ms": 1.2824230762147082, "mean_action_processing_ms": 0.09212636877457125, "mean_env_wait_ms": 4.260417040859816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 212000, "timesteps_this_iter": 0, "agent_timesteps_total": 212000, "timers": {"sample_time_ms": 10730.39, "sample_throughput": 372.773, "load_time_ms": 0.335, "load_throughput": 11924105.188, "learn_time_ms": 2226.919, "learn_throughput": 1796.203, "update_time_ms": 2.096}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.89999771118164, "policy_loss": -0.017899932339787483, "vf_loss": 8.913976669311523, "vf_explained_var": 0.0251462385058403, "kl": 0.005810911767184734, "entropy": 1.5618972778320312, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 212000, "num_agent_steps_sampled": 212000, "num_steps_trained": 212000, "num_agent_steps_trained": 212000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11156, "training_iteration": 53, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-16", "timestamp": 1642601656, "time_this_iter_s": 9.814512014389038, "time_total_s": 552.9850375652313, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 552.9850375652313, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 44.47142857142857, "ram_util_percent": 62.29285714285715}}
{"episode_reward_max": -1.2, "episode_reward_min": -21.700000000000003, "episode_reward_mean": -4.088207547169811, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -2.7, -18.7, -12.699999999999998, -1.7000000000000004, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -3.7000000000000015, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.9, -2.7000000000000015, -1.7000000000000004, -3.6000000000000014, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -4.6999999999999975, -2.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -2.700000000000001, -2.7, -4.7, -7.699999999999999, -7.699999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -11.7, -2.7, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -8.7, -3.7000000000000015, -8.7, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7, -9.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -8.7, -7.699999999999999, -1.7000000000000004, -2.7, -8.7, -4.7, -2.7, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -9.699999999999998, -21.700000000000003, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -1.2, -2.700000000000001, -2.7, -3.7000000000000006, -2.7000000000000006, -9.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -8.7, -2.700000000000001, -2.9, -2.7000000000000015, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -3.7000000000000015, -1.7000000000000004, -4.7, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -12.699999999999998, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -2.7000000000000006, -4.7, -2.7000000000000015, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -7.6999999999999975, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -5.700000000000001, -2.7, -11.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.7000000000000015, -9.699999999999998, -3.700000000000001, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -9.7, -9.699999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -6.699999999999999, -2.7000000000000015, -8.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -7.699999999999999, -5.699999999999999, -1.7000000000000004, -6.700000000000001, -8.7, -1.7000000000000004, -4.7, -1.7000000000000004, -13.4, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -5.700000000000001, -2.700000000000001, -2.7000000000000015, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.37527808817057, "mean_inference_ms": 1.281575282121888, "mean_action_processing_ms": 0.092068647173179, "mean_env_wait_ms": 4.257268129557393, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 216000, "timesteps_this_iter": 0, "agent_timesteps_total": 216000, "timers": {"sample_time_ms": 10722.808, "sample_throughput": 373.037, "load_time_ms": 0.335, "load_throughput": 11941079.004, "learn_time_ms": 2242.111, "learn_throughput": 1784.033, "update_time_ms": 2.095}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.519556999206543, "policy_loss": -0.013697138987481594, "vf_loss": 7.528796672821045, "vf_explained_var": 0.04621323570609093, "kl": 0.006604304537177086, "entropy": 1.554945468902588, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 216000, "num_agent_steps_sampled": 216000, "num_steps_trained": 216000, "num_agent_steps_trained": 216000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11368, "training_iteration": 54, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-26", "timestamp": 1642601666, "time_this_iter_s": 9.955981016159058, "time_total_s": 562.9410185813904, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 562.9410185813904, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 45.21428571428571, "ram_util_percent": 62.25}}
{"episode_reward_max": -1.2, "episode_reward_min": -20.700000000000003, "episode_reward_mean": -4.432692307692308, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.700000000000003, -2.700000000000001, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -19.700000000000003, -2.7, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -2.700000000000001, -7.699999999999999, -2.7000000000000015, -18.700000000000003, -2.7000000000000006, -11.699999999999998, -3.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -16.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -13.699999999999998, -3.7000000000000015, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7, -3.7000000000000006, -2.7000000000000015, -1.7000000000000004, -10.699999999999998, -6.699999999999999, -1.7000000000000004, -2.7, -8.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -7.3, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -8.7, -20.700000000000003, -7.699999999999999, -7.699999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -8.7, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -2.7, -1.7000000000000004, -7.699999999999999, -15.699999999999998, -2.7, -2.7, -1.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -10.699999999999998, -9.699999999999998, -2.6000000000000014, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -2.700000000000001, -4.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -12.599999999999998, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -4.700000000000001, -7.700000000000001, -2.7000000000000015, -1.7000000000000004, -5.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -8.7, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -2.7000000000000015, -2.7000000000000006, -2.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7000000000000006, -4.7, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -9.7, -7.699999999999999, -1.7000000000000004, -10.7, -14.699999999999998, -4.7, -2.7000000000000006, -2.7000000000000015, -2.7000000000000015, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -15.699999999999998, -15.699999999999998, -11.7, -6.699999999999999, -9.7, -2.9000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -8.699999999999998, -11.8, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.3, -4.700000000000001, -13.699999999999998, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3740319440075317, "mean_inference_ms": 1.282031350876101, "mean_action_processing_ms": 0.09199420711486611, "mean_env_wait_ms": 4.2534564428356685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 220000, "timesteps_this_iter": 0, "agent_timesteps_total": 220000, "timers": {"sample_time_ms": 10616.519, "sample_throughput": 376.771, "load_time_ms": 0.333, "load_throughput": 11994863.802, "learn_time_ms": 2210.872, "learn_throughput": 1809.241, "update_time_ms": 2.058}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.440231323242188, "policy_loss": -0.015831630676984787, "vf_loss": 9.451029777526855, "vf_explained_var": 0.07890564203262329, "kl": 0.007456710562109947, "entropy": 1.5695708990097046, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 220000, "num_agent_steps_sampled": 220000, "num_steps_trained": 220000, "num_agent_steps_trained": 220000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11576, "training_iteration": 55, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-36", "timestamp": 1642601676, "time_this_iter_s": 9.96592402458191, "time_total_s": 572.9069426059723, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 572.9069426059723, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 43.45333333333333, "ram_util_percent": 62.299999999999976}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.082075471698114, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -12.699999999999998, -3.7000000000000015, -8.7, -2.7, -1.7000000000000004, -1.7000000000000004, -21.700000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -2.700000000000001, -16.7, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -5.700000000000001, -23.700000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.2, -8.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -20.700000000000003, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.3, -1.7000000000000004, -3.7, -2.700000000000001, -5.699999999999999, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -2.7000000000000006, -2.7000000000000015, -11.6, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -10.699999999999998, -2.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.6000000000000014, -8.7, -11.699999999999998, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -13.2, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -14.699999999999998, -3.700000000000001, -3.7000000000000015, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -11.699999999999998, -3.700000000000001, -6.700000000000001, -9.5, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -8.7, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -5.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -12.699999999999998, -2.700000000000001, -5.700000000000001, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -8.7, -8.7, -1.7000000000000004, -7.700000000000001, -3.7000000000000006, -2.7, -12.699999999999998, -2.7000000000000015, -11.699999999999998, -1.5, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -14.699999999999998, -2.7000000000000006, -2.7000000000000015, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.373119792402482, "mean_inference_ms": 1.2810307782355492, "mean_action_processing_ms": 0.09193817263566922, "mean_env_wait_ms": 4.249957426899521, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 224000, "timesteps_this_iter": 0, "agent_timesteps_total": 224000, "timers": {"sample_time_ms": 10519.137, "sample_throughput": 380.259, "load_time_ms": 0.326, "load_throughput": 12259565.948, "learn_time_ms": 2173.202, "learn_throughput": 1840.602, "update_time_ms": 2.046}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.997849464416504, "policy_loss": -0.013498852029442787, "vf_loss": 9.006617546081543, "vf_explained_var": 0.009848649613559246, "kl": 0.007008769549429417, "entropy": 1.5545854568481445, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 224000, "num_agent_steps_sampled": 224000, "num_steps_trained": 224000, "num_agent_steps_trained": 224000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11788, "training_iteration": 56, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-46", "timestamp": 1642601686, "time_this_iter_s": 9.719139814376831, "time_total_s": 582.6260824203491, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 582.6260824203491, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 45.86153846153846, "ram_util_percent": 62.25384615384617}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -21.700000000000006, "episode_reward_mean": -4.354716981132076, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.700000000000001, -3.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.2, -4.7, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -4.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -14.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -11.699999999999998, -2.700000000000001, -10.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.3, -10.699999999999998, -9.7, -2.7, -6.699999999999999, -15.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -2.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000015, -2.7, -21.700000000000006, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -4.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000006, -3.6000000000000014, -2.700000000000001, -1.7000000000000004, -3.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -16.7, -4.699999999999999, -9.7, -2.7000000000000006, -8.7, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -4.7, -14.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -16.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -7.699999999999999, -2.7, -10.699999999999998, -2.7000000000000006, -8.7, -2.7000000000000015, -1.7000000000000004, -8.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -21.5, -1.7000000000000004, -2.7000000000000006, -4.700000000000001, -2.7000000000000006, -7.699999999999999, -7.699999999999999, -3.7000000000000015, -16.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -12.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -7.699999999999999, -2.7000000000000015, -3.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -11.699999999999998, -2.7000000000000006, -4.7, -9.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -6.700000000000001, -15.699999999999998, -10.7, -5.700000000000001, -9.699999999999998, -8.7, -15.699999999999998, -1.7000000000000004, -8.7, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.379701305102035, "mean_inference_ms": 1.284452168009297, "mean_action_processing_ms": 0.09215468053338745, "mean_env_wait_ms": 4.262706438337857, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 228000, "timesteps_this_iter": 0, "agent_timesteps_total": 228000, "timers": {"sample_time_ms": 10537.481, "sample_throughput": 379.597, "load_time_ms": 0.328, "load_throughput": 12184774.493, "learn_time_ms": 2179.933, "learn_throughput": 1834.919, "update_time_ms": 2.077}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.048001289367676, "policy_loss": -0.017545847222208977, "vf_loss": 9.0606689453125, "vf_explained_var": 0.04888260364532471, "kl": 0.0072289262898266315, "entropy": 1.4984146356582642, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 228000, "num_agent_steps_sampled": 228000, "num_steps_trained": 228000, "num_agent_steps_trained": 228000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12000, "training_iteration": 57, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-14-58", "timestamp": 1642601698, "time_this_iter_s": 11.70664119720459, "time_total_s": 594.3327236175537, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 594.3327236175537, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 54.317647058823525, "ram_util_percent": 62.3235294117647}}
{"episode_reward_max": -1.5, "episode_reward_min": -26.699999999999996, "episode_reward_mean": -4.228365384615386, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.699999999999998, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -4.700000000000001, -2.7000000000000015, -9.7, -1.7000000000000004, -4.699999999999998, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -15.699999999999998, -2.700000000000001, -13.699999999999998, -2.7, -2.5, -2.7000000000000015, -2.7, -14.699999999999998, -3.7000000000000006, -6.699999999999999, -7.699999999999999, -3.700000000000001, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -17.700000000000003, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.3000000000000003, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -4.7, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.5, -3.7000000000000015, -2.2, -2.7000000000000015, -2.7000000000000015, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -8.7, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.7, -4.7, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -3.700000000000001, -5.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -5.7, -8.7, -2.7000000000000006, -11.699999999999998, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -5.700000000000001, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -5.700000000000001, -4.7, -1.7000000000000004, -3.7000000000000006, -4.9, -1.7000000000000004, -14.699999999999998, -26.699999999999996, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -3.700000000000001, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -3.7000000000000015, -2.7, -9.699999999999998, -6.699999999999999, -2.7000000000000006, -12.699999999999998, -1.7000000000000004, -17.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -2.7, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -2.7000000000000015, -2.7000000000000015, -13.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -12.699999999999998, -13.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -4.7, -3.7000000000000006, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -9.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -16.7, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.700000000000001, -5.700000000000001, -2.7000000000000015, -9.7, -2.7000000000000015, -2.7000000000000015, -15.699999999999998, -9.7, -3.7000000000000015, -8.7, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.381861111215122, "mean_inference_ms": 1.2860072279582342, "mean_action_processing_ms": 0.09227988925511006, "mean_env_wait_ms": 4.267537176205174, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 232000, "timesteps_this_iter": 0, "agent_timesteps_total": 232000, "timers": {"sample_time_ms": 10635.547, "sample_throughput": 376.097, "load_time_ms": 0.331, "load_throughput": 12096918.307, "learn_time_ms": 2140.506, "learn_throughput": 1868.717, "update_time_ms": 2.094}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.936745643615723, "policy_loss": -0.017796238884329796, "vf_loss": 8.949630737304688, "vf_explained_var": 0.04598189890384674, "kl": 0.007276889402419329, "entropy": 1.5304534435272217, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 232000, "num_agent_steps_sampled": 232000, "num_steps_trained": 232000, "num_agent_steps_trained": 232000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12208, "training_iteration": 58, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-15-08", "timestamp": 1642601708, "time_this_iter_s": 10.871967554092407, "time_total_s": 605.2046911716461, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 605.2046911716461, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 48.68125, "ram_util_percent": 62.4}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.190094339622642, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7, -5.699999999999999, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -2.7, -1.7000000000000004, -2.7000000000000015, -4.699999999999998, -4.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -8.7, -3.7000000000000006, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -14.299999999999999, -16.7, -6.699999999999999, -2.0999999999999996, -2.7000000000000015, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -4.300000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7, -9.699999999999998, -11.699999999999998, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -9.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -9.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -19.7, -7.699999999999999, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -3.7000000000000006, -3.7000000000000015, -11.699999999999998, -23.700000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7, -23.700000000000006, -1.7000000000000004, -2.700000000000001, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -6.699999999999999, -4.700000000000001, -4.700000000000001, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -16.7, -10.699999999999998, -10.699999999999998, -11.699999999999998, -3.7, -2.7000000000000006, -2.700000000000001, -16.700000000000003, -3.7000000000000015, -1.7000000000000004, -4.7, -4.7, -5.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -4.7, -2.700000000000001, -2.7000000000000006, -7.699999999999999, -7.699999999999999, -3.500000000000001, -11.699999999999998, -1.7000000000000004, -8.699999999999998, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.2, -3.7000000000000015, -2.700000000000001, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -17.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.700000000000001, -3.7000000000000015, -2.2, -4.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -11.699999999999998, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7, -14.7, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -12.699999999999998, -2.7000000000000006, -3.7000000000000006, -4.700000000000001, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3814958163543136, "mean_inference_ms": 1.2861335866118009, "mean_action_processing_ms": 0.09229780304211886, "mean_env_wait_ms": 4.267916951376945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 236000, "timesteps_this_iter": 0, "agent_timesteps_total": 236000, "timers": {"sample_time_ms": 10434.268, "sample_throughput": 383.352, "load_time_ms": 0.33, "load_throughput": 12118763.363, "learn_time_ms": 2112.069, "learn_throughput": 1893.877, "update_time_ms": 2.062}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.120447158813477, "policy_loss": -0.013663889840245247, "vf_loss": 9.12984561920166, "vf_explained_var": 0.023478519171476364, "kl": 0.006317865569144487, "entropy": 1.5213786363601685, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 236000, "num_agent_steps_sampled": 236000, "num_steps_trained": 236000, "num_agent_steps_trained": 236000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12420, "training_iteration": 59, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-15-19", "timestamp": 1642601719, "time_this_iter_s": 10.402827024459839, "time_total_s": 615.607518196106, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 615.607518196106, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 47.173333333333325, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.097596153846155, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000015, -23.700000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -2.7000000000000006, -9.6, -1.7000000000000004, -7.699999999999999, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -6.700000000000001, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -12.2, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -4.7, -14.699999999999998, -2.7, -3.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -5.700000000000001, -4.7, -2.7000000000000006, -8.7, -1.7000000000000004, -12.7, -1.7000000000000004, -4.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -10.2, -1.5, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -14.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000015, -2.7000000000000006, -2.7, -1.7000000000000004, -3.700000000000001, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -3.7, -3.7000000000000015, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -8.2, -1.7000000000000004, -10.699999999999998, -2.7000000000000015, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7, -2.700000000000001, -6.699999999999999, -12.699999999999998, -5.700000000000001, -10.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -6.699999999999999, -2.7000000000000015, -3.7000000000000015, -2.7000000000000015, -8.700000000000001, -4.699999999999999, -1.7000000000000004, -3.7000000000000006, -11.699999999999998, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -9.7, -1.7000000000000004, -13.2, -2.7000000000000015, -5.699999999999999, -1.7000000000000004, -3.7000000000000006, -8.7, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -5.2, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -3.700000000000001, -2.7000000000000015, -3.7000000000000015, -14.699999999999998, -2.7000000000000015, -9.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -4.7, -11.699999999999998, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3823048110381833, "mean_inference_ms": 1.2863843461393971, "mean_action_processing_ms": 0.09232332216867024, "mean_env_wait_ms": 4.26822294304942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 240000, "timesteps_this_iter": 0, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 10321.575, "sample_throughput": 387.538, "load_time_ms": 0.329, "load_throughput": 12170631.846, "learn_time_ms": 2084.708, "learn_throughput": 1918.734, "update_time_ms": 2.107}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.986137866973877, "policy_loss": -0.013680040836334229, "vf_loss": 7.995770454406738, "vf_explained_var": 0.05619533732533455, "kl": 0.00599667988717556, "entropy": 1.5094184875488281, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 240000, "num_agent_steps_sampled": 240000, "num_steps_trained": 240000, "num_agent_steps_trained": 240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12628, "training_iteration": 60, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-15-30", "timestamp": 1642601730, "time_this_iter_s": 10.589777946472168, "time_total_s": 626.1972961425781, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 626.1972961425781, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 48.919999999999995, "ram_util_percent": 62.37999999999999}}
{"episode_reward_max": -1.7, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.148584905660377, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.7, -1.7000000000000004, -4.7, -1.7000000000000004, -4.7, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -13.699999999999998, -2.7000000000000015, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000006, -2.7, -10.699999999999998, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -14.699999999999998, -3.700000000000001, -19.700000000000003, -2.5, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -5.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7000000000000006, -11.7, -1.7000000000000004, -3.7, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -7.699999999999999, -6.700000000000001, -1.7000000000000004, -2.700000000000001, -8.7, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -2.7000000000000015, -2.7000000000000006, -8.699999999999998, -2.7000000000000006, -8.7, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000015, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -7.699999999999999, -3.7000000000000006, -1.7000000000000004, -9.699999999999998, -8.7, -9.699999999999998, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -4.7, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -5.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -7.2, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -14.699999999999998, -1.7000000000000004, -4.7, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -2.700000000000001, -8.7, -2.7000000000000006, -4.7, -2.7000000000000006, -14.699999999999998, -4.700000000000001, -1.7000000000000004, -18.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.5, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -18.700000000000003, -4.7, -1.7000000000000004, -5.699999999999999, -12.7, -1.7000000000000004, -2.7000000000000006, -1.7, -10.699999999999998, -11.7, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.383123163148943, "mean_inference_ms": 1.2867743416975028, "mean_action_processing_ms": 0.09236462719977749, "mean_env_wait_ms": 4.2688050859629225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 244000, "timesteps_this_iter": 0, "agent_timesteps_total": 244000, "timers": {"sample_time_ms": 10404.217, "sample_throughput": 384.459, "load_time_ms": 0.329, "load_throughput": 12155641.211, "learn_time_ms": 2038.117, "learn_throughput": 1962.595, "update_time_ms": 2.068}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.895306587219238, "policy_loss": -0.014811569824814796, "vf_loss": 8.905502319335938, "vf_explained_var": 0.058149971067905426, "kl": 0.006837398745119572, "entropy": 1.5050904750823975, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 244000, "num_agent_steps_sampled": 244000, "num_steps_trained": 244000, "num_agent_steps_trained": 244000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12840, "training_iteration": 61, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-15-40", "timestamp": 1642601740, "time_this_iter_s": 10.388304948806763, "time_total_s": 636.5856010913849, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 636.5856010913849, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 46.95333333333334, "ram_util_percent": 62.36666666666666}}
{"episode_reward_max": -1.2, "episode_reward_min": -19.700000000000003, "episode_reward_mean": -3.8778301886792454, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7, -1.7000000000000004, -3.700000000000001, -2.7, -6.699999999999999, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -1.2, -1.7000000000000004, -1.7000000000000004, -8.7, -11.699999999999998, -8.7, -2.7000000000000006, -1.7000000000000004, -18.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -2.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -3.7000000000000006, -7.699999999999999, -3.7, -1.7000000000000004, -16.7, -9.7, -1.7000000000000004, -14.699999999999998, -19.700000000000003, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.5, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.6999999999999975, -3.7000000000000015, -7.699999999999999, -1.7000000000000004, -14.9, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -4.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7000000000000015, -1.7000000000000004, -4.100000000000001, -1.7000000000000004, -2.7, -2.7000000000000015, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -4.7, -2.5, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -4.7, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -9.7, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -2.7, -4.699999999999998, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -8.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -7.699999999999999, -2.7000000000000015, -2.7000000000000006, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -16.7, -2.7000000000000006, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -16.7, -2.7, -2.7000000000000006, -16.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -4.699999999999999, -11.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -6.699999999999999, -1.7000000000000004, -10.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -14.699999999999998, -2.700000000000001, -2.7, -2.7, -2.7000000000000006, -15.699999999999998, -3.7000000000000015, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3874279900951985, "mean_inference_ms": 1.2896839569592498, "mean_action_processing_ms": 0.09253274679003226, "mean_env_wait_ms": 4.277839557549385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 248000, "timesteps_this_iter": 0, "agent_timesteps_total": 248000, "timers": {"sample_time_ms": 10505.944, "sample_throughput": 380.737, "load_time_ms": 0.331, "load_throughput": 12101281.016, "learn_time_ms": 2033.056, "learn_throughput": 1967.482, "update_time_ms": 2.058}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.709482192993164, "policy_loss": -0.014523640275001526, "vf_loss": 7.719661235809326, "vf_explained_var": 0.07101599872112274, "kl": 0.006434930954128504, "entropy": 1.4779856204986572, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 248000, "num_agent_steps_sampled": 248000, "num_steps_trained": 248000, "num_agent_steps_trained": 248000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13052, "training_iteration": 62, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-15-51", "timestamp": 1642601751, "time_this_iter_s": 11.33626103401184, "time_total_s": 647.9218621253967, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 647.9218621253967, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 50.974999999999994, "ram_util_percent": 62.4}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.040865384615386, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7, -1.7000000000000004, -8.6, -2.700000000000001, -1.7000000000000004, -5.2, -3.700000000000001, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -22.700000000000006, -3.7000000000000015, -3.7, -4.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.7, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.2, -3.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -11.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -3.7, -1.7000000000000004, -2.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -10.7, -8.7, -8.7, -9.699999999999998, -2.700000000000001, -2.7, -1.7000000000000004, -9.7, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -8.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -23.700000000000006, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -15.7, -5.699999999999999, -1.7000000000000004, -11.699999999999998, -7.6999999999999975, -2.7000000000000006, -2.7000000000000006, -4.7, -2.7, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7, -8.7, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.1, -12.699999999999998, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -3.7000000000000006, -2.7000000000000006, -8.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.3, -11.699999999999998, -1.7000000000000004, -3.700000000000001, -11.7, -1.7000000000000004, -3.7, -2.7, -2.7000000000000006, -1.7000000000000004, -9.7, -2.700000000000001, -9.7, -2.7000000000000015, -1.7000000000000004, -8.7, -2.7, -2.7, -2.700000000000001, -13.699999999999998, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -7.699999999999999, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -12.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -7.699999999999999, -2.7000000000000015, -14.699999999999998, -12.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.388943441500616, "mean_inference_ms": 1.2906503502152213, "mean_action_processing_ms": 0.09260047373492607, "mean_env_wait_ms": 4.280835416108431, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 252000, "timesteps_this_iter": 0, "agent_timesteps_total": 252000, "timers": {"sample_time_ms": 10577.744, "sample_throughput": 378.152, "load_time_ms": 0.333, "load_throughput": 12018923.992, "learn_time_ms": 2048.21, "learn_throughput": 1952.925, "update_time_ms": 2.109}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.474247932434082, "policy_loss": -0.014731285162270069, "vf_loss": 8.484904289245605, "vf_explained_var": 0.05675739422440529, "kl": 0.006036002654582262, "entropy": 1.4760817289352417, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 252000, "num_agent_steps_sampled": 252000, "num_steps_trained": 252000, "num_agent_steps_trained": 252000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13260, "training_iteration": 63, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-02", "timestamp": 1642601762, "time_this_iter_s": 10.736545085906982, "time_total_s": 658.6584072113037, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 658.6584072113037, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 48.6, "ram_util_percent": 62.43333333333332}}
{"episode_reward_max": -1.5, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.448584905660378, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.7, -1.7000000000000004, -11.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -12.699999999999998, -3.700000000000001, -2.700000000000001, -15.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -4.1, -1.7000000000000004, -3.700000000000001, -5.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -11.699999999999998, -1.7000000000000004, -3.7000000000000006, -4.7, -3.7000000000000006, -6.699999999999999, -4.700000000000001, -2.7000000000000006, -9.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -4.699999999999999, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -7.699999999999999, -4.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -8.7, -2.7000000000000006, -9.699999999999998, -1.7000000000000004, -12.699999999999998, -2.7000000000000006, -23.700000000000006, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -8.7, -2.7, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -2.6000000000000014, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -5.7, -1.7000000000000004, -21.700000000000006, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -11.699999999999998, -2.7000000000000006, -13.699999999999998, -11.2, -4.700000000000001, -2.7, -7.699999999999999, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -11.699999999999998, -2.700000000000001, -2.7000000000000015, -2.700000000000001, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -2.700000000000001, -2.7000000000000015, -3.7000000000000015, -1.7000000000000004, -3.7, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -4.699999999999998, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -4.7, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -19.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -11.699999999999998, -8.7, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -4.7, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -4.7, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -1.5, -13.699999999999998, -16.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7, -2.7000000000000006, -3.700000000000001, -4.699999999999998, -2.2, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -2.7, -8.7, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -11.699999999999998, -7.699999999999999, -2.7000000000000006, -11.7, -1.7000000000000004, -2.3, -2.7000000000000006, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.393409150892588, "mean_inference_ms": 1.2940320379519727, "mean_action_processing_ms": 0.09278783321239056, "mean_env_wait_ms": 4.289676846158674, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 256000, "timesteps_this_iter": 0, "agent_timesteps_total": 256000, "timers": {"sample_time_ms": 10738.721, "sample_throughput": 372.484, "load_time_ms": 0.334, "load_throughput": 11979447.34, "learn_time_ms": 2050.511, "learn_throughput": 1950.733, "update_time_ms": 2.133}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.23154067993164, "policy_loss": -0.016630565747618675, "vf_loss": 10.24349594116211, "vf_explained_var": 0.011100595816969872, "kl": 0.006926718633621931, "entropy": 1.5059295892715454, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 256000, "num_agent_steps_sampled": 256000, "num_steps_trained": 256000, "num_agent_steps_trained": 256000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13472, "training_iteration": 64, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-14", "timestamp": 1642601774, "time_this_iter_s": 11.437434911727905, "time_total_s": 670.0958421230316, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 670.0958421230316, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 52.15625, "ram_util_percent": 62.293749999999996}}
{"episode_reward_max": -1.2, "episode_reward_min": -25.700000000000003, "episode_reward_mean": -4.409905660377359, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000006, -2.7, -4.7, -2.7000000000000015, -2.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -6.699999999999999, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -2.7000000000000006, -23.700000000000006, -2.700000000000001, -7.699999999999999, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -4.7, -1.7000000000000004, -5.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.7, -3.7000000000000006, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -10.699999999999998, -21.700000000000003, -10.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7, -3.7000000000000006, -10.699999999999998, -3.5, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -21.700000000000006, -2.7, -2.700000000000001, -2.7000000000000015, -2.7, -8.7, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -13.699999999999998, -5.7, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -2.700000000000001, -3.7000000000000015, -14.699999999999998, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -8.7, -11.699999999999998, -1.7000000000000004, -9.7, -4.7, -9.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.0999999999999996, -1.7000000000000004, -2.700000000000001, -11.699999999999998, -1.7000000000000004, -2.700000000000001, -13.699999999999998, -1.7000000000000004, -4.7, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -5.699999999999999, -8.699999999999998, -14.699999999999998, -1.7000000000000004, -2.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -24.700000000000006, -10.699999999999998, -2.7, -2.700000000000001, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -4.500000000000002, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -20.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -6.700000000000001, -1.7000000000000004, -25.700000000000003, -3.7, -2.700000000000001, -1.7000000000000004, -11.699999999999998, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.2, -3.7000000000000006, -12.699999999999998, -2.7000000000000015, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.392856897320175, "mean_inference_ms": 1.2942913031534415, "mean_action_processing_ms": 0.09281279569376348, "mean_env_wait_ms": 4.289305673555433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 260000, "timesteps_this_iter": 0, "agent_timesteps_total": 260000, "timers": {"sample_time_ms": 10757.242, "sample_throughput": 371.843, "load_time_ms": 0.335, "load_throughput": 11937680.376, "learn_time_ms": 2071.071, "learn_throughput": 1931.368, "update_time_ms": 2.151}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 10.98322582244873, "policy_loss": -0.015714354813098907, "vf_loss": 10.99450397491455, "vf_explained_var": 0.03965502604842186, "kl": 0.006571349687874317, "entropy": 1.488211989402771, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 260000, "num_agent_steps_sampled": 260000, "num_steps_trained": 260000, "num_agent_steps_trained": 260000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13684, "training_iteration": 65, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-24", "timestamp": 1642601784, "time_this_iter_s": 10.325714111328125, "time_total_s": 680.4215562343597, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 680.4215562343597, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 46.11333333333333, "ram_util_percent": 62.31333333333331}}
{"episode_reward_max": -1.2, "episode_reward_min": -25.700000000000003, "episode_reward_mean": -4.174519230769231, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -9.7, -2.7000000000000006, -4.7, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -2.5, -2.7000000000000006, -2.7000000000000006, -10.699999999999998, -10.699999999999998, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7, -14.699999999999998, -3.7000000000000015, -1.7000000000000004, -4.700000000000001, -3.7000000000000015, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -13.699999999999998, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -8.7, -2.700000000000001, -1.2, -14.699999999999998, -14.699999999999998, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.500000000000001, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -3.7000000000000006, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -25.700000000000003, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7, -17.7, -4.7, -3.700000000000001, -3.7000000000000015, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -2.7, -2.700000000000001, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.2, -2.700000000000001, -7.699999999999999, -2.5, -1.7000000000000004, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -13.699999999999998, -1.7000000000000004, -4.7, -2.7000000000000015, -1.7000000000000004, -10.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -4.7, -20.700000000000003, -2.700000000000001, -2.7, -2.7000000000000006, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -8.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.2, -11.7, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -3.7, -2.700000000000001, -2.7, -18.700000000000003, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -7.699999999999999, -7.6999999999999975, -2.7000000000000006, -2.7, -2.700000000000001, -1.7000000000000004, -9.7, -1.7000000000000004, -2.700000000000001, -3.5000000000000004, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.9, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -2.7000000000000015, -1.7000000000000004, -11.699999999999998, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -6.700000000000001, -1.7000000000000004, -3.7000000000000015], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3942130892293485, "mean_inference_ms": 1.2951077671640274, "mean_action_processing_ms": 0.09284439803025928, "mean_env_wait_ms": 4.290810484909359, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 264000, "timesteps_this_iter": 0, "agent_timesteps_total": 264000, "timers": {"sample_time_ms": 10852.298, "sample_throughput": 368.586, "load_time_ms": 0.336, "load_throughput": 11899578.694, "learn_time_ms": 2099.194, "learn_throughput": 1905.493, "update_time_ms": 2.195}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.869094848632812, "policy_loss": -0.015992900356650352, "vf_loss": 8.880976676940918, "vf_explained_var": 0.04810716211795807, "kl": 0.006090203300118446, "entropy": 1.484679102897644, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 264000, "num_agent_steps_sampled": 264000, "num_steps_trained": 264000, "num_agent_steps_trained": 264000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13892, "training_iteration": 66, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-35", "timestamp": 1642601795, "time_this_iter_s": 10.74374008178711, "time_total_s": 691.1652963161469, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 691.1652963161469, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 46.766666666666666, "ram_util_percent": 62.36666666666665}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.375943396226416, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7, -2.7000000000000006, -2.7000000000000006, -10.699999999999998, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -9.7, -12.2, -2.7000000000000006, -3.7000000000000015, -8.7, -1.7000000000000004, -1.7000000000000004, -17.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -6.699999999999999, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -17.700000000000003, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -23.700000000000006, -2.7000000000000015, -4.7, -2.7, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7, -4.700000000000001, -6.699999999999999, -2.7000000000000006, -4.7, -8.2, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -6.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -16.7, -1.7000000000000004, -1.7000000000000004, -2.7, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.7, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -4.7, -2.7, -6.699999999999999, -2.7000000000000015, -3.2, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -3.7000000000000015, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -19.700000000000003, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.2, -1.7000000000000004, -2.7, -8.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -8.7, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -2.7000000000000015, -13.699999999999998, -11.699999999999998, -4.700000000000001, -3.7000000000000015, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -10.699999999999998, -3.7000000000000006, -14.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -8.7, -2.7000000000000015, -3.7000000000000015, -2.7000000000000006, -2.7000000000000006, -3.2, -1.7000000000000004, -9.699999999999998, -3.700000000000001, -3.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -16.7, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -8.7, -10.699999999999998, -1.2, -7.699999999999999, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.7, -3.2, -2.7000000000000006, -2.7, -2.7000000000000006, -8.699999999999998, -9.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7, -3.700000000000001, -12.7, -2.7000000000000015, -2.7, -2.7, -1.7000000000000004, -2.7, -14.699999999999998, -10.699999999999998, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -3.7000000000000006, -2.5, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -4.7, -2.7, -11.7, -1.7000000000000004, -3.2, -2.7, -2.7000000000000006, -2.7000000000000006, -4.699999999999999, -1.2, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -15.699999999999998, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4029283866521354, "mean_inference_ms": 1.2994456272694879, "mean_action_processing_ms": 0.09315546066966944, "mean_env_wait_ms": 4.305208368612114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 268000, "timesteps_this_iter": 0, "agent_timesteps_total": 268000, "timers": {"sample_time_ms": 10937.94, "sample_throughput": 365.7, "load_time_ms": 0.338, "load_throughput": 11846643.13, "learn_time_ms": 2192.651, "learn_throughput": 1824.275, "update_time_ms": 2.198}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.648313522338867, "policy_loss": -0.012925415299832821, "vf_loss": 8.657515525817871, "vf_explained_var": 0.0704934224486351, "kl": 0.005515799857676029, "entropy": 1.489917278289795, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 268000, "num_agent_steps_sampled": 268000, "num_steps_trained": 268000, "num_agent_steps_trained": 268000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14104, "training_iteration": 67, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-48", "timestamp": 1642601808, "time_this_iter_s": 13.210103988647461, "time_total_s": 704.3754003047943, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 704.3754003047943, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 59.584210526315786, "ram_util_percent": 62.38947368421052}}
{"episode_reward_max": -1.2, "episode_reward_min": -21.700000000000006, "episode_reward_mean": -3.8456730769230774, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.2, -2.7000000000000006, -8.7, -12.699999999999998, -5.700000000000001, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -4.7, -2.7, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -8.700000000000001, -4.5, -1.7000000000000004, -2.700000000000001, -5.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -3.7000000000000015, -5.700000000000001, -18.5, -2.7000000000000006, -2.7, -3.7, -4.7, -3.700000000000001, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.7, -8.7, -1.2, -1.7000000000000004, -2.2, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7, -2.7000000000000006, -3.7000000000000006, -10.699999999999998, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -5.699999999999999, -4.699999999999999, -1.7000000000000004, -1.7000000000000004, -10.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -15.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -11.699999999999998, -2.7, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -6.699999999999999, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7, -2.7, -2.7000000000000006, -2.7, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -4.6999999999999975, -11.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -7.699999999999999, -1.7000000000000004, -13.5, -3.2, -4.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -3.900000000000001, -1.7000000000000004, -2.7000000000000006, -3.3000000000000007, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -4.9, -7.699999999999999, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.0999999999999996, -2.7000000000000006, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.9, -2.700000000000001, -21.700000000000006, -6.699999999999999, -15.699999999999998, -10.699999999999998, -1.7000000000000004, -5.6000000000000005, -1.7000000000000004, -3.0999999999999996, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.405938727931309, "mean_inference_ms": 1.3019082157091648, "mean_action_processing_ms": 0.09331616094411431, "mean_env_wait_ms": 4.313017962229635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 272000, "timesteps_this_iter": 0, "agent_timesteps_total": 272000, "timers": {"sample_time_ms": 11079.022, "sample_throughput": 361.043, "load_time_ms": 0.338, "load_throughput": 11838283.94, "learn_time_ms": 2212.774, "learn_throughput": 1807.685, "update_time_ms": 2.191}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.63624906539917, "policy_loss": -0.014295190572738647, "vf_loss": 6.647140979766846, "vf_explained_var": 0.0359555222094059, "kl": 0.005041321273893118, "entropy": 1.4777987003326416, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 272000, "num_agent_steps_sampled": 272000, "num_steps_trained": 272000, "num_agent_steps_trained": 272000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14312, "training_iteration": 68, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-16-59", "timestamp": 1642601819, "time_this_iter_s": 11.539175271987915, "time_total_s": 715.9145755767822, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 715.9145755767822, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 53.13529411764706, "ram_util_percent": 62.38235294117647}}
{"episode_reward_max": -1.7, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.8155660377358496, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.3, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -11.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.5, -15.699999999999998, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.7, -2.7000000000000006, -6.699999999999999, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.2, -8.7, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -8.2, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -3.7000000000000006, -3.7000000000000015, -8.7, -1.7000000000000004, -2.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -2.7000000000000015, -7.699999999999999, -1.7000000000000004, -15.699999999999998, -3.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -2.700000000000001, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -3.7000000000000015, -1.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -9.7, -10.699999999999998, -2.7000000000000015, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7000000000000006, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -9.699999999999998, -3.700000000000001, -15.699999999999998, -2.7000000000000006, -8.699999999999998, -2.7000000000000006, -7.699999999999999, -10.699999999999998, -2.7000000000000015, -3.7000000000000015, -2.7000000000000015, -10.699999999999998, -14.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -10.699999999999998, -5.699999999999999, -3.7000000000000006, -2.7000000000000006, -9.7, -1.7000000000000004, -15.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -2.7, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -6.700000000000001, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -3.3, -2.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -4.2, -11.699999999999998, -2.7000000000000006, -6.699999999999999, -1.7000000000000004, -3.7, -3.7000000000000006, -3.7000000000000015, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -23.700000000000006, -2.700000000000001, -2.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4034723893668115, "mean_inference_ms": 1.3002096596849955, "mean_action_processing_ms": 0.09320727400281399, "mean_env_wait_ms": 4.307211077722425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 276000, "timesteps_this_iter": 0, "agent_timesteps_total": 276000, "timers": {"sample_time_ms": 11034.592, "sample_throughput": 362.496, "load_time_ms": 0.338, "load_throughput": 11834943.567, "learn_time_ms": 2235.784, "learn_throughput": 1789.081, "update_time_ms": 2.2}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.35233211517334, "policy_loss": -0.01747751049697399, "vf_loss": 6.365334987640381, "vf_explained_var": 0.09280664473772049, "kl": 0.006628525443375111, "entropy": 1.4747364521026611, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 276000, "num_agent_steps_sampled": 276000, "num_steps_trained": 276000, "num_agent_steps_trained": 276000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14524, "training_iteration": 69, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-17-09", "timestamp": 1642601829, "time_this_iter_s": 9.989245891571045, "time_total_s": 725.9038214683533, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 725.9038214683533, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 45.607142857142854, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -21.700000000000006, "episode_reward_mean": -3.808490566037736, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -3.700000000000001, -2.7000000000000015, -3.7000000000000015, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -4.500000000000001, -5.700000000000001, -2.2, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7, -2.700000000000001, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.399999999999999, -2.7000000000000006, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.0999999999999996, -3.2, -1.7000000000000004, -1.7000000000000004, -2.3, -2.7, -1.7000000000000004, -1.2, -2.7000000000000006, -3.2, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -8.7, -3.5, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.699999999999998, -17.700000000000003, -21.700000000000006, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -4.699999999999998, -15.699999999999998, -11.699999999999998, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -2.7, -1.7000000000000004, -8.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -17.7, -2.700000000000001, -11.7, -2.7000000000000006, -2.7000000000000006, -12.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -19.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -2.7, -3.2, -4.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -11.7, -1.7000000000000004, -3.7000000000000015, -9.7, -9.7, -11.699999999999998, -8.7, -3.7000000000000015, -2.7000000000000006, -14.699999999999998, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.9000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -9.699999999999998, -13.699999999999998, -2.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.404655790814665, "mean_inference_ms": 1.3003239471437837, "mean_action_processing_ms": 0.09321199584195611, "mean_env_wait_ms": 4.307311616882787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 280000, "timesteps_this_iter": 0, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 11064.347, "sample_throughput": 361.522, "load_time_ms": 0.341, "load_throughput": 11734780.723, "learn_time_ms": 2240.73, "learn_throughput": 1785.133, "update_time_ms": 2.229}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.522707939147949, "policy_loss": -0.014573791064321995, "vf_loss": 7.532816410064697, "vf_explained_var": 0.002868225798010826, "kl": 0.006614250130951405, "entropy": 1.46446692943573, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 280000, "num_agent_steps_sampled": 280000, "num_steps_trained": 280000, "num_agent_steps_trained": 280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14736, "training_iteration": 70, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-17-20", "timestamp": 1642601840, "time_this_iter_s": 10.704314231872559, "time_total_s": 736.6081357002258, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 736.6081357002258, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 49.166666666666664, "ram_util_percent": 62.46}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -16.7, "episode_reward_mean": -4.113942307692308, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -10.699999999999998, -13.2, -14.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7, -3.7000000000000015, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -8.7, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.700000000000001, -16.7, -2.7, -1.7000000000000004, -1.7000000000000004, -13.5, -3.2, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -9.7, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -16.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -4.7, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -6.699999999999999, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -6.699999999999999, -9.1, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -4.7, -2.700000000000001, -1.7000000000000004, -2.7, -12.699999999999998, -1.7000000000000004, -3.7, -2.7, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -12.599999999999998, -2.700000000000001, -9.699999999999998, -2.7000000000000015, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -4.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -9.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7, -10.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -2.7, -7.699999999999999, -2.7, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -14.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -11.699999999999998, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.405390609521412, "mean_inference_ms": 1.3006855292370019, "mean_action_processing_ms": 0.09323733183459877, "mean_env_wait_ms": 4.308733629043018, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 284000, "timesteps_this_iter": 0, "agent_timesteps_total": 284000, "timers": {"sample_time_ms": 11070.053, "sample_throughput": 361.335, "load_time_ms": 0.343, "load_throughput": 11656510.804, "learn_time_ms": 2299.825, "learn_throughput": 1739.263, "update_time_ms": 2.286}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.8252272605896, "policy_loss": -0.014910506084561348, "vf_loss": 7.835436820983887, "vf_explained_var": 0.023997141048312187, "kl": 0.006964362226426601, "entropy": 1.488037347793579, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 284000, "num_agent_steps_sampled": 284000, "num_steps_trained": 284000, "num_agent_steps_trained": 284000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14944, "training_iteration": 71, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-17-31", "timestamp": 1642601851, "time_this_iter_s": 10.986854791641235, "time_total_s": 747.5949904918671, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 747.5949904918671, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 52.66875, "ram_util_percent": 62.475}}
{"episode_reward_max": -1.5, "episode_reward_min": -20.700000000000003, "episode_reward_mean": -3.5339622641509436, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.5, -3.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.7000000000000006, -18.700000000000003, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.5, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -13.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -11.7, -2.7, -2.7000000000000006, -7.699999999999999, -2.7, -10.399999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -6.700000000000001, -3.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.7000000000000006, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -7.699999999999999, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -3.2, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -3.7000000000000006, -4.7, -2.7000000000000006, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -15.699999999999998, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -8.7, -2.7, -3.7000000000000015, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.7, -4.7, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -20.700000000000003, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -2.700000000000001, -1.7000000000000004, -8.699999999999998, -2.7, -2.7000000000000006, -2.2, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -19.700000000000003, -1.7000000000000004, -4.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -18.7, -2.7, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -8.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000015, -7.699999999999999, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4051211830331276, "mean_inference_ms": 1.3000583695371297, "mean_action_processing_ms": 0.09319996946717389, "mean_env_wait_ms": 4.306323212786924, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 288000, "timesteps_this_iter": 0, "agent_timesteps_total": 288000, "timers": {"sample_time_ms": 11004.915, "sample_throughput": 363.474, "load_time_ms": 0.342, "load_throughput": 11680044.556, "learn_time_ms": 2294.516, "learn_throughput": 1743.287, "update_time_ms": 2.278}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.924898147583008, "policy_loss": -0.015021387487649918, "vf_loss": 6.93580961227417, "vf_explained_var": -0.019874820485711098, "kl": 0.006089262198656797, "entropy": 1.461054801940918, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 288000, "num_agent_steps_sampled": 288000, "num_steps_trained": 288000, "num_agent_steps_trained": 288000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15156, "training_iteration": 72, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-17-41", "timestamp": 1642601861, "time_this_iter_s": 10.037622213363647, "time_total_s": 757.6326127052307, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 757.6326127052307, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 46.728571428571435, "ram_util_percent": 62.43571428571427}}
{"episode_reward_max": -1.2, "episode_reward_min": -21.700000000000006, "episode_reward_mean": -3.8278301886792456, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -8.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -2.7000000000000006, -1.7000000000000004, -2.7, -4.700000000000001, -3.700000000000001, -3.7000000000000006, -3.7000000000000006, -2.7, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7, -7.699999999999999, -1.7000000000000004, -8.7, -3.7000000000000006, -2.7, -2.2, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000015, -2.7, -9.7, -3.7000000000000015, -7.699999999999999, -2.2, -3.7000000000000015, -9.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7, -2.7000000000000006, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.6999999999999975, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -18.700000000000003, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -4.7, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -2.7, -1.7000000000000004, -10.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -8.7, -9.699999999999998, -7.699999999999999, -2.7, -1.7000000000000004, -1.2, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -21.700000000000003, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -4.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -7.699999999999999, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.7000000000000015, -15.699999999999998, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -12.699999999999998, -3.0999999999999996, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -21.700000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -9.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -3.7000000000000006, -11.7, -8.9, -11.699999999999998, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -10.7, -2.7000000000000006, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.403020310899323, "mean_inference_ms": 1.2984909594358642, "mean_action_processing_ms": 0.09310013712178346, "mean_env_wait_ms": 4.301017100604498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 292000, "timesteps_this_iter": 0, "agent_timesteps_total": 292000, "timers": {"sample_time_ms": 10893.727, "sample_throughput": 367.184, "load_time_ms": 0.342, "load_throughput": 11697961.233, "learn_time_ms": 2295.121, "learn_throughput": 1742.827, "update_time_ms": 2.256}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.746088027954102, "policy_loss": -0.01415251661092043, "vf_loss": 7.755914211273193, "vf_explained_var": 0.02936907298862934, "kl": 0.006409661378711462, "entropy": 1.4481959342956543, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 292000, "num_agent_steps_sampled": 292000, "num_steps_trained": 292000, "num_agent_steps_trained": 292000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15368, "training_iteration": 73, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-17-51", "timestamp": 1642601871, "time_this_iter_s": 9.684096097946167, "time_total_s": 767.3167088031769, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 767.3167088031769, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 43.94999999999999, "ram_util_percent": 62.321428571428555}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -19.700000000000003, "episode_reward_mean": -4.067788461538463, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.7, -17.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -17.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -7.699999999999999, -9.699999999999998, -2.700000000000001, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -11.699999999999998, -2.700000000000001, -13.699999999999998, -1.7000000000000004, -3.700000000000001, -8.7, -1.7000000000000004, -4.7, -2.7000000000000015, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7000000000000006, -17.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.5, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.2, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7, -12.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -4.700000000000001, -3.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -4.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -16.7, -2.7000000000000006, -10.699999999999998, -17.7, -2.7000000000000006, -1.7000000000000004, -2.7, -18.700000000000003, -1.7000000000000004, -2.7000000000000015, -13.699999999999998, -1.7000000000000004, -16.700000000000003, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -8.700000000000001, -19.700000000000003, -5.6999999999999975, -10.699999999999998, -3.7000000000000015, -11.699999999999998, -3.3, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -9.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -16.7, -2.7, -2.7000000000000006, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -12.699999999999998, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -17.7, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -3.5, -9.7, -9.699999999999998, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7, -11.7, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -7.699999999999999, -2.7, -2.7000000000000015, -1.7000000000000004, -9.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4043831472015, "mean_inference_ms": 1.2997773791923373, "mean_action_processing_ms": 0.0931911996177038, "mean_env_wait_ms": 4.305912566970158, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 296000, "timesteps_this_iter": 0, "agent_timesteps_total": 296000, "timers": {"sample_time_ms": 10857.374, "sample_throughput": 368.413, "load_time_ms": 0.345, "load_throughput": 11589676.706, "learn_time_ms": 2311.238, "learn_throughput": 1730.674, "update_time_ms": 2.243}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 8.796316146850586, "policy_loss": -0.017676040530204773, "vf_loss": 8.808324813842773, "vf_explained_var": -0.03403370454907417, "kl": 0.008397676050662994, "entropy": 1.4782922267913818, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 296000, "num_agent_steps_sampled": 296000, "num_steps_trained": 296000, "num_agent_steps_trained": 296000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15576, "training_iteration": 74, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-02", "timestamp": 1642601882, "time_this_iter_s": 11.228509902954102, "time_total_s": 778.545218706131, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 778.545218706131, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 54.662499999999994, "ram_util_percent": 62.44375}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -23.700000000000003, "episode_reward_mean": -3.9825471698113217, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -8.7, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -7.699999999999999, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -10.7, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -3.7000000000000006, -4.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -11.699999999999998, -11.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -23.700000000000003, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -12.399999999999999, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -10.7, -2.7000000000000015, -12.699999999999998, -2.7, -3.7000000000000015, -13.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -2.7000000000000006, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -12.699999999999998, -8.700000000000001, -2.6000000000000014, -9.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -12.699999999999998, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.7000000000000015, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -19.700000000000003, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -2.700000000000001, -13.699999999999998, -3.7000000000000015, -2.7000000000000015, -8.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.0999999999999996, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.9, -8.700000000000001, -2.7000000000000006, -7.699999999999999, -2.7, -1.7000000000000004, -3.2, -1.7000000000000004, -10.699999999999998, -3.7000000000000006, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -5.700000000000001, -2.6000000000000014, -14.699999999999998, -2.5, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -7.699999999999999, -1.7000000000000004, -9.2, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4068426020000686, "mean_inference_ms": 1.3011828317440162, "mean_action_processing_ms": 0.09328358011343257, "mean_env_wait_ms": 4.310943013332606, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 300000, "timesteps_this_iter": 0, "agent_timesteps_total": 300000, "timers": {"sample_time_ms": 10939.021, "sample_throughput": 365.663, "load_time_ms": 0.347, "load_throughput": 11532317.844, "learn_time_ms": 2338.398, "learn_throughput": 1710.573, "update_time_ms": 2.238}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.512953281402588, "policy_loss": -0.01504027470946312, "vf_loss": 7.523199081420898, "vf_explained_var": 0.05879908800125122, "kl": 0.007102418225258589, "entropy": 1.4898288249969482, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 300000, "num_agent_steps_sampled": 300000, "num_steps_trained": 300000, "num_agent_steps_trained": 300000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15788, "training_iteration": 75, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-14", "timestamp": 1642601894, "time_this_iter_s": 11.2617826461792, "time_total_s": 789.8070013523102, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 789.8070013523102, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 52.04375, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -24.400000000000002, "episode_reward_mean": -4.0094339622641515, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.700000000000001, -2.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.7, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -2.7, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -8.7, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -8.699999999999998, -1.7000000000000004, -1.2, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.7, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -2.6000000000000014, -2.7, -17.7, -2.700000000000001, -2.7000000000000015, -8.7, -2.7000000000000006, -19.700000000000003, -14.699999999999998, -12.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000015, -13.0, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7, -1.7000000000000004, -13.699999999999998, -21.700000000000006, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -4.7, -3.7000000000000006, -1.7000000000000004, -11.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -2.7000000000000006, -1.7000000000000004, -8.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -13.699999999999998, -6.699999999999999, -2.7000000000000006, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -4.7, -18.700000000000003, -2.5, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -2.7000000000000006, -2.7, -3.7000000000000015, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -2.700000000000001, -2.7, -2.7000000000000006, -2.7000000000000015, -2.7, -1.7000000000000004, -4.7, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -11.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -24.400000000000002, -2.7000000000000006, -9.7, -10.599999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4088932734392436, "mean_inference_ms": 1.3021527273893572, "mean_action_processing_ms": 0.09335802629764729, "mean_env_wait_ms": 4.313992931818305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 304000, "timesteps_this_iter": 0, "agent_timesteps_total": 304000, "timers": {"sample_time_ms": 10988.99, "sample_throughput": 364.001, "load_time_ms": 0.347, "load_throughput": 11538662.999, "learn_time_ms": 2323.31, "learn_throughput": 1721.681, "update_time_ms": 2.176}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.11373233795166, "policy_loss": -0.02829955704510212, "vf_loss": 9.136670112609863, "vf_explained_var": -0.03776123747229576, "kl": 0.007942130789160728, "entropy": 1.462986946105957, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 304000, "num_agent_steps_sampled": 304000, "num_steps_trained": 304000, "num_agent_steps_trained": 304000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16000, "training_iteration": 76, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-24", "timestamp": 1642601904, "time_this_iter_s": 10.81853699684143, "time_total_s": 800.6255383491516, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 800.6255383491516, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 50.5125, "ram_util_percent": 62.4375}}
{"episode_reward_max": -1.2, "episode_reward_min": -21.2, "episode_reward_mean": -3.8798076923076934, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000015, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -3.7000000000000015, -2.700000000000001, -2.700000000000001, -10.699999999999998, -3.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -8.7, -2.7000000000000015, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -21.2, -2.7, -1.7000000000000004, -1.7000000000000004, -8.7, -10.7, -2.7000000000000006, -7.699999999999999, -3.7000000000000015, -1.7000000000000004, -12.699999999999998, -8.7, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -4.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -2.7000000000000015, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -2.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -9.699999999999998, -2.7000000000000015, -2.7000000000000015, -2.7, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -3.7000000000000015, -1.7000000000000004, -2.7000000000000015, -14.9, -1.7000000000000004, -1.7000000000000004, -2.7, -19.7, -2.7, -4.7, -4.1, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -5.700000000000001, -2.7000000000000006, -4.7, -1.7000000000000004, -1.2, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -3.100000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -9.699999999999998, -1.7000000000000004, -16.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -13.699999999999998, -3.7000000000000006, -2.7000000000000015, -2.700000000000001, -7.699999999999999, -7.699999999999999, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -20.700000000000003, -1.7000000000000004, -3.7000000000000006, -14.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.7, -10.699999999999998, -6.699999999999999, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.700000000000001, -3.7000000000000006, -3.7000000000000006, -10.699999999999998, -4.7, -2.7000000000000006, -18.7, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000015, -2.9, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -2.7, -1.7000000000000004, -15.9, -1.7000000000000004, -8.7, -7.699999999999999, -1.7000000000000004, -2.7, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4066121204709288, "mean_inference_ms": 1.3006568369921956, "mean_action_processing_ms": 0.09325560767195973, "mean_env_wait_ms": 4.309025125499452, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 308000, "timesteps_this_iter": 0, "agent_timesteps_total": 308000, "timers": {"sample_time_ms": 10719.206, "sample_throughput": 373.162, "load_time_ms": 0.344, "load_throughput": 11638720.777, "learn_time_ms": 2225.088, "learn_throughput": 1797.681, "update_time_ms": 2.144}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.653349876403809, "policy_loss": -0.01921560987830162, "vf_loss": 7.667448997497559, "vf_explained_var": -0.09981951862573624, "kl": 0.007579646538943052, "entropy": 1.443580150604248, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 308000, "num_agent_steps_sampled": 308000, "num_steps_trained": 308000, "num_agent_steps_trained": 308000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16208, "training_iteration": 77, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-34", "timestamp": 1642601914, "time_this_iter_s": 9.690960168838501, "time_total_s": 810.3164985179901, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 810.3164985179901, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 44.41538461538461, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -20.7, "episode_reward_mean": -3.7132075471698114, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -8.7, -7.699999999999999, -3.7000000000000015, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7000000000000015, -1.2, -11.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000015, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -20.7, -10.699999999999998, -3.7000000000000006, -10.699999999999998, -9.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -14.699999999999998, -2.7000000000000006, -3.7000000000000006, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -9.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7, -2.7, -19.700000000000003, -14.699999999999998, -10.699999999999998, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -9.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -6.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7, -7.699999999999999, -3.7, -2.7000000000000006, -8.700000000000001, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000015, -6.2, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -11.7, -4.7, -8.7, -1.7000000000000004, -2.7, -2.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7, -8.7, -11.699999999999998, -1.7000000000000004, -8.7, -2.2, -7.699999999999999, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -8.7, -1.7000000000000004, -3.7000000000000015, -12.699999999999998, -4.7, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.2, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -10.699999999999998, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4034700389580896, "mean_inference_ms": 1.2986801219010051, "mean_action_processing_ms": 0.09311857493225943, "mean_env_wait_ms": 4.302656669188529, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 312000, "timesteps_this_iter": 0, "agent_timesteps_total": 312000, "timers": {"sample_time_ms": 10427.37, "sample_throughput": 383.606, "load_time_ms": 0.343, "load_throughput": 11673543.0, "learn_time_ms": 2221.528, "learn_throughput": 1800.562, "update_time_ms": 2.145}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.525640487670898, "policy_loss": -0.013060114346444607, "vf_loss": 6.534548282623291, "vf_explained_var": 0.04068227857351303, "kl": 0.006152034737169743, "entropy": 1.4248881340026855, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 312000, "num_agent_steps_sampled": 312000, "num_steps_trained": 312000, "num_agent_steps_trained": 312000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16420, "training_iteration": 78, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-44", "timestamp": 1642601924, "time_this_iter_s": 9.581313133239746, "time_total_s": 819.8978116512299, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 819.8978116512299, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 42.09285714285714, "ram_util_percent": 62.48571428571428}}
{"episode_reward_max": -1.2, "episode_reward_min": -22.700000000000003, "episode_reward_mean": -3.6173076923076932, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -3.2, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -16.700000000000003, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -4.7, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -3.9, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -11.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000015, -11.699999999999998, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -2.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -2.7, -12.699999999999998, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.2, -10.699999999999998, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -2.7, -2.700000000000001, -2.7, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -15.699999999999998, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -11.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -3.5, -2.7, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -18.700000000000003, -1.7000000000000004, -4.699999999999998, -12.699999999999998, -8.2, -3.7000000000000015, -9.699999999999998, -4.699999999999998, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -2.7, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -8.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -22.700000000000003, -12.699999999999998, -2.7000000000000015, -2.7000000000000015, -4.7, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -10.7, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -3.7000000000000006, -2.7000000000000015, -2.7000000000000015, -3.700000000000001, -3.7, -1.7000000000000004, -2.7, -1.7000000000000004, -4.7, -2.7, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -3.7, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -9.2, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.2, -5.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -8.7, -1.7000000000000004, -1.2, -1.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -10.699999999999998], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4006638138691465, "mean_inference_ms": 1.2967195312104143, "mean_action_processing_ms": 0.09297843377856753, "mean_env_wait_ms": 4.295846460481256, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 316000, "timesteps_this_iter": 0, "agent_timesteps_total": 316000, "timers": {"sample_time_ms": 10401.34, "sample_throughput": 384.566, "load_time_ms": 0.343, "load_throughput": 11673543.0, "learn_time_ms": 2237.226, "learn_throughput": 1787.928, "update_time_ms": 2.163}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.427905559539795, "policy_loss": -0.027265669777989388, "vf_loss": 6.450479030609131, "vf_explained_var": 0.040440309792757034, "kl": 0.006952181458473206, "entropy": 1.3874772787094116, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 316000, "num_agent_steps_sampled": 316000, "num_steps_trained": 316000, "num_agent_steps_trained": 316000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16628, "training_iteration": 79, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-18-54", "timestamp": 1642601934, "time_this_iter_s": 9.92096209526062, "time_total_s": 829.8187737464905, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 829.8187737464905, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 44.97857142857142, "ram_util_percent": 62.51428571428572}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.7650943396226415, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -8.7, -2.7000000000000006, -1.7000000000000004, -4.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -2.7, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -11.2, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7, -2.7, -13.6, -13.499999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -10.699999999999998, -2.7, -2.7, -2.700000000000001, -9.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -2.7, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -13.699999999999998, -8.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7, -8.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -3.7000000000000006, -3.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -2.7, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7000000000000015, -2.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -2.700000000000001, -2.7, -1.7000000000000004, -3.7000000000000006, -8.7, -12.5, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -8.7, -2.700000000000001, -10.699999999999998, -2.3, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.6000000000000014, -1.7000000000000004, -2.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -17.700000000000003, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -8.7, -1.7000000000000004, -1.7000000000000004, -2.5, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -2.7, -2.7, -4.7, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -4.7, -1.7000000000000004, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -6.700000000000001, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -7.699999999999999, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -16.7, -14.699999999999998, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.399543204415857, "mean_inference_ms": 1.295942802494525, "mean_action_processing_ms": 0.09291851452440876, "mean_env_wait_ms": 4.293238767538858, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 320000, "timesteps_this_iter": 0, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 10356.263, "sample_throughput": 386.24, "load_time_ms": 0.364, "load_throughput": 10993523.36, "learn_time_ms": 2341.362, "learn_throughput": 1708.408, "update_time_ms": 2.153}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.340873718261719, "policy_loss": -0.02096165530383587, "vf_loss": 7.355610370635986, "vf_explained_var": 0.03951093181967735, "kl": 0.00922193843871355, "entropy": 1.4022289514541626, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 320000, "num_agent_steps_sampled": 320000, "num_steps_trained": 320000, "num_agent_steps_trained": 320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16840, "training_iteration": 80, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-05", "timestamp": 1642601945, "time_this_iter_s": 11.138644933700562, "time_total_s": 840.957418680191, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 840.957418680191, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 52.16875, "ram_util_percent": 62.537499999999994}}
{"episode_reward_max": -1.2, "episode_reward_min": -24.699999999999996, "episode_reward_mean": -3.8764150943396234, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -2.7, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -11.699999999999998, -7.699999999999999, -1.7000000000000004, -11.699999999999998, -3.7000000000000015, -1.2, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -8.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -17.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -11.0, -2.7000000000000006, -2.7, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -1.2, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -3.2, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -7.699999999999999, -18.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -12.699999999999998, -4.699999999999999, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -21.299999999999997, -3.700000000000001, -4.699999999999999, -1.7000000000000004, -19.700000000000003, -1.7000000000000004, -8.699999999999998, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7000000000000015, -2.7000000000000006, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -9.699999999999998, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -21.700000000000006, -2.7, -1.7000000000000004, -3.7000000000000015, -2.7, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -8.7, -3.7000000000000015, -2.700000000000001, -24.699999999999996, -14.699999999999998, -1.7000000000000004, -3.2, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7000000000000015, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -17.700000000000003, -3.7000000000000015, -11.699999999999998, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7, -2.7000000000000015, -3.700000000000001, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -8.7, -3.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -10.699999999999998, -2.700000000000001, -2.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4037923202522182, "mean_inference_ms": 1.298463555321623, "mean_action_processing_ms": 0.09308847471118904, "mean_env_wait_ms": 4.30154030641593, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 324000, "timesteps_this_iter": 0, "agent_timesteps_total": 324000, "timers": {"sample_time_ms": 10569.798, "sample_throughput": 378.437, "load_time_ms": 0.37, "load_throughput": 10823312.044, "learn_time_ms": 2368.679, "learn_throughput": 1688.705, "update_time_ms": 2.115}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.229422569274902, "policy_loss": -0.01943429745733738, "vf_loss": 9.243889808654785, "vf_explained_var": 0.027372339740395546, "kl": 0.007360170129686594, "entropy": 1.389944314956665, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 324000, "num_agent_steps_sampled": 324000, "num_steps_trained": 324000, "num_agent_steps_trained": 324000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17052, "training_iteration": 81, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-17", "timestamp": 1642601957, "time_this_iter_s": 12.348800897598267, "time_total_s": 853.3062195777893, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 853.3062195777893, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 55.91111111111112, "ram_util_percent": 62.57222222222222}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.071153846153846, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -8.7, -2.7000000000000006, -14.699999999999998, -11.699999999999998, -8.7, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -4.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -9.699999999999998, -7.699999999999999, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7, -3.7000000000000006, -4.700000000000001, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -5.699999999999999, -3.7000000000000006, -1.7000000000000004, -14.699999999999998, -5.699999999999999, -7.699999999999999, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -3.7000000000000006, -3.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -12.2, -2.7000000000000006, -9.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7, -1.7000000000000004, -3.7000000000000015, -5.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.2, -1.7000000000000004, -2.7, -2.7, -12.699999999999998, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -3.7000000000000015, -3.700000000000001, -2.7000000000000015, -4.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7, -1.7000000000000004, -2.7, -2.7000000000000006, -3.7000000000000006, -2.7, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7000000000000006, -2.9, -3.7000000000000015, -2.7, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -23.700000000000006, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -2.7, -4.7, -2.2, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -3.700000000000001, -2.7, -9.7, -2.7, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7, -3.7000000000000015, -1.7000000000000004, -10.699999999999998, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -2.700000000000001, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -17.7, -1.2, -2.700000000000001, -12.699999999999998, -2.700000000000001, -9.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4052035389736677, "mean_inference_ms": 1.2995507718266497, "mean_action_processing_ms": 0.09316561930083736, "mean_env_wait_ms": 4.305009572189411, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 328000, "timesteps_this_iter": 0, "agent_timesteps_total": 328000, "timers": {"sample_time_ms": 10681.027, "sample_throughput": 374.496, "load_time_ms": 0.371, "load_throughput": 10779501.414, "learn_time_ms": 2409.845, "learn_throughput": 1659.858, "update_time_ms": 2.133}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.372905254364014, "policy_loss": -0.033706508576869965, "vf_loss": 7.402608871459961, "vf_explained_var": 0.0380433015525341, "kl": 0.005929647479206324, "entropy": 1.3920890092849731, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 328000, "num_agent_steps_sampled": 328000, "num_steps_trained": 328000, "num_agent_steps_trained": 328000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17260, "training_iteration": 82, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-29", "timestamp": 1642601969, "time_this_iter_s": 11.291256189346313, "time_total_s": 864.5974757671356, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 864.5974757671356, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 50.54375, "ram_util_percent": 62.456250000000004}}
{"episode_reward_max": -1.2, "episode_reward_min": -17.7, "episode_reward_mean": -3.7033018867924534, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -4.699999999999999, -10.699999999999998, -2.7000000000000015, -4.699999999999999, -3.7000000000000006, -3.7000000000000006, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -16.7, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.2, -8.7, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -2.700000000000001, -4.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.700000000000001, -16.299999999999997, -4.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -14.699999999999998, -2.7, -2.7, -4.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -2.7, -9.699999999999998, -2.700000000000001, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.9000000000000004, -7.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -4.699999999999998, -7.699999999999999, -2.7, -2.7, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -13.699999999999998, -7.699999999999999, -9.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -17.7, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -2.7, -2.7, -1.2, -1.2, -2.7000000000000006, -3.7000000000000006, -14.699999999999998, -1.7000000000000004, -5.699999999999999, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -2.7, -2.7, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -16.7, -16.7, -1.7000000000000004, -2.7000000000000006, -15.600000000000001, -2.7, -4.700000000000001, -2.7, -3.6000000000000014, -1.7000000000000004, -1.7000000000000004, -1.2, -3.7000000000000006, -9.699999999999998, -4.700000000000001, -8.7, -9.6, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -2.9000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -7.6999999999999975, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.404884086847463, "mean_inference_ms": 1.2990019963182042, "mean_action_processing_ms": 0.09311026325355208, "mean_env_wait_ms": 4.302915700267501, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332000, "timesteps_this_iter": 0, "agent_timesteps_total": 332000, "timers": {"sample_time_ms": 10777.943, "sample_throughput": 371.128, "load_time_ms": 0.37, "load_throughput": 10810758.425, "learn_time_ms": 2394.903, "learn_throughput": 1670.214, "update_time_ms": 2.128}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.62094259262085, "policy_loss": -0.014512607827782631, "vf_loss": 6.6311492919921875, "vf_explained_var": 0.03989975154399872, "kl": 0.006379267666488886, "entropy": 1.3543897867202759, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 332000, "num_agent_steps_sampled": 332000, "num_steps_trained": 332000, "num_agent_steps_trained": 332000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17472, "training_iteration": 83, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-39", "timestamp": 1642601979, "time_this_iter_s": 10.09168004989624, "time_total_s": 874.6891558170319, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 874.6891558170319, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 45.199999999999996, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -22.700000000000003, "episode_reward_mean": -3.7292452830188685, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -4.7, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -8.2, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -17.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -3.7000000000000006, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -20.7, -13.5, -19.299999999999997, -2.7, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -8.7, -2.2, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -3.700000000000001, -6.700000000000001, -2.700000000000001, -2.7000000000000015, -2.700000000000001, -2.5, -1.7000000000000004, -2.7, -2.7000000000000015, -14.699999999999998, -1.7000000000000004, -2.7, -11.7, -2.7000000000000006, -1.7000000000000004, -4.7, -3.2, -1.7000000000000004, -3.7000000000000006, -8.699999999999998, -15.699999999999998, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000015, -4.7, -2.7, -10.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.2, -2.7, -1.7000000000000004, -2.7, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7, -4.7, -1.7000000000000004, -1.7000000000000004, -22.700000000000003, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -2.700000000000001, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -3.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -14.699999999999998, -3.7000000000000015, -16.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -2.7, -2.7, -2.7, -18.7, -2.7000000000000006, -1.7000000000000004, -2.7, -2.700000000000001, -1.7000000000000004, -8.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.2, -1.7000000000000004, -2.7000000000000006, -3.2, -2.7, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -2.7, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -12.699999999999998, -13.699999999999998, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.402663658057532, "mean_inference_ms": 1.2976062303355695, "mean_action_processing_ms": 0.09301320321318567, "mean_env_wait_ms": 4.2984452035145795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 336000, "timesteps_this_iter": 0, "agent_timesteps_total": 336000, "timers": {"sample_time_ms": 10622.402, "sample_throughput": 376.563, "load_time_ms": 0.367, "load_throughput": 10896418.783, "learn_time_ms": 2368.57, "learn_throughput": 1688.782, "update_time_ms": 2.116}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.2133259773254395, "policy_loss": -0.022006873041391373, "vf_loss": 7.230560779571533, "vf_explained_var": -0.010400952771306038, "kl": 0.007069908082485199, "entropy": 1.3869925737380981, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 336000, "num_agent_steps_sampled": 336000, "num_steps_trained": 336000, "num_agent_steps_trained": 336000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17684, "training_iteration": 84, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-48", "timestamp": 1642601988, "time_this_iter_s": 9.559940814971924, "time_total_s": 884.2490966320038, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 884.2490966320038, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 43.078571428571436, "ram_util_percent": 62.42857142857142}}
{"episode_reward_max": -1.2, "episode_reward_min": -19.700000000000003, "episode_reward_mean": -4.1312500000000005, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000015, -5.699999999999999, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -3.700000000000001, -2.7, -4.7, -12.699999999999998, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -16.7, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.9, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7, -2.7000000000000015, -2.700000000000001, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -1.2, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -2.700000000000001, -2.7000000000000006, -3.7000000000000015, -17.700000000000003, -3.7000000000000015, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -10.7, -2.700000000000001, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -10.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -4.7, -2.7000000000000006, -11.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -3.7000000000000006, -9.699999999999998, -3.7000000000000006, -2.7, -1.7000000000000004, -2.7000000000000006, -4.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -5.699999999999999, -2.7, -5.700000000000001, -2.700000000000001, -13.699999999999998, -2.7000000000000015, -13.699999999999998, -2.7000000000000006, -7.699999999999999, -16.700000000000003, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -3.2, -7.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -3.700000000000001, -8.7, -5.300000000000001, -3.7000000000000015, -3.700000000000001, -2.7000000000000015, -1.7000000000000004, -5.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -10.699999999999998, -2.7000000000000006, -5.699999999999999, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7000000000000015, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -2.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -3.7000000000000015, -18.7, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -5.699999999999999, -2.7000000000000006, -10.699999999999998, -12.699999999999998, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -8.7, -3.5, -12.699999999999998, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.2, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -8.7, -15.7, -2.700000000000001, -2.7000000000000006, -2.2, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -11.599999999999998, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -2.7, -3.7, -15.699999999999998, -2.700000000000001, -10.699999999999998, -1.7000000000000004, -19.700000000000003, -2.700000000000001, -3.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.900000000000001, -1.7000000000000004, -3.7, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -8.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4010197966044453, "mean_inference_ms": 1.2964570676998113, "mean_action_processing_ms": 0.09293275850452891, "mean_env_wait_ms": 4.294515003172213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 340000, "timesteps_this_iter": 0, "agent_timesteps_total": 340000, "timers": {"sample_time_ms": 10489.495, "sample_throughput": 381.334, "load_time_ms": 0.366, "load_throughput": 10917691.156, "learn_time_ms": 2331.067, "learn_throughput": 1715.953, "update_time_ms": 2.108}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.1460723876953125, "policy_loss": -0.026938870549201965, "vf_loss": 7.167234897613525, "vf_explained_var": 0.0640057772397995, "kl": 0.008558310568332672, "entropy": 1.383482813835144, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 340000, "num_agent_steps_sampled": 340000, "num_steps_trained": 340000, "num_agent_steps_trained": 340000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17892, "training_iteration": 85, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-19-58", "timestamp": 1642601998, "time_this_iter_s": 9.820883989334106, "time_total_s": 894.0699806213379, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 894.0699806213379, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 44.292857142857144, "ram_util_percent": 62.43571428571429}}
{"episode_reward_max": -1.2, "episode_reward_min": -22.0, "episode_reward_mean": -3.8542452830188685, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.700000000000001, -1.7000000000000004, -14.699999999999998, -3.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -6.6999999999999975, -1.7000000000000004, -1.7000000000000004, -3.2, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -2.7, -3.700000000000001, -15.699999999999998, -3.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -2.7, -4.699999999999999, -1.7000000000000004, -2.7, -3.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -4.500000000000001, -2.7, -3.700000000000001, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -5.6, -1.7000000000000004, -2.7, -2.7000000000000006, -2.2, -8.7, -11.7, -2.700000000000001, -7.699999999999999, -7.699999999999999, -1.7000000000000004, -18.700000000000003, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -8.7, -11.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.2, -2.700000000000001, -2.7, -9.7, -7.699999999999999, -1.2, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7, -12.7, -2.7000000000000006, -3.7000000000000006, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -22.0, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.700000000000001, -2.7, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -8.7, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -2.2, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -8.699999999999998, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -8.699999999999998, -3.7000000000000015, -1.7000000000000004, -3.7000000000000006, -4.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -2.7, -2.7000000000000006, -2.9, -1.7000000000000004, -7.699999999999999, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -2.7000000000000006, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -16.5, -2.7, -1.7000000000000004, -8.7, -1.7000000000000004, -2.700000000000001, -13.2, -19.700000000000003, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -11.699999999999998, -3.9, -3.7000000000000006, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -17.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -14.2, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3974175543340475, "mean_inference_ms": 1.294387598910765, "mean_action_processing_ms": 0.09278882053142061, "mean_env_wait_ms": 4.287872418025386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 344000, "timesteps_this_iter": 0, "agent_timesteps_total": 344000, "timers": {"sample_time_ms": 10301.252, "sample_throughput": 388.302, "load_time_ms": 0.373, "load_throughput": 10729864.415, "learn_time_ms": 2336.229, "learn_throughput": 1712.161, "update_time_ms": 2.135}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.199005603790283, "policy_loss": -0.015425528399646282, "vf_loss": 7.210139274597168, "vf_explained_var": 0.08860224485397339, "kl": 0.006359205115586519, "entropy": 1.385962963104248, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 344000, "num_agent_steps_sampled": 344000, "num_steps_trained": 344000, "num_agent_steps_trained": 344000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18104, "training_iteration": 86, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-07", "timestamp": 1642602007, "time_this_iter_s": 9.366529941558838, "time_total_s": 903.4365105628967, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 903.4365105628967, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 41.96923076923077, "ram_util_percent": 62.44615384615384}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.88798076923077, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.499999999999998, -2.7, -7.6999999999999975, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -15.699999999999998, -7.699999999999999, -1.7000000000000004, -19.4, -1.7000000000000004, -2.700000000000001, -19.700000000000003, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.9000000000000004, -3.7000000000000015, -8.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -11.699999999999998, -1.2, -2.7000000000000006, -1.7000000000000004, -2.7, -4.7, -2.7, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -4.699999999999999, -3.7000000000000006, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -6.700000000000001, -5.699999999999999, -3.7000000000000015, -3.7000000000000006, -1.7000000000000004, -22.700000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -5.700000000000001, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -11.699999999999998, -2.7, -2.7, -1.2, -4.699999999999999, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -4.700000000000001, -2.7000000000000006, -2.7000000000000015, -3.7000000000000006, -2.700000000000001, -14.699999999999998, -3.7000000000000015, -1.7000000000000004, -3.0999999999999996, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -2.7, -8.7, -16.7, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -2.7, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -7.2, -2.7000000000000006, -1.7000000000000004, -23.700000000000006, -1.7000000000000004, -2.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -2.7000000000000006, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.2, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.2, -4.699999999999999, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -7.699999999999999, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -3.7000000000000006, -2.700000000000001, -15.699999999999998, -2.7, -3.700000000000001, -2.7000000000000006, -4.700000000000001, -9.1, -2.7, -9.699999999999998, -2.7000000000000006, -3.7000000000000015, -4.300000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -18.700000000000003, -13.699999999999998, -2.7000000000000015, -3.7000000000000006, -1.7000000000000004, -2.2, -2.7, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.393156236273737, "mean_inference_ms": 1.2919968934504786, "mean_action_processing_ms": 0.09262957993151778, "mean_env_wait_ms": 4.279903657225277, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 348000, "timesteps_this_iter": 0, "agent_timesteps_total": 348000, "timers": {"sample_time_ms": 10251.033, "sample_throughput": 390.205, "load_time_ms": 0.373, "load_throughput": 10730550.688, "learn_time_ms": 2369.618, "learn_throughput": 1688.036, "update_time_ms": 2.15}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.803995609283447, "policy_loss": -0.01771475560963154, "vf_loss": 7.817586421966553, "vf_explained_var": 0.026690267026424408, "kl": 0.006109459791332483, "entropy": 1.3956267833709717, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 348000, "num_agent_steps_sampled": 348000, "num_steps_trained": 348000, "num_agent_steps_trained": 348000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18312, "training_iteration": 87, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-17", "timestamp": 1642602017, "time_this_iter_s": 9.470674991607666, "time_total_s": 912.9071855545044, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 912.9071855545044, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 41.13571428571429, "ram_util_percent": 62.43571428571429}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.79433962264151, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -3.9, -17.7, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -10.699999999999998, -2.7, -3.700000000000001, -4.700000000000001, -14.699999999999998, -2.700000000000001, -4.700000000000001, -2.7000000000000015, -1.7000000000000004, -8.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -8.7, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -3.3, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -20.700000000000003, -5.700000000000001, -3.700000000000001, -2.700000000000001, -3.7000000000000006, -9.699999999999998, -3.7000000000000015, -2.7, -5.700000000000001, -2.7, -2.7000000000000006, -4.699999999999999, -8.7, -9.699999999999998, -3.7000000000000006, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -21.700000000000003, -1.7000000000000004, -2.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -5.1000000000000005, -2.7000000000000006, -2.7, -2.7, -2.7000000000000006, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -4.7, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -2.7, -2.7, -2.7, -3.7000000000000006, -2.7000000000000015, -1.7000000000000004, -3.7000000000000006, -3.6000000000000014, -9.7, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -11.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -3.7000000000000006, -1.7000000000000004, -14.699999999999998, -2.7, -2.7, -3.700000000000001, -2.7, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -2.7000000000000015, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -4.7, -3.700000000000001, -1.7000000000000004, -8.7, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -5.699999999999999, -2.7, -4.699999999999999, -10.1, -2.7000000000000006, -3.700000000000001, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -2.700000000000001, -13.699999999999998, -3.7000000000000015, -3.7000000000000015, -1.7000000000000004, -7.699999999999999, -3.7000000000000006, -8.7, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000015, -23.700000000000006, -3.7000000000000006, -4.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3896452570539704, "mean_inference_ms": 1.2895195995211206, "mean_action_processing_ms": 0.09245977332809538, "mean_env_wait_ms": 4.271737889221267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 352000, "timesteps_this_iter": 0, "agent_timesteps_total": 352000, "timers": {"sample_time_ms": 10250.611, "sample_throughput": 390.221, "load_time_ms": 0.379, "load_throughput": 10549054.326, "learn_time_ms": 2377.629, "learn_throughput": 1682.348, "update_time_ms": 2.163}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.525119781494141, "policy_loss": -0.018679315224289894, "vf_loss": 6.54025936126709, "vf_explained_var": 0.04080439731478691, "kl": 0.005243333987891674, "entropy": 1.3886561393737793, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 352000, "num_agent_steps_sampled": 352000, "num_steps_trained": 352000, "num_agent_steps_trained": 352000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18524, "training_iteration": 88, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-26", "timestamp": 1642602026, "time_this_iter_s": 9.321946859359741, "time_total_s": 922.2291324138641, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 922.2291324138641, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 41.01538461538462, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -15.699999999999998, "episode_reward_mean": -3.4721698113207555, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000015, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -3.3, -1.7000000000000004, -11.699999999999998, -2.7000000000000015, -2.7, -10.7, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.2, -14.699999999999998, -3.7000000000000006, -1.7000000000000004, -14.699999999999998, -1.2, -3.700000000000001, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.2, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -4.7, -12.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -3.7000000000000006, -4.700000000000001, -1.7000000000000004, -4.5, -1.7000000000000004, -15.699999999999998, -2.7, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -2.7, -3.7000000000000006, -10.699999999999998, -4.6999999999999975, -4.700000000000001, -3.700000000000001, -3.7000000000000006, -3.700000000000001, -2.700000000000001, -2.700000000000001, -2.7, -1.7000000000000004, -2.7000000000000006, -10.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -3.7000000000000006, -14.699999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.2, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -13.499999999999998, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -3.7000000000000015, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -12.699999999999998, -2.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -13.7, -2.7, -1.7000000000000004, -2.700000000000001, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000015, -8.7, -3.700000000000001, -3.700000000000001, -13.699999999999998, -2.700000000000001, -2.700000000000001, -2.700000000000001, -3.7, -4.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.7000000000000015, -5.699999999999999, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -5.699999999999999, -1.7000000000000004, -2.7000000000000006, -13.2, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.386952511770087, "mean_inference_ms": 1.2875342474625506, "mean_action_processing_ms": 0.09232520724953945, "mean_env_wait_ms": 4.265063359570478, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 356000, "timesteps_this_iter": 0, "agent_timesteps_total": 356000, "timers": {"sample_time_ms": 10245.674, "sample_throughput": 390.409, "load_time_ms": 0.379, "load_throughput": 10555027.367, "learn_time_ms": 2340.122, "learn_throughput": 1709.313, "update_time_ms": 2.203}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 4.289369583129883, "policy_loss": -0.01759941317141056, "vf_loss": 4.302895545959473, "vf_explained_var": 0.08821480721235275, "kl": 0.006035025231540203, "entropy": 1.3965193033218384, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 356000, "num_agent_steps_sampled": 356000, "num_steps_trained": 356000, "num_agent_steps_trained": 356000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18736, "training_iteration": 89, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-36", "timestamp": 1642602036, "time_this_iter_s": 9.417783975601196, "time_total_s": 931.6469163894653, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 931.6469163894653, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 42.40714285714286, "ram_util_percent": 62.464285714285715}}
{"episode_reward_max": -1.2, "episode_reward_min": -19.700000000000003, "episode_reward_mean": -3.377884615384616, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -2.7, -4.699999999999998, -11.699999999999998, -2.7000000000000006, -2.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.2, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -9.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -4.1, -2.7, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7000000000000015, -1.5, -3.7000000000000015, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -12.2, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7, -2.700000000000001, -2.7, -3.7000000000000015, -1.7000000000000004, -3.2, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7000000000000006, -2.7000000000000006, -13.2, -2.7, -1.7000000000000004, -2.2, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -19.700000000000003, -1.7000000000000004, -1.2, -3.700000000000001, -11.699999999999998, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.2, -1.7000000000000004, -1.7000000000000004, -4.2, -8.7, -13.5, -11.699999999999998, -1.7000000000000004, -2.7, -3.7000000000000006, -2.7000000000000006, -9.7, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -2.7000000000000006, -3.7000000000000006, -2.7, -2.7000000000000006, -2.7000000000000006, -2.7, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -13.699999999999998, -4.7, -2.7000000000000015, -3.7000000000000006, -2.2, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -11.699999999999998, -4.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3847935317647475, "mean_inference_ms": 1.2865086628107747, "mean_action_processing_ms": 0.09225855811320588, "mean_env_wait_ms": 4.26172273368118, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 360000, "timesteps_this_iter": 0, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 10196.726, "sample_throughput": 392.283, "load_time_ms": 0.353, "load_throughput": 11316840.472, "learn_time_ms": 2218.067, "learn_throughput": 1803.372, "update_time_ms": 2.172}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 4.354290962219238, "policy_loss": -0.026397664099931717, "vf_loss": 4.374768257141113, "vf_explained_var": 0.10836578905582428, "kl": 0.008770599961280823, "entropy": 1.3802248239517212, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 360000, "num_agent_steps_sampled": 360000, "num_steps_trained": 360000, "num_agent_steps_trained": 360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18944, "training_iteration": 90, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-46", "timestamp": 1642602046, "time_this_iter_s": 9.790417909622192, "time_total_s": 941.4373342990875, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 941.4373342990875, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 43.32142857142858, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -17.299999999999997, "episode_reward_mean": -3.387735849056604, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7, -2.2, -10.9, -4.7, -2.7, -2.700000000000001, -2.700000000000001, -2.7000000000000006, -1.2, -2.2, -3.7, -1.7000000000000004, -3.700000000000001, -8.7, -1.7000000000000004, -16.7, -4.700000000000001, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -10.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -9.9, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.7, -2.2, -2.7000000000000006, -4.7, -1.7000000000000004, -9.699999999999998, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -2.700000000000001, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -17.299999999999997, -1.7000000000000004, -2.7, -3.9, -1.7000000000000004, -1.7000000000000004, -6.699999999999999, -1.7000000000000004, -2.2, -2.700000000000001, -2.7000000000000006, -3.7000000000000015, -2.700000000000001, -4.7, -2.7, -2.7000000000000006, -2.700000000000001, -2.7, -2.2, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -1.7000000000000004, -2.2, -3.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.2, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -2.700000000000001, -3.7000000000000006, -2.700000000000001, -2.7000000000000015, -1.7000000000000004, -5.699999999999999, -2.2, -2.7000000000000015, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -1.2, -1.7000000000000004, -4.7, -2.7, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -10.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.2, -3.700000000000001, -1.7000000000000004, -4.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.2, -3.700000000000001, -8.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.2, -2.7, -12.599999999999998, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -3.7000000000000006, -3.700000000000001, -2.7000000000000006, -8.7, -1.7000000000000004, -2.7000000000000006, -4.7, -2.7000000000000015, -2.7, -1.7000000000000004, -8.7, -1.7000000000000004, -4.700000000000001, -3.2, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -3.7000000000000015, -2.7, -3.700000000000001, -11.699999999999998, -2.700000000000001, -2.9, -3.700000000000001, -4.6, -4.700000000000001, -1.7000000000000004, -3.700000000000001, -2.7, -1.7000000000000004, -3.7000000000000006, -12.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.3, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3830297709787267, "mean_inference_ms": 1.2851371954926303, "mean_action_processing_ms": 0.09216253100470541, "mean_env_wait_ms": 4.257021953131588, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 364000, "timesteps_this_iter": 0, "agent_timesteps_total": 364000, "timers": {"sample_time_ms": 9871.061, "sample_throughput": 405.225, "load_time_ms": 0.344, "load_throughput": 11626622.315, "learn_time_ms": 2135.26, "learn_throughput": 1873.308, "update_time_ms": 2.169}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 4.468010425567627, "policy_loss": -0.01962120831012726, "vf_loss": 4.482599258422852, "vf_explained_var": 0.11528487503528595, "kl": 0.007455037906765938, "entropy": 1.3824349641799927, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 364000, "num_agent_steps_sampled": 364000, "num_steps_trained": 364000, "num_agent_steps_trained": 364000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19156, "training_iteration": 91, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-20-55", "timestamp": 1642602055, "time_this_iter_s": 9.49160099029541, "time_total_s": 950.9289352893829, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 950.9289352893829, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 42.01538461538462, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.9825471698113217, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.699999999999998, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -3.7, -4.7, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -14.7, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -3.700000000000001, -2.700000000000001, -11.699999999999998, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -16.6, -1.7000000000000004, -2.7000000000000006, -5.699999999999999, -2.700000000000001, -2.7, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -2.7000000000000006, -5.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -9.699999999999998, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -23.700000000000006, -1.7000000000000004, -4.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.2, -3.7000000000000006, -2.2, -12.0, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -10.599999999999998, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -3.7000000000000006, -3.2, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.2, -2.700000000000001, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -2.2, -8.699999999999998, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -5.700000000000001, -2.2, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.3, -3.7000000000000006, -12.6, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -2.7, -2.7000000000000006, -10.7, -2.7000000000000015, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -4.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.7, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.2, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -21.4, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -2.5, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -14.699999999999998, -2.700000000000001, -21.700000000000003, -2.700000000000001, -1.2, -3.7000000000000015, -9.699999999999998, -1.2, -2.7, -3.7000000000000015, -3.700000000000001, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -2.7000000000000006, -1.7000000000000004, -17.700000000000003, -2.7, -2.7, -1.2, -5.699999999999999, -3.7000000000000006, -3.7000000000000015, -3.2, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -14.699999999999998, -3.7000000000000006, -1.7000000000000004, -2.7, -3.700000000000001, -3.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -12.7, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -23.5, -9.7, -3.700000000000001, -2.6000000000000014, -2.7, -1.7000000000000004, -1.7000000000000004, -10.7, -1.7000000000000004, -3.3, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -8.7, -1.7000000000000004, -9.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3822278826445675, "mean_inference_ms": 1.2844971299911314, "mean_action_processing_ms": 0.09212212228726822, "mean_env_wait_ms": 4.254925200602831, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 368000, "timesteps_this_iter": 0, "agent_timesteps_total": 368000, "timers": {"sample_time_ms": 9696.331, "sample_throughput": 412.527, "load_time_ms": 0.341, "load_throughput": 11742994.331, "learn_time_ms": 2081.387, "learn_throughput": 1921.795, "update_time_ms": 2.113}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.431911945343018, "policy_loss": -0.02420658804476261, "vf_loss": 7.451258182525635, "vf_explained_var": 0.0754183977842331, "kl": 0.007200898602604866, "entropy": 1.3876357078552246, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 368000, "num_agent_steps_sampled": 368000, "num_steps_trained": 368000, "num_agent_steps_trained": 368000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19368, "training_iteration": 92, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-05", "timestamp": 1642602065, "time_this_iter_s": 9.835119009017944, "time_total_s": 960.7640542984009, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 960.7640542984009, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 44.22857142857142, "ram_util_percent": 62.5}}
{"episode_reward_max": -1.2, "episode_reward_min": -15.699999999999998, "episode_reward_mean": -3.7605769230769237, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.700000000000001, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -2.7, -2.7000000000000006, -2.7, -2.700000000000001, -4.700000000000001, -3.7000000000000006, -3.7000000000000015, -2.7, -3.3, -1.7000000000000004, -9.6, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -15.699999999999998, -4.699999999999999, -2.7, -1.7000000000000004, -2.7000000000000006, -7.699999999999999, -11.699999999999998, -3.700000000000001, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -9.699999999999998, -3.7000000000000006, -3.700000000000001, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -4.699999999999998, -1.7000000000000004, -2.7, -7.699999999999999, -2.7, -1.7000000000000004, -4.699999999999999, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -11.699999999999998, -3.700000000000001, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -3.7000000000000006, -14.699999999999998, -4.700000000000001, -13.699999999999998, -1.7000000000000004, -3.700000000000001, -8.7, -3.7000000000000015, -2.7000000000000006, -10.699999999999998, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -3.5, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -11.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -10.699999999999998, -5.699999999999999, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -4.7, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.2, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -6.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.699999999999999, -2.7000000000000006, -1.7000000000000004, -13.699999999999998, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -10.699999999999998, -3.7000000000000006, -1.2, -1.7000000000000004, -2.2, -2.700000000000001, -1.7000000000000004, -5.699999999999999, -2.7000000000000006, -2.7, -1.7000000000000004, -4.300000000000001, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -8.699999999999998, -1.7000000000000004, -13.699999999999998, -1.7000000000000004, -3.700000000000001, -8.7, -14.699999999999998, -3.7000000000000015, -8.2, -2.700000000000001, -4.700000000000001, -2.7000000000000015, -2.7, -1.7000000000000004, -1.7000000000000004, -12.5, -3.7000000000000006, -1.2, -12.299999999999999, -2.7000000000000006, -4.500000000000001, -3.700000000000001, -2.7000000000000006, -2.7, -2.700000000000001, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -5.700000000000001, -2.7000000000000015], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3815149932834094, "mean_inference_ms": 1.2841124093460397, "mean_action_processing_ms": 0.09209343882561026, "mean_env_wait_ms": 4.253568417259373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 372000, "timesteps_this_iter": 0, "agent_timesteps_total": 372000, "timers": {"sample_time_ms": 9638.447, "sample_throughput": 415.005, "load_time_ms": 0.34, "load_throughput": 11780925.497, "learn_time_ms": 2081.339, "learn_throughput": 1921.839, "update_time_ms": 2.102}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 5.465740203857422, "policy_loss": -0.018424980342388153, "vf_loss": 5.479341506958008, "vf_explained_var": 0.10868281871080399, "kl": 0.0071449242532253265, "entropy": 1.3854193687438965, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 372000, "num_agent_steps_sampled": 372000, "num_steps_trained": 372000, "num_agent_steps_trained": 372000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19576, "training_iteration": 93, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-15", "timestamp": 1642602075, "time_this_iter_s": 10.049973964691162, "time_total_s": 970.814028263092, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 970.814028263092, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 44.90666666666665, "ram_util_percent": 62.47333333333333}}
{"episode_reward_max": -1.2, "episode_reward_min": -22.700000000000006, "episode_reward_mean": -3.79811320754717, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.5, -3.7000000000000006, -2.7000000000000006, -8.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -8.7, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -2.2, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -3.7000000000000006, -3.700000000000001, -12.2, -14.699999999999998, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -13.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -2.7, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -12.399999999999999, -3.7000000000000015, -2.7, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -22.3, -6.4, -2.7, -5.5, -2.7, -1.7000000000000004, -4.7, -1.2, -9.699999999999998, -2.7, -3.7000000000000015, -1.7000000000000004, -4.700000000000001, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000006, -14.699999999999998, -2.700000000000001, -4.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -8.7, -2.7, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -3.7000000000000015, -7.6999999999999975, -1.7000000000000004, -2.7, -5.699999999999999, -2.7, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -2.7, -2.700000000000001, -2.7, -2.7000000000000006, -2.700000000000001, -2.7, -1.7000000000000004, -4.699999999999999, -3.5, -4.699999999999998, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -1.7000000000000004, -2.7, -2.7000000000000006, -2.2, -1.7000000000000004, -2.7000000000000006, -2.7, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.2, -2.700000000000001, -3.700000000000001, -2.7, -1.7000000000000004, -4.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7, -3.7000000000000006, -12.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.2, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -4.7, -1.7000000000000004, -2.7, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -3.3, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -3.7000000000000006, -8.7, -2.700000000000001, -12.699999999999998, -2.7, -1.7000000000000004, -1.7000000000000004, -1.2, -2.700000000000001, -13.699999999999998, -2.700000000000001, -11.2, -2.7000000000000006, -2.7, -5.700000000000001, -2.700000000000001, -2.7, -14.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -3.7000000000000006, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -14.499999999999998, -2.7000000000000006, -3.7000000000000006, -3.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -22.700000000000006, -11.699999999999998, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.379841672538579, "mean_inference_ms": 1.2829736010031332, "mean_action_processing_ms": 0.09201412141272997, "mean_env_wait_ms": 4.249672092233175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 376000, "timesteps_this_iter": 0, "agent_timesteps_total": 376000, "timers": {"sample_time_ms": 9639.709, "sample_throughput": 414.95, "load_time_ms": 0.338, "load_throughput": 11836613.518, "learn_time_ms": 2068.906, "learn_throughput": 1933.389, "update_time_ms": 2.082}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 5.807984352111816, "policy_loss": -0.016656115651130676, "vf_loss": 5.820213794708252, "vf_explained_var": 0.11694730818271637, "kl": 0.006557696498930454, "entropy": 1.4044594764709473, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 376000, "num_agent_steps_sampled": 376000, "num_steps_trained": 376000, "num_agent_steps_trained": 376000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19788, "training_iteration": 94, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-25", "timestamp": 1642602085, "time_this_iter_s": 9.450569152832031, "time_total_s": 980.2645974159241, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 980.2645974159241, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 42.55384615384616, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -18.7, "episode_reward_mean": -3.4113207547169813, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -17.8, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -2.7, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -18.7, -1.7000000000000004, -1.2, -2.700000000000001, -1.7000000000000004, -10.699999999999998, -2.6000000000000014, -3.7000000000000015, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -9.699999999999998, -4.699999999999999, -2.7000000000000006, -9.699999999999998, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -6.700000000000001, -2.7, -3.7, -1.7000000000000004, -6.700000000000001, -2.7000000000000006, -3.7000000000000015, -2.7000000000000006, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7, -3.700000000000001, -4.1000000000000005, -1.7000000000000004, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -2.7000000000000006, -2.700000000000001, -2.7, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7, -3.7000000000000006, -8.7, -1.7000000000000004, -7.699999999999999, -2.7, -2.7, -2.7, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -2.700000000000001, -3.7, -4.7, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000015, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7000000000000015, -2.7000000000000006, -3.700000000000001, -3.7000000000000015, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -3.7000000000000006, -2.7, -2.7, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -3.7000000000000006, -3.700000000000001, -2.7, -5.699999999999999, -3.2, -3.700000000000001, -2.7000000000000006, -2.7000000000000006, -3.700000000000001, -16.7, -1.7000000000000004, -1.7000000000000004, -8.7, -1.7000000000000004, -1.7000000000000004, -8.2, -6.699999999999999, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -10.7, -1.7000000000000004, -4.699999999999999, -2.7, -12.699999999999998, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -3.700000000000001, -2.7, -2.2, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7, -2.700000000000001, -1.7000000000000004, -12.6, -2.7, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -12.2, -2.7000000000000006, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -3.7000000000000006, -2.2, -3.7000000000000006, -1.2, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -7.699999999999999, -3.7000000000000006, -5.699999999999999], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.378166789746338, "mean_inference_ms": 1.2819159068684436, "mean_action_processing_ms": 0.09194486230372445, "mean_env_wait_ms": 4.246011023619248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 380000, "timesteps_this_iter": 0, "agent_timesteps_total": 380000, "timers": {"sample_time_ms": 9610.12, "sample_throughput": 416.228, "load_time_ms": 0.339, "load_throughput": 11811613.63, "learn_time_ms": 2067.269, "learn_throughput": 1934.92, "update_time_ms": 2.086}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 4.378067970275879, "policy_loss": -0.022617807611823082, "vf_loss": 4.396493434906006, "vf_explained_var": 0.1305992603302002, "kl": 0.006210338789969683, "entropy": 1.3752946853637695, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 380000, "num_agent_steps_sampled": 380000, "num_steps_trained": 380000, "num_agent_steps_trained": 380000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20000, "training_iteration": 95, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-34", "timestamp": 1642602094, "time_this_iter_s": 9.632338762283325, "time_total_s": 989.8969361782074, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 989.8969361782074, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 42.4, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -20.700000000000003, "episode_reward_mean": -3.644711538461539, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -8.7, -1.7000000000000004, -7.699999999999999, -4.7, -20.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -2.2, -1.7000000000000004, -5.2, -2.7000000000000015, -2.700000000000001, -2.7, -2.7000000000000006, -2.7, -2.7, -1.7000000000000004, -2.7000000000000015, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -14.499999999999998, -1.7000000000000004, -2.7000000000000006, -6.700000000000001, -2.7000000000000006, -3.700000000000001, -15.699999999999998, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -3.700000000000001, -2.7, -8.7, -7.699999999999999, -1.7000000000000004, -2.7000000000000006, -10.599999999999998, -2.7000000000000006, -3.7000000000000006, -2.700000000000001, -2.7, -2.700000000000001, -1.7000000000000004, -2.7, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.7, -1.7000000000000004, -2.7, -2.700000000000001, -3.7000000000000015, -1.7000000000000004, -3.7000000000000015, -1.2, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -4.699999999999999, -2.7, -2.700000000000001, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000006, -1.2, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -2.7, -17.7, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -17.7, -1.7000000000000004, -11.699999999999998, -2.7, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -13.699999999999998, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.7, -1.7000000000000004, -7.699999999999999, -4.7, -2.7, -3.7000000000000006, -2.700000000000001, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000015, -3.7000000000000006, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -10.7, -2.7000000000000006, -2.7, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.2, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -2.7, -1.7000000000000004, -4.700000000000001, -2.700000000000001, -2.2, -2.700000000000001, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -4.7, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -3.5, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -5.699999999999999, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -3.700000000000001, -2.700000000000001, -13.699999999999998, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -13.699999999999998, -2.7], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.376294007774537, "mean_inference_ms": 1.2807218234075437, "mean_action_processing_ms": 0.0918651364487676, "mean_env_wait_ms": 4.242091587752812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 384000, "timesteps_this_iter": 0, "agent_timesteps_total": 384000, "timers": {"sample_time_ms": 9646.403, "sample_throughput": 414.662, "load_time_ms": 0.332, "load_throughput": 12043080.899, "learn_time_ms": 2049.986, "learn_throughput": 1951.232, "update_time_ms": 2.082}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 5.929235935211182, "policy_loss": -0.020060410723090172, "vf_loss": 5.944210529327393, "vf_explained_var": 0.09740133583545685, "kl": 0.007535258773714304, "entropy": 1.3947845697402954, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 384000, "num_agent_steps_sampled": 384000, "num_steps_trained": 384000, "num_agent_steps_trained": 384000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20208, "training_iteration": 96, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-44", "timestamp": 1642602104, "time_this_iter_s": 9.57381296157837, "time_total_s": 999.4707491397858, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 999.4707491397858, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 42.65384615384615, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.2, "episode_reward_min": -22.700000000000003, "episode_reward_mean": -3.8000000000000007, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.7000000000000006, -11.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.2, -2.700000000000001, -3.700000000000001, -2.6000000000000014, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -9.699999999999998, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -2.700000000000001, -2.7, -2.7, -4.2, -2.7000000000000015, -1.7000000000000004, -2.7, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -14.699999999999998, -9.7, -3.7000000000000006, -2.7, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -9.7, -1.7000000000000004, -1.7000000000000004, -1.2, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.7, -1.7000000000000004, -3.2, -3.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.7, -1.7000000000000004, -1.7000000000000004, -13.699999999999998, -12.699999999999998, -7.6999999999999975, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -4.7, -1.7000000000000004, -1.7000000000000004, -7.699999999999999, -10.6, -1.7000000000000004, -3.7000000000000015, -1.2, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -12.5, -1.7000000000000004, -16.7, -21.700000000000003, -1.7000000000000004, -2.700000000000001, -2.7, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -4.7, -3.700000000000001, -4.7, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -3.7000000000000006, -3.7000000000000006, -2.7, -2.700000000000001, -3.700000000000001, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -4.699999999999999, -3.7000000000000006, -7.699999999999999, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -12.7, -2.7, -1.7000000000000004, -2.7, -1.7000000000000004, -22.700000000000003, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7, -1.7000000000000004, -2.7, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -3.7, -2.7, -1.7000000000000004, -2.7000000000000006, -11.2, -4.700000000000001, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -10.699999999999998, -2.7000000000000006, -1.2, -3.7000000000000006, -5.7, -2.7, -8.7, -2.7, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -2.7, -3.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -12.699999999999998, -3.7000000000000006, -12.2, -2.2, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -13.699999999999998, -13.8, -2.7000000000000006, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.374745084077291, "mean_inference_ms": 1.2793817818382964, "mean_action_processing_ms": 0.09176958858462343, "mean_env_wait_ms": 4.237467208533771, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 388000, "timesteps_this_iter": 0, "agent_timesteps_total": 388000, "timers": {"sample_time_ms": 9666.368, "sample_throughput": 413.806, "load_time_ms": 0.333, "load_throughput": 12017202.206, "learn_time_ms": 2009.346, "learn_throughput": 1990.698, "update_time_ms": 2.044}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 6.919243335723877, "policy_loss": -0.013989608734846115, "vf_loss": 6.929600238800049, "vf_explained_var": 0.008414257317781448, "kl": 0.0053822011686861515, "entropy": 1.414184808731079, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 388000, "num_agent_steps_sampled": 388000, "num_steps_trained": 388000, "num_agent_steps_trained": 388000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20420, "training_iteration": 97, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-21-53", "timestamp": 1642602113, "time_this_iter_s": 9.437199831008911, "time_total_s": 1008.9079489707947, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1008.9079489707947, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 41.76428571428572, "ram_util_percent": 62.39999999999999}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -3.979807692307693, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 208, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7000000000000006, -1.7000000000000004, -4.699999999999999, -8.7, -15.699999999999998, -12.699999999999998, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -3.700000000000001, -2.7, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7000000000000006, -1.7000000000000004, -2.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000006, -3.7000000000000006, -1.7000000000000004, -4.7, -2.7000000000000006, -13.699999999999998, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -2.7, -1.7000000000000004, -4.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -6.699999999999999, -2.7, -1.7000000000000004, -2.9, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -2.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -11.699999999999998, -4.7, -5.699999999999999, -2.7000000000000015, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.3, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -9.6, -2.7, -2.700000000000001, -3.2, -3.700000000000001, -2.7, -3.7000000000000006, -8.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -6.700000000000001, -2.7, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -8.2, -3.700000000000001, -1.7000000000000004, -8.7, -2.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -2.7, -9.3, -1.7000000000000004, -21.700000000000006, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -1.7000000000000004, -8.7, -2.7, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -4.6, -2.7000000000000006, -1.7000000000000004, -9.7, -15.6, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -4.7, -4.7, -1.7000000000000004, -22.700000000000003, -2.700000000000001, -17.5, -4.700000000000001, -2.7, -16.700000000000003, -4.1000000000000005, -2.7, -2.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -12.7, -23.700000000000006, -1.7000000000000004, -2.7000000000000015, -1.7000000000000004, -17.7, -2.7, -4.1, -1.7000000000000004, -2.7, -3.7000000000000006, -14.699999999999998, -2.7000000000000006, -16.7, -12.699999999999998, -2.700000000000001, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -4.700000000000001, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3719623764405853, "mean_inference_ms": 1.277739588756298, "mean_action_processing_ms": 0.09165718801627273, "mean_env_wait_ms": 4.232019798785885, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 392000, "timesteps_this_iter": 0, "agent_timesteps_total": 392000, "timers": {"sample_time_ms": 9635.692, "sample_throughput": 415.123, "load_time_ms": 0.326, "load_throughput": 12255983.636, "learn_time_ms": 1991.221, "learn_throughput": 2008.817, "update_time_ms": 2.017}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 9.39107894897461, "policy_loss": -0.020832661539316177, "vf_loss": 9.406779289245605, "vf_explained_var": -0.11541162431240082, "kl": 0.007602238561958075, "entropy": 1.456425666809082, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 392000, "num_agent_steps_sampled": 392000, "num_steps_trained": 392000, "num_agent_steps_trained": 392000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20628, "training_iteration": 98, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-22-02", "timestamp": 1642602122, "time_this_iter_s": 9.240580081939697, "time_total_s": 1018.1485290527344, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1018.1485290527344, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 41.81538461538461, "ram_util_percent": 62.43076923076923}}
{"episode_reward_max": -1.2, "episode_reward_min": -23.700000000000006, "episode_reward_mean": -4.097641509433963, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.699999999999999, -1.7000000000000004, -2.7000000000000006, -2.7, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -5.699999999999999, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.7, -2.7000000000000015, -2.9, -2.7000000000000006, -2.7, -3.700000000000001, -1.7000000000000004, -7.699999999999999, -2.7000000000000006, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -3.7, -4.700000000000001, -1.7000000000000004, -10.399999999999999, -2.7000000000000006, -3.700000000000001, -9.7, -22.700000000000003, -2.700000000000001, -2.7000000000000006, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -23.0, -3.7000000000000015, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7000000000000006, -2.7, -2.7, -1.7000000000000004, -2.7000000000000006, -12.699999999999998, -1.7000000000000004, -3.700000000000001, -1.2, -4.7, -7.699999999999999, -1.7000000000000004, -2.700000000000001, -14.699999999999998, -1.7000000000000004, -4.2, -2.7000000000000006, -2.7000000000000006, -23.700000000000006, -3.700000000000001, -2.7000000000000006, -2.700000000000001, -2.7000000000000006, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -3.7000000000000015, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.2, -3.9, -13.699999999999998, -1.2, -3.6000000000000014, -8.7, -21.700000000000006, -2.7000000000000006, -4.700000000000001, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -12.599999999999998, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.699999999999998, -2.700000000000001, -1.7000000000000004, -14.699999999999998, -1.7000000000000004, -1.7000000000000004, -15.699999999999998, -1.7000000000000004, -11.699999999999998, -1.7000000000000004, -2.7000000000000006, -15.8, -3.700000000000001, -2.7000000000000006, -3.7000000000000015, -2.700000000000001, -5.100000000000001, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -4.700000000000001, -3.3, -1.7000000000000004, -2.7000000000000015, -12.4, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -1.7000000000000004, -2.2, -2.700000000000001, -7.699999999999999, -5.699999999999999, -1.7000000000000004, -1.7000000000000004, -20.700000000000003, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.7000000000000006, -2.7, -3.7, -2.700000000000001, -1.2, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -1.7000000000000004, -4.699999999999999, -1.7000000000000004, -2.7000000000000006, -4.7, -2.7000000000000015, -2.7000000000000006, -2.7, -10.599999999999998, -4.700000000000001, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.7000000000000015, -2.7, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -2.700000000000001, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -12.699999999999998, -1.7000000000000004, -13.699999999999998, -10.699999999999998, -1.7000000000000004, -1.7000000000000004, -2.7, -1.7000000000000004, -3.700000000000001, -5.699999999999999, -2.7, -2.7, -1.7000000000000004, -10.699999999999998, -3.3, -3.5000000000000004], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3692913018621953, "mean_inference_ms": 1.2759975407542867, "mean_action_processing_ms": 0.09153890984945652, "mean_env_wait_ms": 4.226279761328582, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 396000, "timesteps_this_iter": 0, "agent_timesteps_total": 396000, "timers": {"sample_time_ms": 9606.425, "sample_throughput": 416.388, "load_time_ms": 0.326, "load_throughput": 12270325.459, "learn_time_ms": 2034.063, "learn_throughput": 1966.507, "update_time_ms": 2.085}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 7.733229160308838, "policy_loss": -0.027787702158093452, "vf_loss": 7.75576114654541, "vf_explained_var": -0.004121958743780851, "kl": 0.007785798981785774, "entropy": 1.4480268955230713, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 396000, "num_agent_steps_sampled": 396000, "num_steps_trained": 396000, "num_agent_steps_trained": 396000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20840, "training_iteration": 99, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-22-12", "timestamp": 1642602132, "time_this_iter_s": 9.740132093429565, "time_total_s": 1027.888661146164, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1027.888661146164, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 43.114285714285714, "ram_util_percent": 62.457142857142856}}
{"episode_reward_max": -1.7000000000000004, "episode_reward_min": -16.7, "episode_reward_mean": -3.7500000000000004, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 212, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.7, -15.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -4.699999999999999, -11.699999999999998, -7.699999999999999, -1.7000000000000004, -4.7, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.700000000000001, -3.7000000000000006, -1.7000000000000004, -2.7000000000000006, -2.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -11.7, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -2.7, -3.7000000000000006, -14.699999999999998, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -9.7, -2.700000000000001, -4.1, -1.7000000000000004, -2.7, -2.7, -3.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.7000000000000015, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -9.7, -2.7000000000000006, -1.7000000000000004, -4.7, -5.2, -7.699999999999999, -7.699999999999999, -7.699999999999999, -3.7000000000000006, -3.7, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7, -2.7000000000000006, -1.7000000000000004, -2.7000000000000006, -3.700000000000001, -7.699999999999999, -2.7, -7.699999999999999, -2.7, -1.7000000000000004, -3.7000000000000006, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -1.7000000000000004, -2.7, -3.7000000000000015, -1.7000000000000004, -2.7, -10.5, -2.700000000000001, -1.7000000000000004, -12.699999999999998, -3.1, -15.9, -8.7, -2.7000000000000006, -2.7, -1.7000000000000004, -2.7000000000000006, -2.7000000000000006, -2.700000000000001, -12.699999999999998, -3.3, -2.700000000000001, -2.7, -4.700000000000001, -1.7000000000000004, -13.699999999999998, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -9.7, -3.7, -3.700000000000001, -2.7, -8.7, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -14.699999999999998, -2.7000000000000006, -11.699999999999998, -1.7000000000000004, -3.7000000000000015, -1.7000000000000004, -2.7, -11.699999999999998, -1.7000000000000004, -2.2, -1.7000000000000004, -2.700000000000001, -11.7, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.2, -2.7000000000000006, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -14.699999999999998, -4.7, -3.700000000000001, -2.700000000000001, -4.7, -14.699999999999998, -3.7000000000000015, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -3.700000000000001, -2.7, -1.7000000000000004, -1.7000000000000004, -3.7000000000000006, -2.7000000000000006, -2.7000000000000006, -2.7000000000000015, -1.7000000000000004, -16.7, -1.7000000000000004, -3.7, -1.7000000000000004, -4.700000000000001, -1.7000000000000004, -2.2, -1.7000000000000004, -1.7000000000000004, -1.7000000000000004, -2.7, -2.7000000000000006, -3.2, -1.7000000000000004, -1.7000000000000004, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -3.6000000000000014, -2.7000000000000006, -1.7000000000000004, -1.7000000000000004, -2.700000000000001, -1.7000000000000004, -3.700000000000001, -2.7000000000000006, -2.7000000000000006, -3.7000000000000006, -1.7000000000000004, -5.700000000000001, -2.7, -2.700000000000001, -1.7000000000000004, -1.7000000000000004, -11.699999999999998, -4.700000000000001, -2.7000000000000006, -12.0, -2.2], "episode_lengths": [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3711321252609316, "mean_inference_ms": 1.2768461192112324, "mean_action_processing_ms": 0.09159374136448915, "mean_env_wait_ms": 4.229042430187271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 400000, "timesteps_this_iter": 0, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 9750.124, "sample_throughput": 410.251, "load_time_ms": 0.33, "load_throughput": 12125770.454, "learn_time_ms": 2064.9, "learn_throughput": 1937.14, "update_time_ms": 2.08}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 9.999999747378752e-05, "total_loss": 5.784639835357666, "policy_loss": -0.017670888453722, "vf_loss": 5.797897815704346, "vf_explained_var": 0.07442653179168701, "kl": 0.00653656804934144, "entropy": 1.4506474733352661, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}}}, "num_steps_sampled": 400000, "num_agent_steps_sampled": 400000, "num_steps_trained": 400000, "num_agent_steps_trained": 400000, "num_steps_trained_this_iter": 0}, "done": true, "episodes_total": 21052, "training_iteration": 100, "trial_id": "bbf7d_00000", "experiment_id": "f2c185a4aef2409fb936206183c460ad", "date": "2022-01-19_14-22-23", "timestamp": 1642602143, "time_this_iter_s": 11.195850849151611, "time_total_s": 1039.0845119953156, "pid": 45667, "hostname": "MAC-ATI0602", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0001, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "my_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "CybORGAgent", "observation_space": null, "action_space": null, "env_config": {"null": 0}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1039.0845119953156, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 50.5375, "ram_util_percent": 62.6}}
